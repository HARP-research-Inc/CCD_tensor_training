# Lenin, Chomsky, Napoleon, Curie, Mercury
# socialism, linguistics, war, chemistry, rock

1 - Vladimir Lenin (born April 10 [April 22, New Style], 1870, Simbirsk, Russia—died January 21, 1924, Gorki [later Gorki Leninskiye], near Moscow) was the founder of the Russian Communist Party (Bolsheviks), inspirer and leader of the Bolshevik Revolution (1917), and the architect, builder, and first head (1917–24) of the Soviet state. He was the founder of the organization known as Comintern (Communist International) and the posthumous source of “Leninism,” the doctrine codified and conjoined with Karl Marx’s works by Lenin’s successors to form Marxism-Leninism, which became the Communist worldview.
1 - If the Bolshevik Revolution is—as some people have called it—the most significant political event of the 20th century, then Lenin must for good or ill be regarded as the century’s most significant political leader. Not only in the scholarly circles of the former Soviet Union but even among many non-Communist scholars, he has been regarded as both the greatest revolutionary leader and revolutionary statesman in history, as well as the greatest revolutionary thinker since Marx.
1 - It is difficult to identify any particular events in his childhood that might prefigure his turn onto the path of a professional revolutionary. Vladimir Ilich Ulyanov was born in Simbirsk, which was renamed Ulyanovsk in his honour. (He adopted the pseudonym Lenin in 1901 during his clandestine party work after exile in Siberia.) He was the third of six children born into a close-knit, happy family of highly educated and cultured parents. His mother was the daughter of a physician, while his father, though the son of a serf, became a schoolteacher and rose to the position of inspector of schools. Lenin, intellectually gifted, physically strong, and reared in a warm, loving home, early displayed a voracious passion for learning. He graduated from high school ranking first in his class. He distinguished himself in Latin and Greek and seemed destined for the life of a classical scholar. When he was 16, nothing in Lenin indicated a future rebel, still less a professional revolutionary—except, perhaps, his turn to atheism. But, despite the comfortable circumstances of their upbringing, all five of the Ulyanov children who reached maturity joined the revolutionary movement. This was not an uncommon phenomenon in tsarist Russia, where even the highly educated and cultured intelligentsia were denied elementary civil and political rights.
1 - As an adolescent Lenin suffered two blows that unquestionably influenced his subsequent decision to take the path of revolution. First, his father was threatened shortly before his untimely death with premature retirement by a reactionary government that had grown fearful of the spread of public education. Second, in 1887 his beloved eldest brother, Aleksandr, a student at the University of St. Petersburg (later renamed Leningrad State University), was hanged for conspiring with a revolutionary terrorist group that plotted to assassinate Emperor Alexander III. Suddenly, at age 17, Lenin became the male head of the family, which was now stigmatized as having reared a “state criminal.”
1 - Fortunately the income from his mother’s pension and inheritance kept the family in comfortable circumstances, although it could not prevent the frequent imprisonment or exile of her children. Moreover, Lenin’s high school principal (the father of Aleksandr Kerensky, who was later to lead the Provisional government deposed by Lenin’s Bolsheviks in November [October, O.S.] 1917) did not turn his back on the “criminal’s” family. He courageously wrote a character reference that smoothed Lenin’s admission to a university.
1 - In autumn 1887 Lenin enrolled in the faculty of law of the imperial Kazan University (later renamed Kazan [V.I. Lenin] State University), but within three months he was expelled from the school, having been accused of participating in an illegal student assembly. He was arrested and banished from Kazan to his grandfather’s estate in the village of Kokushkino, where his older sister Anna had already been ordered by the police to reside. In the autumn of 1888, the authorities permitted him to return to Kazan but denied him readmission to the university. During this period of enforced idleness, he met exiled revolutionaries of the older generation and avidly read revolutionary political literature, especially Marx’s Das Kapital. He became a Marxist in January 1889.
1 - In May 1889 the Ulyanov family moved to Samara (known as Kuybyshev from 1935 to 1991). After much petitioning, Lenin was granted permission to take his law examinations. In November 1891 he passed his examinations, taking a first in all subjects, and was graduated with a first-class degree. After the police finally waived their political objections, Lenin was admitted to the bar and practiced law in Samara in 1892–93, his clients being mainly poor peasants and artisans. In his experience practicing law, he acquired an intense loathing for the class bias of the legal system and a lifelong revulsion for lawyers, even those who claimed to be Social-Democrats.
1 - Law proved to be an extremely useful cover for a revolutionary activist. He moved to St. Petersburg (from 1914 to 1924 known as Petrograd; from 1924 to 1991 known as Leningrad) in August 1893 and, while working as a public defender, associated with revolutionary Marxist circles. In 1895 his comrades sent him abroad to make contact with Russian exiles in western Europe, especially with Russia’s most commanding Marxist thinker, Georgy Plekhanov. Upon his return to Russia in 1895, Lenin and other Marxists, including L. Martov, the future leader of the Mensheviks, succeeded in unifying the Marxist groups of the capital in an organization known as the Union for the Struggle for the Liberation of the Working Class. The Union issued leaflets and proclamations on the workers’ behalf, supported workers’ strikes, and infiltrated workers’ education classes to impart to them the rudiments of Marxism. In December 1895, the leaders of the Union were arrested. Lenin was jailed for 15 months and thereafter was sent into exile to Shushenskoye, in Siberia, for a term of three years. He was joined there in exile by his fiancée, Nadezhda Krupskaya, a Union member, whom he had met in the capital. They were married in Siberia, and she became Lenin’s indispensable secretary and comrade. In exile they conducted clandestine party correspondence and collaborated (legally) on a Russian translation of Sidney and Beatrice Webb’s Industrial Democracy.
1 - Upon completing his term of Siberian exile in January 1900, Lenin left the country and was joined later by Krupskaya in Munich. His first major task abroad was to join Plekhanov, Martov, and three other editors in bringing out the newspaper Iskra (“The Spark”), which they hoped would unify the Russian Marxist groups that were scattered throughout Russia and western Europe into a cohesive Social-Democratic party.
1 - Up to the point at which Lenin began working on Iskra, his writings had taken as their focus three problems: first, he had written a number of leaflets that aimed to shake the workers’ traditional veneration of the tsar by showing them that their harsh life was caused, in part, by the support tsarism rendered the capitalists; second, he attacked those self-styled Marxists who urged Social-Democrats and workers to concentrate on wage and hour issues, leaving the political struggle for the present to the bourgeoisie; third, and ultimately most important, he addressed himself to the peasant question.
1 - The principal obstacle to the acceptance of Marxism by many of the Russian intelligentsia was their adherence to the widespread belief of the Populists (Russian pre-Marxist radicals) that Marxism was inapplicable to peasant Russia, in which a proletariat (an industrial working class) was almost nonexistent. Russia, they believed, was immune to capitalism, owing to the circumstances of joint ownership of peasant land by the village commune. This view had been first attacked by Plekhanov in the 1880s. Plekhanov had argued that Russia had already entered the capitalist stage, looking for evidence to the rapid growth of industry. Despite the denials of the Populists, he claimed, the man of the future in Russia was indeed the proletarian, not the peasant. While attempting to apply the Marxist scheme of social development to Russia, Plekhanov had come to the conclusion that the revolution in Russia would have to pass through two discrete stages: first, a bourgeois revolution that would establish a democratic republic and full-blown capitalism; and second, a proletarian revolution after mature capitalism had generated a numerous proletariat that had attained a high level of political organization, socialist consciousness, and culture, enabling them to usher in full Socialism.
1 - It was this set of principles that Lenin adhered to after he read Plekhanov’s work in the late 1880s. But, almost immediately, Lenin went a step beyond his former mentor, especially with regard to the peasant question. In an attack on the Populists published in 1894, Lenin charged that, even if they realized their fondest dream and divided all the land among the peasant communes, the result would not be Socialism but rather capitalism spawned by a free market in agricultural produce. The “Socialism” put forth by the Populists would in practice favour the development of small-scale capitalism; hence the Populists were not Socialists but “petty bourgeois democrats.” Lenin came to the conclusion that outside of Marxism, which aimed ultimately to abolish the market system as well as the private ownership of the means of production, there could be no Socialism.
1 - Even while in exile in Siberia, Lenin had begun research on his investigation of the peasant question, which culminated in his magisterial Development of Capitalism in Russia (published legally in 1899). In this work, a study of Russian economics, he argued that capitalism was rapidly destroying the peasant commune. The peasantry constituted for the Populists a homogeneous social class, but Lenin claimed that the peasantry was in actuality rapidly stratifying into a well-off rural bourgeoisie, a middling peasantry, and an impoverished rural “proletariat and semi-proletariat.” In this last group, which comprised half the peasant population, Lenin found an ally for the extremely small industrial proletariat in Russia.
1 - Iskra’s success in recruiting Russian intellectuals to Marxism led Lenin and his comrades to believe that the time was ripe to found a revolutionary Marxist party that would weld together all the disparate Marxist groups at home and abroad. An abortive First Congress, held in 1898 in Minsk, had failed to achieve this objective, for most of the delegates were arrested shortly after the congress. The organizing committee of the Second Congress decided to convene the congress in Brussels in 1903, but police pressure forced it to transfer to London.
1 - The congressional sessions wore on for nearly three weeks, for no point appeared too trivial to debate. The main issues, nevertheless, quickly became plain: eligibility for membership and the character of party discipline; but, above all, the key questions centred around the relation between the party and the proletariat, for whom the party claimed to speak.
1 - In his What Is To Be Done? (1902), Lenin totally rejected the standpoint that the proletariat was being driven spontaneously to revolutionary Socialism by capitalism and that the party’s role should be to merely coordinate the struggle of the proletariat’s diverse sections on a national and international scale. Capitalism, he contended, predisposed the workers to the acceptance of Socialism but did not spontaneously make them conscious Socialists. The proletariat by its own efforts in the everyday struggle against the capitalist could go so far as to achieve “trade-union consciousness.” But the proletariat could not by its own efforts grasp that it would be possible to win complete emancipation only by overthrowing capitalism and building Socialism, unless the party from without infused it with Socialist consciousness.
1 - In his What Is To Be Done? and in his other works dealing with party organization, Lenin articulated one of his most momentous political innovations, his theory of the party as the “vanguard of the proletariat.” He conceived of the vanguard as a highly disciplined, centralized party that would work unremittingly to suffuse the proletariat with Socialist consciousness and serve as mentor, leader, and guide, constantly showing the proletariat where its true class interests lie.
1 - At the Second Congress the Iskra group split, and Lenin found himself in a minority of opinion on this very issue. Nevertheless, he continued to develop his view of “the party of a new type,” which was to be guided by “democratic centralism,” or absolute party discipline. According to Lenin the party had to be a highly centralized body organized around a small, ideologically homogeneous, hardened core of experienced professional revolutionaries, who would be elected to the central committee by the party congress and who would lead a ramified hierarchy of lower party organizations that would enjoy the support and sympathy of the proletariat and all groups opposed to tsarism. “Give us an organization of revolutionaries,” Lenin exclaimed, “and we will overturn Russia!”
1 - Lenin spared no effort to build just this kind of party over the next 20 years, despite fierce attacks on his position by some of his closest comrades of the Iskra days, Plekhanov, Martov, and Leon Trotsky. They charged that his scheme of party organization and discipline tended toward “Jacobinism,” suppression of free intraparty discussion, a dictatorship over the proletariat, not of the proletariat, and, finally, establishment of a one-man dictatorship.
1 - Lenin found himself in the minority in the early sessions of the Second Congress of what was then proclaimed to be the Russian Social-Democratic Workers’ Party (RSDWP). But a walkout by a disgruntled group of Jewish Social-Democrats, the Bund, left Lenin with a slight majority. Consequently, the members of Lenin’s adventitious majority were called Bolsheviks (majoritarians), and Martov’s group were dubbed Mensheviks (minoritarians). The two groups fought each other ceaselessly within the same RSDWP and professed the same program until 1912, when Lenin made the split final at the Prague Conference of the Bolshevik Party.
1 - The differences between Lenin and the Mensheviks became sharper in the Revolution of 1905 and its aftermath, when Lenin moved to a distinctly original view on two issues: class alignments in the revolution and the character of the post-revolutionary regime.
1 - The outbreak of the revolution, in January 1905, found Lenin abroad in Switzerland, and he did not return to Russia until November. Immediately Lenin set down a novel strategy. Both wings of the RSDWP, Bolshevik and Menshevik, adhered to Plekhanov’s view of the revolution in two stages: first, a bourgeois revolution; second, a proletarian revolution (see above). But the Mensheviks argued that the bourgeois revolution must be led by the bourgeoisie, with whom the proletariat must ally itself in order to make the democratic revolution. This would bring the liberal bourgeoisie to full power, whereupon the RSDWP would act as the party of opposition. Lenin defiantly rejected this kind of alliance and post-revolutionary regime. Hitherto he had spoken of the need for the proletariat to win “hegemony” in the democratic revolution. Now he flatly declared that the proletariat was the driving force of the revolution and that its only reliable ally was the peasantry. The bourgeoisie he branded as hopelessly counterrevolutionary and too cowardly to make its own revolution. Thus, unlike the Mensheviks, Lenin henceforth banked on an alliance that would establish a “revolutionary democratic dictatorship of the proletariat and the peasantry.”
1 - Nor would the revolution necessarily stop at the first stage, the bourgeois revolution. If the Russian revolution should inspire the western European proletariat to make the Socialist revolution, for which industrial Europe was ripe, the Russian revolution might well pass over directly to the second stage, the Socialist revolution. Then, the Russian proletariat, supported by the rural proletariat and semi-proletariat at home and assisted by the triumphant industrial proletariat of the West, which had established its “dictatorship of the proletariat,” could cut short the life-span of Russian capitalism.
1 - After the defeat of the Revolution of 1905, the issue between Lenin and the Mensheviks was more clearly drawn than ever, despite efforts at reunion. But, forced again into exile from 1907 to 1917, Lenin found serious challenges to his policies not only from the Mensheviks but within his own faction as well. The combination of repression and modest reform effected by the tsarist regime led to a decline of party membership. Disillusionment and despair in the chances of successful revolution swept the dwindled party ranks, rent by controversies over tactics and philosophy. Attempts to unite the Bolshevik and Menshevik factions came to naught, all breaking on Lenin’s intransigent insistence that his conditions for reunification be adopted. As one Menshevik opponent described Lenin: “There is no other man who is absorbed by the revolution twenty-four hours a day, who has no other thoughts but the thought of revolution, and who even when he sleeps, dreams of nothing but revolution.” Placing revolution above party unity, Lenin would accept no unity compromise if he thought it might delay, not accelerate, revolution.
1 - Desperately fighting to maintain the cohesion of the Bolsheviks against internal differences and the Mensheviks’ growing strength at home, Lenin convened the Bolshevik Party Conference at Prague, in 1912, which split the RSDWP forever. Lenin proclaimed that the Bolsheviks were the RSDWP and that the Mensheviks were schismatics. Thereafter, each faction maintained its separate central committee, party apparatus, and press.
1 - When war broke out, in August 1914, Socialist parties throughout Europe rallied behind their governments despite the resolutions of prewar congresses of the Second International obliging them to resist or even overthrow their respective governments if they plunged their countries into an imperialist war.
1 - After Lenin recovered from his initial disbelief in this “betrayal” of the International, he proclaimed a policy whose audacity stunned his own Bolshevik comrades. He denounced the pro-war Socialists as “social-chauvinists” who had betrayed the international working-class cause by support of a war that was imperialist on both sides. He pronounced the Second International as dead and appealed for the creation of a new, Third International composed of genuinely revolutionary Socialist parties. More immediately, revolutionary Socialists must work to “transform the imperialist war into civil war.” The real enemy of the worker was not the worker in the opposite trench but the capitalist at home. Workers and soldiers should therefore turn their guns on their rulers and destroy the system that had plunged them into imperialist carnage.
1 - Lenin’s policy found few advocates in Russia or elsewhere in the first months of the war. Indeed, in the first flush of patriotic fervour, not a few Bolsheviks supported the war effort. Lenin and his closest comrades were left an isolated band swimming against the current.
1 - Lenin succeeded in reaching neutral Switzerland in September 1914, there joining a small group of anti-war Bolshevik and Menshevik émigrés. The war virtually cut them off from all contact with Russia and with like-minded Socialists in other countries. Nevertheless, in 1915 and 1916, anti-war Socialists in various countries managed to hold two anti-war conferences in Zimmerwald and Kienthal, Switzerland. Lenin failed at both meetings to persuade his comrades to adopt his slogan: “transform the imperialist war into civil war!” They adopted instead the more moderate formula: “An immediate peace without annexations or indemnities and the right of the peoples to self-determination.” Lenin consequently found his party a minority within the group of anti-war Socialists, who, in turn, constituted a small minority of the international Socialist movement compared with the pro-war Socialists.
1 - Undaunted, Lenin continued to hammer home his views on the war, confident that eventually he would win decisive support. In his Imperialism, the Highest Stage of Capitalism (1917), he set out to explain, first, the real causes of the war; second, why Socialists had abandoned internationalism for patriotism and supported the war; and third, why revolution alone could bring about a just, democratic peace.
1 - War erupted, he wrote, because of the insatiable, expansionist character of imperialism, itself a product of monopoly finance capitalism. At the end of the 19th century, a handful of banks had come to dominate the advanced countries, which, by 1914, had in their respective empires brought the rest of the world under their direct or indirect controls. Amassing vast quantities of “surplus” capital, the giant banks found they could garner superprofits on investments in colonies and semi-colonies, and this intensified the race for empire among the great powers. By 1914, dissatisfied with the way the world had been shared out, rival coalitions of imperialists launched the war to bring about a redivision of the world at the expense of the other coalition. The war was therefore imperialist in its origins and aims and deserved the condemnation of genuine Socialists.
1 - Socialist Party and trade-union leaders had rallied to support their respective imperialist governments because they represented the “labour aristocracy,” the better paid workers who received a small share of the colonial “superprofits” the imperialists proffered them. “Bribed” by the imperialists, the “labour aristocracy” took the side of their paymasters in the imperialist war and betrayed the most exploited workers at home and the super-exploited in the colonies. The imperialists, Lenin contended, driven by an annexationist dynamic, could not conclude a just, lasting peace. Future wars were inevitable so long as imperialism existed; imperialism was inevitable so long as capitalism existed; only the overthrow of capitalism everywhere could end the imperialist war and prevent such wars in the future. First published in Russia in 1917, Imperialism to this day provides the instrument that Communists everywhere employ to evaluate major trends in the non-Communist world.
1 - By 1917 it seemed to Lenin that the war would never end and that the prospect of revolution was rapidly receding. But in the week of March 8–15, the starving, freezing, war-weary workers and soldiers of Petrograd (until 1914, St. Petersburg) succeeded in deposing the Tsar. Lenin and his closest lieutenants hastened home after the German authorities agreed to permit their passage through Germany to neutral Sweden. Berlin hoped that the return of anti-war Socialists to Russia would undermine the Russian war effort.
1 - Lenin arrived in Petrograd on April 16, 1917, one month after the Tsar had been forced to abdicate. Out of the revolution was born the Provisional Government, formed by a group of leaders of the bourgeois liberal parties. This government’s accession to power was made possible only by the assent of the Petrograd Soviet, a council of workers’ deputies elected in the factories of the capital. Similar soviets of workers’ deputies sprang up in all the major cities and towns throughout the country, as did soviets of soldiers’ deputies and of peasants’ deputies. Although the Petrograd Soviet had been the sole political power recognized by the revolutionary workers and soldiers in March 1917, its leaders had hastily turned full power over to the Provisional Government. The Petrograd Soviet was headed by a majority composed of Menshevik and Socialist Revolutionary (SR), or peasant party, leaders who regarded the March (February, O.S.) Revolution as bourgeois; hence, they believed that the new regime should be headed by leaders of the bourgeois parties.
1 - On his return to Russia, Lenin electrified his own comrades, most of whom accepted the authority of the Provisional Government. Lenin called this government, despite its democratic pretensions, thoroughly imperialist and undeserving of support by Socialists. It was incapable of satisfying the most profound desires of the workers, soldiers, and peasants for immediate peace and division of landed estates among the peasants. Only a soviet government—that is, direct rule by workers, soldiers, and peasants—could fulfill these demands. Therefore, he raised the battle cry, “All power to the Soviets!”—although the Bolsheviks still constituted a minority within the soviets and despite the manifest unwillingness of the Menshevik–SR majority to exercise such power. This introduced what Lenin called the period of “dual power.” Under the leadership of “opportunist” Socialists, the soviets, the real power, had relinquished power to the Provisional Government, the nominal power in the land. The Bolsheviks, Lenin exhorted, must persuade the workers, peasants, and soldiers, temporarily deceived by the “opportunists,” to retrieve state power for the soviets from the Provisional Government. This would constitute a second revolution. But, so long as the government did not suppress the revolutionary parties, this revolution could be achieved peacefully, since the Provisional Government existed only by the sufferance of the soviets. Initially, Lenin’s fellow Bolsheviks thought that he was temporarily disoriented by the complexity of the situation; moderate Socialists thought him mad. It required several weeks of sedulous persuasion by Lenin before he won the Bolshevik Party Central Committee to his view. The April Party Conference endorsed his program: the party must withhold support from the Provisional Government and win a majority in the soviets in favour of soviet power. A soviet government, once established, should begin immediate negotiations for a general peace on all fronts. The soviets should forthwith confiscate landlords’ estates without compensation, nationalize all land, and divide it among the peasants. And the government should establish tight controls over privately owned industry to the benefit of labour.
1 - From March to September 1917, the Bolsheviks remained a minority in the soviets. By autumn, however, the Provisional Government (since July headed by the moderate Socialist Aleksandr Kerensky, who was supported by the moderate Socialist leadership of the soviets) had lost popular support. Increasing war-weariness and the breakdown of the economy overtaxed the patience of the workers, peasants, and soldiers, who demanded immediate and fundamental change. Lenin capitalized on the growing disillusionment of the people with Kerensky’s ability and willingness to complete the revolution. Kerensky, in turn, claimed that only a freely elected constituent assembly would have the power to decide Russia’s political future—but that must await the return of order. Meanwhile, Lenin and the party demanded peace, land, and bread—immediately, without further delay. The Bolshevik line won increasing support among the workers, soldiers, and peasants. By September they voted in a Bolshevik majority in the Petrograd Soviet and in the soviets of the major cities and towns throughout the country.
1 - Lenin, who had gone underground in July after he had been accused as a “German agent” by Kerensky’s government, now decided that the time was ripe to seize power. The party must immediately begin preparations for an armed uprising to depose the Provisional Government and transfer state power to the soviets, now headed by a Bolshevik majority.
1 - Lenin’s decision to establish soviet power derived from his belief that the proletarian revolution must smash the existing state machinery and introduce a “dictatorship of the proletariat”; that is, direct rule by the armed workers and peasants which would eventually “wither away” into a non-coercive, classless, stateless, Communist society. He expounded this view most trenchantly in his brochure The State and Revolution, written while he was still in hiding. The brochure, though never completed and often dismissed as Lenin’s most “Utopian” work, nevertheless served as Lenin’s doctrinal springboard to power.
1 - Until 1917 all revolutionary Socialists rightly believed, Lenin wrote, that a parliamentary republic could serve a Socialist system as well as a capitalist. But the Russian Revolution had brought forth something new, the soviets. Created by workers, soldiers, and peasants and excluding the propertied classes, the soviets infinitely surpassed the most democratic of parliaments in democracy, because parliaments everywhere virtually excluded workers and peasants. The choice before Russia in early September 1917, as Lenin saw it, was either a soviet republic—a dictatorship of the propertyless majority—or a parliamentary republic—as he saw it, a dictatorship of the propertied minority.
1 - Lenin therefore raised the slogan, “All power to the Soviets!”, even though he had willingly conceded in the spring of 1917 that revolutionary Russia was the “freest of all the belligerent countries.” To Lenin, however, the Provisional Government was merely a “dictatorship of the bourgeoisie” that kept Russia in the imperialist war. What is more, it had turned openly counterrevolutionary in the month of July when it accused the Bolshevik leaders of treason.
1 - From late September, Lenin, a fugitive in Finland, sent a stream of articles and letters to Petrograd feverishly exhorting the Party Central Committee to organize an armed uprising without delay. The opportune moment might be lost. But for nearly a month Lenin’s forceful urgings from afar were unsuccessful. As in April, Lenin again found himself in the party minority. He resorted to a desperate stratagem.
1 - Around October 20, Lenin, in disguise and at considerable personal risk, slipped into Petrograd and attended a secret meeting of the Bolshevik Central Committee held on the evening of October 23. Not until after a heated 10-hour debate did he finally win a majority in favour of preparing an armed takeover. Now steps to enlist the support of soldiers and sailors and to train the Red Guards, the Bolshevik-led workers’ militia, for an armed takeover proceeded openly under the guise of self-defense of the Petrograd Soviet. But preparations moved haltingly, because serious opposition to the fateful decision persisted in the Central Committee. Enthusiastically in accord with Lenin on the timeliness of an armed uprising, Trotsky led its preparation from his strategic position as newly elected chairman of the Petrograd Soviet. Lenin, now hiding in Petrograd and fearful of further procrastination, desperately pressed the Central Committee to fix an early date for the uprising. On the evening of November 6, he wrote a letter to the members of the Central Committee exhorting them to proceed that very evening to arrest the members of the Provisional Government. To delay would be “fatal.” The Second All-Russian Congress of Soviets, scheduled to convene the next evening, should be placed before a fait accompli.
1 - On November 7 and 8, the Bolshevik-led Red Guards and revolutionary soldiers and sailors, meeting only slight resistance, deposed the Provisional Government and proclaimed that state power had passed into the hands of the Soviets. By this time the Bolsheviks, with their allies among the Left SR’s (dissidents who broke with the pro-Kerensky SR leaders), constituted an absolute majority of the Second All-Russian Congress of Soviets. The delegates therefore voted overwhelmingly to accept full power and elected Lenin as chairman of the Council of People’s Commissars, the new Soviet Government, and approved his Peace Decree and Land Decree. Overnight, Lenin had vaulted from his hideout as a fugitive to head the Revolutionary government of the largest country in the world. Since his youth he had spent his life building a party that would win such a victory, and now at the age of 47 he and his party had triumphed. “It makes one’s head spin,” he confessed. But power neither intoxicated nor frightened Lenin; it cleared his head. Soberly, he steered the Soviet government toward the consolidation of its power and negotiations for peace.
1 - In both spheres, Lenin was plagued by breaks within the ranks of Bolshevik leaders. He reluctantly agreed with the right-wingers that it would be desirable to include the Menshevik and Right SR parties in a coalition government—but on Lenin’s terms. They must above all accept the soviet form of government, not a parliamentary one; they refused. Only the Left SR’s agreed, and several were included in the Soviet government. Likewise, when the freely elected Constituent Assembly met in January 1918, the Mensheviks and Right SR majority flatly rejected sovietism. Lenin without hesitation ordered the dispersal of the Constituent Assembly.
1 - The Allies refused to recognize the Soviet government; consequently it entered alone into peace negotiations with the Central Powers (Germany and her allies Austro-Hungary and Turkey) at the town of Brest-Litovsk. They imposed ruinous conditions that would strip away from Soviet Russia the western tier of non-Russian nations of the old Russian Empire. Left Communists fanatically opposed acceptance and preached a revolutionary war, even if it imperilled the Soviet government. Lenin insisted that the terms, however ruinous and humiliating, must be accepted or he would resign from the government. He sensed that peace was the deepest yearning of the people; in any case, the shattered army could not raise effective resistance to the invader. Finally, in March 1918, after a still larger part had been carved out of old Russia by the enemy, Lenin succeeded in winning the Central Committee’s acceptance of the Treaty of Brest-Litovsk. At last Russia was at peace.
1 - But Brest-Litovsk only intensified the determination of counterrevolutionary forces and the Allies who supported them to bring about the overthrow of the Soviet government. That determination hardened when, in 1918, Lenin’s government repudiated repayments of all foreign loans obtained by the tsarist and Provisional governments and nationalized foreign properties in Russia without compensation. From 1918 to 1920 Russia was torn by a Civil War, which cost millions of lives and untold destruction. One of the earliest victims was Lenin himself. In August 1918 an assassin fired two bullets into Lenin as he left a factory in which he had just delivered a speech. Because of his robust constitution, he recovered rapidly.
1 - The Soviet government faced tremendous odds. The anti-Soviet forces, or Whites, headed mainly by former tsarist generals and admirals, fought desperately to overthrow the Red regime. Moreover, the Whites were lavishly supplied by the Allies with materiel, money, and support troops that secured White bases. Yet, the Whites failed.
1 - It was largely because of Lenin’s inspired leadership that the Soviet government managed to survive against such military odds. He caused the formation and guided the strategy of the Workers’ and Peasants’ Red Army, commanded by Trotsky. Although the economy had collapsed, he managed to mobilize sufficient resources to sustain the Red Army and the industrial workers. But above all it was his political leadership that saved the day for the Soviets. By proclaiming the right of the peoples to self-determination, including the right to secession, he won the active sympathy, or at least the benevolent neutrality, of the non-Russian nationalities within Russia, because the Whites did not recognize that right. Indeed, his perceptive, skillful policy on the national question enabled Soviet Russia to avoid total disintegration and to remain a huge multinational state. By making the industrial workers the new privileged class, favoured in the distribution of rations, housing, and political power, he retained the loyalty of the proletariat. His championing of the peasants’ demand that they take all the land from the gentry, church, and crown without compensation won over the peasants, without whose support the government could not survive.
1 - Because of the breakdown of the economy, however, Lenin adopted a policy toward the peasant that threatened to destroy the Soviet government. Lacking funds or goods to exchange against grain needed to feed the Red Army and the towns, Lenin instituted a system of requisitioning grain surpluses without compensation. Many peasants resisted—at least until they experienced White “liberation.” On the territories that the Whites won, they restored landed property to the previous owners and savagely punished the peasants who had dared seize the land. Despite the peasants’ detestation of the Soviet’s grain requisitioning, the peasants, when forced to choose between Reds and Whites, chose the Reds.
1 - After the defeat of the Whites, the peasants no longer had to make that choice. They now totally refused to surrender their grain to the government. Threatened by mass peasant rebellion, Lenin called a retreat. In March 1921 the government introduced the New Economic Policy, which ended the system of grain requisitioning and permitted the peasant to sell his harvest on an open market. This constituted a partial retreat to capitalism.
1 - From the moment Lenin came to power, his abiding aims in international relations were twofold: to prevent the formation of an imperialist united front against Soviet Russia; but, even more important, to stimulate proletarian revolutions abroad.
1 - In his first aim he largely succeeded. In 1924, shortly after his death, Soviet Russia had won de jure recognition of all the major world powers except the United States. But his greater hope of the formation of a world republic of soviets failed to materialize, and Soviet Russia was left isolated in hostile capitalist encirclement.
1 - To break this encirclement, he had called on revolutionaries to form Communist parties that would emulate the example of the Bolshevik Revolution in all countries. Dramatizing his break with the reformist Second International, in 1918 he had changed the name of the RSDWP to the Russian Communist Party (Bolsheviks), and in March 1919 he founded the Communist, or Third, International. This International accepted the affiliation only of parties that accepted its decisions as binding, imposed iron discipline, and made a clean break with the Second International. In sum, Lenin now held up the Russian Communist Party, the only party that had made a successful revolution, as the model for Communist parties in all countries. One result of this policy was to engender a split in the world labour movement between the adherents of the two internationals.
1 - The Communist International scored its greatest success in the colonial world. By championing the rights of the peoples in the colonies and semi-colonies to self-determination and independence, the International won considerable sympathy for Communism. Lenin’s policy in this question still reverberates through the world today. And it offers another example of Lenin’s unique ability to find allies where revolutionaries had not found them before. By taking the side of the national liberation movements, Lenin could claim that the overwhelming majority of the world’s population, then living under imperialist rule, as well as the European proletariat, were the natural allies of the Bolshevik Revolution. 
1 - Thus Lenin’s revolutionary genius was not confined to his ability to divide his enemies; more important was his skill in finding allies and friends for the exiguous proletariat of Russia. First, he won the Russian peasants to the side of the proletariat. Second, while he did not win the workers to make successful Communist revolutions in the West, they did compel their governments to curtail armed intervention against the Bolshevik Revolution. Third, while the Asian revolutions barely stirred in his lifetime, they did strengthen the Soviet Communists in the belief that they were not alone in a hostile world.
1 - By 1921 Lenin’s government had crushed all opposition parties on the grounds that they had opposed or failed to support sufficiently the Soviet cause in the Civil War. Now that peace had come, Lenin believed that their opposition was more dangerous than ever, since the peasantry and even a large section of the working class had become disaffected with the Soviet regime. To repress opponents of Bolshevism, Lenin demanded the harshest measures, including “show” trials and frequent resort to the death penalty. Moreover, he insisted on even tighter control over dissent within the party. Lenin’s insistence on merciless destruction of the opposition to the Bolshevik dictatorship subsequently led many observers to conclude that Lenin, though personally opposed to one-man rule, nevertheless unwittingly cleared the way for the rise of Joseph Stalin’s dictatorship.
1 - By 1922 Lenin had become keenly aware that degeneration of the Soviet system and party was the greatest danger to the cause of Socialism in Russia. He found the party and Soviet state apparatus hopelessly entangled in red tape and incompetence. Even the agency headed by Stalin that was responsible for streamlining administration was, in fact, less efficient than the rest of the government. The Soviets of Workers’ and Peasants’ Deputies had been drained of all power, which had flowed to the centre. Most disturbing was the Great Russian chauvinism that leading Bolsheviks manifested toward the non-Russian nationalities in the reorganization of the state in which Stalin was playing a key role. Moreover, in April 1922 Stalin won appointment as general secretary of the party, in which post he was rapidly concentrating immense power in his hands. Soviet Russia in Lenin’s last years could not have been more remote from the picture of Socialism he had portrayed in State and Revolution. Lenin strained every nerve to reverse these trends, which he regarded as antithetical to Socialism, and to replace Stalin.
1 - In the spring of 1922, however, Lenin fell seriously ill. In April his doctors extracted from his neck one of the bullets he had received from the assassin’s gun in August 1918. He recovered rapidly from the operation, but a month later he fell ill, partially paralyzed and unable to speak. In June he made a partial recovery and threw himself into the formation of the Union of Soviet Socialist Republics, the federal system of reorganization he favoured against Stalin’s unitary scheme. However, in December he was again incapacitated by semiparalysis. Although no longer the active leader of the state and party, he did muster the strength to dictate several prescient articles and what is called his political “Testament,” dictated to his secretary between Dec. 23, 1922, and Jan. 4, 1923, in which he expressed a great fear for the stability of the party under the leadership of disparate, forceful personalities such as Stalin and Trotsky. On March 10, 1923, another stroke deprived him of speech. His political activity came to an end. He suffered yet another stroke on the morning of Jan. 21, 1924, and died that evening in the village of Gorki (now known as Gorki Leninskiye).
1 - The last year of Lenin’s political life, when he fought to eradicate abuses of his Socialist ideals and the corruption of power, may well have been his greatest. Whether the history of the Soviet Union would have been fundamentally different had he survived beyond his 54th birthday, no one can say with certainty.

2 - Noam Chomsky (born December 7, 1928, Philadelphia, Pennsylvania, U.S.) is an American theoretical linguist whose work from the 1950s revolutionized the field of linguistics by treating language as a uniquely human, biologically based cognitive capacity. Through his contributions to linguistics and related fields, including cognitive psychology and the philosophies of mind and language, Chomsky helped to initiate and sustain what came to be known as the “cognitive revolution.” Chomsky also gained a worldwide following as a political dissident for his analyses of the pernicious influence of economic elites on U.S. domestic politics, foreign policy, and intellectual culture.
2 - Born into a middle-class Jewish family, Chomsky attended an experimental elementary school in which he was encouraged to develop his own interests and talents through self-directed learning. When he was 10 years old, he wrote an editorial for his school newspaper lamenting the fall of Barcelona in the Spanish Civil War and the rise of fascism in Europe. His research then and during the next few years was thorough enough to serve decades later as the basis of “Objectivity and Liberal Scholarship” (1969), Chomsky’s critical review of a study of the period by the historian Gabriel Jackson.
2 - When he was 13 years old, Chomsky began taking trips by himself to New York City, where he found books for his voracious reading habit and made contact with a thriving working-class Jewish intellectual community. Discussion enriched and confirmed the beliefs that would underlie his political views throughout his life: that all people are capable of comprehending political and economic issues and making their own decisions on that basis; that all people need and derive satisfaction from acting freely and creatively and from associating with others; and that authority—whether political, economic, or religious—that cannot meet a strong test of rational justification is illegitimate. According to Chomsky’s anarchosyndicalism, or libertarian socialism, the best form of political organization is one in which all people have a maximal opportunity to engage in cooperative activity with others and to take part in all decisions of the community that affect them.
2 - In 1945, at the age of 16, Chomsky entered the University of Pennsylvania but found little to interest him. After two years he considered leaving the university to pursue his political interests, perhaps by living on a kibbutz. He changed his mind, however, after meeting the linguist Zellig S. Harris, one of the American founders of structural linguistics, whose political convictions were similar to Chomsky’s. Chomsky took graduate courses with Harris and, at Harris’s recommendation, studied philosophy with Nelson Goodman and Nathan Salmon and mathematics with Nathan Fine, who was then teaching at Harvard University. In his 1951 master’s thesis, The Morphophonemics of Modern Hebrew, and especially in The Logical Structure of Linguistic Theory (LSLT), written while he was a junior fellow at Harvard (1951–55) and published in part in 1975, Chomsky adopted aspects of Harris’s approach to the study of language and of Goodman’s views on formal systems and the philosophy of science and transformed them into something novel.
2 - Whereas Goodman assumed that the mind at birth is largely a tabula rasa (blank slate) and that language learning in children is essentially a conditioned response to linguistic stimuli, Chomsky held that the basic principles of all languages, as well as the basic range of concepts they are used to express, are innately represented in the human mind and that language learning consists of the unconscious construction of a grammar from these principles in accordance with cues drawn from the child’s linguistic environment. Whereas Harris thought of the study of language as the taxonomic classification of “data,” Chomsky held that it is the discovery, through the application of formal systems, of the innate principles that make possible the swift acquisition of language by children and the ordinary use of language by children and adults alike. And whereas Goodman believed that linguistic behaviour is regular and caused (in the sense of being a specific response to specific stimuli), Chomsky argued that it is incited by social context and discourse context but essentially uncaused—enabled by a distinct set of innate principles but innovative, or “creative.” It is for this reason that Chomsky believed that it is unlikely that there will ever be a full-fledged science of linguistic behaviour. As in the view of the 17th-century French philosopher Réne Descartes, according to Chomsky, the use of language is due to a “creative principle,” not a causal one.
2 - Harris ignored Chomsky’s work, and Goodman—when he realized that Chomsky would not accept his behaviourism—denounced it. Their reactions, with some variations, were shared by a large majority of linguists, philosophers, and psychologists. Although some linguists and psychologists eventually came to accept Chomsky’s basic assumptions regarding language and the mind, most philosophers continued to resist them.
2 - Chomsky received a Ph.D. in linguistics from the University of Pennsylvania in 1955 after submitting one chapter of LSLT as a doctoral dissertation (Transformational Analysis). In 1956 he was appointed by the Massachusetts Institute of Technology (MIT) to a teaching position that required him to spend half his time on a machine translation project, though he was openly skeptical of its prospects for success (he told the director of the translation laboratory that the project was of “no intellectual interest and was also pointless”). Impressed with his book Syntactic Structures (1957), a revised version of a series of lectures he gave to MIT undergraduates, the university asked Chomsky and his colleague Morris Halle to establish a new graduate program in linguistics, which soon attracted several outstanding scholars, including Robert Lees, Jerry Fodor, Jerold Katz, and Paul Postal.
2 - Chomsky’s 1959 review of Verbal Behavior, by B.F. Skinner, the dean of American behaviourism, came to be regarded as the definitive refutation of behaviourist accounts of language learning. Starting in the mid-1960s, with the publication of Aspects of the Theory of Syntax (1965) and Cartesian Linguistics (1966), Chomsky’s approach to the study of language and mind gained wider acceptance within linguistics, though there were many theoretical variations within the paradigm. Chomsky was appointed full professor at MIT in 1961, Ferrari P. Ward Professor of Modern Languages and Linguistics in 1966, and Institute Professor in 1976. He retired from MIT as professor emeritus in 2002. Fifteen years later, in 2017, he became a laureate professor of linguistics at the University of Arizona.
2 - A fundamental insight of philosophical rationalism is that human creativity crucially depends on an innate system of concept generation and combination. According to Chomsky, children display “ordinary” creativity—appropriate and innovative use of complexes of concepts—from virtually their first words. With language, they bring to bear thousands of rich and articulate concepts when they play, invent, and speak to and understand each other. They seem to know much more than they have been taught—or even could be taught. Such knowledge, therefore, must be innate in some sense. To say it is innate, however, is not to say that the child is conscious of it or even that it exists, fully formed, at birth. It is only to say that it is produced by the child’s system of concept generation and combination, in accordance with the system’s courses of biological and physical development, upon their exposure to certain kinds of environmental input.
2 - It has frequently been observed that children acquire both concepts and language with amazing facility and speed, despite the paucity or even absence of meaningful evidence and instruction in their early years. The inference to the conclusion that much of what they acquire must be innate is known as the argument from the “poverty of the stimulus.” Specifying precisely what children acquire and how they acquire it are aspects of what Chomsky called in LSLT the “fundamental problem” of linguistics. In later work he referred to this as “Plato’s problem,” a reference to Plato’s attempt (in his dialogue the Meno) to explain how it is possible for an uneducated child to solve geometrical problems with appropriate prompting but without any specific training or background in mathematics. Unlike Plato, however, Chomsky held that solving Plato’s problem is a task for natural science, specifically cognitive science and linguistics.
2 - Chomsky’s early attempts to solve the linguistic version of Plato’s problem were presented in the “standard theory” of Aspects of the Theory of Syntax and the subsequent “extended standard theory,” which was developed and revised through the late 1970s. These theories proposed that the mind of the human infant is endowed with a “format” of a possible grammar (a theory of linguistic data), a method of constructing grammars based on the linguistic data to which the child is exposed, and a device that evaluates the relative simplicity of constructed grammars. The child’s mind constructs a number of possible grammars that are consistent with the linguistic data and then selects the grammar with the fewest rules or primitives. Although ingenious, this approach was cumbersome in comparison with later theories, in part because it was not clear exactly what procedures would have to be involved in the construction and evaluation of grammars.
2 - In the late 1970s and early 1980s Chomsky and others developed a better solution using a theoretical framework known as “principles and parameters” (P&P), which Chomsky introduced in Lectures on Government and Binding (1981) and elaborated in Knowledge of Language (1986). Principles are linguistic universals, or structural features that are common to all natural languages; hence, they are part of the child’s native endowment. Parameters, also native (though not necessarily specific to language, perhaps figuring elsewhere too), are options that allow for variation in linguistic structure. The P&P approach assumed that these options are readily set upon the child’s exposure to a minimal amount of linguistic data, a hypothesis that has been supported by empirical evidence. One proposed principle, for example, is that phrase structure must consist of a head, such as a noun or a verb, and a complement, which can be a phrase of any form. The order of head and complement, however, is not fixed: languages may have a head-initial structure, as in the English verb phrase (VP) “wash the clothes,” or a “head-final” structure, as in the corresponding Japanese VP “the clothes wash.” Thus, one parameter that is set through the child’s exposure to linguistic data is “head-initial/head-final.” The setting of what was thought, during the early development of P&P, to be a small number of parametric options within the constraints provided by a sufficiently rich set of linguistic principles would, according to this approach, yield a grammar of the specific language to which the child is exposed. Later the introduction of “microparameters” and certain nonlinguistic constraints on development complicated this simple story, but the basic P&P approach remained in place, offering what appears to be the best solution to Plato’s problem yet proposed.
2 - The phonological, or sound-yielding, features of languages are also parameterized, according to the P&P approach. They are usually set early in development—apparently within a few days—and they must be set before the child becomes too old if he is to be able to pronounce the language without an accent. This time limit on phonological parameter setting would explain why second-language learners rarely, if ever, sound like native speakers. In contrast, young children exposed to any number of additional languages before the time limit is reached have no trouble producing the relevant sounds.
2 - In contrast to the syntactic and phonological features of language, the basic features out of which lexically expressed concepts (and larger units of linguistic meaning) are constructed do not appear to be parameterized: different natural languages seem to rely on the same set. Even if semantic features were parameterized, however, a set of features detailed enough to provide (in principle) for hundreds of thousands of root, or basic, concepts would have to be a part of the child’s innate, specifically linguistic endowment—what Chomsky calls Universal Grammar, or UG—or of his nonlinguistic endowment—the innate controls on growth, development, and the final states of other systems in the mind or brain. This is indicated, as noted above, by the extraordinary rate at which children acquire lexical concepts (about one per waking hour between the ages of two and eight) and the rich knowledge that each concept and its verbal, nominal, adverbial, and other variants provide. No training or conscious intervention plays a role; lexical acquisition seems to be as automatic as parameter setting.
2 - Of course, people differ in the words contained in their vocabularies and in the particular sounds they happen to associate with different concepts. Early in the 20th century, the Swiss linguist Ferdinand de Saussure noted that there is nothing natural or necessary about the specific sounds with which a concept may be associated in a given language. According to Chomsky, this “Saussurean arbitrariness” is of no interest to the natural scientist of language, because sound-concept associations in this sense are not a part of UG or of other nonlinguistic systems that contribute to concept (and sound) development.
2 - A developed theory of UG and of relevant nonlinguistic systems would in principle account for all possible linguistic sounds and all possible lexical concepts and linguistic meanings, for it would contain all possible phonological and semantic features and all the rules and constraints for combining phonological and semantic features into words and for combining words into a potentially infinite number of phrases and sentences. Of course, such a complete theory may never be fully achieved, but in this respect linguistics is no worse off than physics, chemistry, or any other science. They too are incomplete.
2 - It is important to notice that the semantic features that constitute lexical concepts, and the rules and constraints governing their combination, seem to be virtually designed for use by human beings—i.e., designed to serve human interests and to solve human problems. For example, concepts such as “give” and “village” have features that reflect human actions and interests: transfer of ownership (and much more) is part of the meaning of give, and polity (both abstract and concrete) is part of the meaning of village. Linguists and philosophers sympathetic to empiricism will object that these features are created when a community “invents” a language to do the jobs it needs to do—no wonder, then, that linguistic meanings reflect human interests and problems. The rationalist, in contrast, argues that humans could not even conceive of these interests and problems unless the necessary conceptual machinery were available beforehand. In Chomsky’s view, the speed and facility with which children learn “give” and “village” and many thousands of other concepts show that the empiricist approach is incorrect—though it may be correct in the case of scientific concepts, such as “muon,” which apparently are not innate and do not reflect human concerns.
2 - The overall architecture of the language faculty also helps to explain how conceptual and linguistic creativity is possible. In the P&P framework in its later “minimalist” forms (see below Rule systems in Chomskyan theories of language), the language faculty has “interfaces” that allow it to communicate with other parts of the mind. The information it provides through “sensorimotor” interfaces enables humans to produce and perceive speech and sign language, and the information it provides through “conceptual-intentional” interfaces enables humans to perform numerous cognitive tasks, ranging from categorization (“that’s a lynx”) to understanding and producing stories and poetry.
2 - Chomsky’s theories of grammar and language are often referred to as “generative,” “transformational,” or “transformational-generative.” In a mathematical sense, “generative” simply means “formally explicit.” In the case of language, however, the meaning of the term typically also includes the notion of “productivity”—i.e., the capacity to produce an infinite number of grammatical phrases and sentences using only finite means (e.g., a finite number of principles and parameters and a finite vocabulary). In order for a theory of language to be productive in this sense, at least some of its principles or rules must be recursive. A rule or series of rules is recursive if it is such that it can be applied to its own output an indefinite number of times, yielding a total output that is potentially infinite. A simple example of a recursive rule is the successor function in mathematics, which takes a number as input and yields that number plus 1 as output. If one were to start at 0 and apply the successor function indefinitely, the result would be the infinite set of natural numbers. In grammars of natural languages, recursion appears in various forms, including in rules that allow for concatenation, relativization, and complementization, among other operations.
2 - Chomsky’s theories are “transformational” in the sense that they account for the syntactic and semantic properties of sentences by means of modifications of the structure of a phrase in the course of its generation. The standard theory of Syntactic Structures and especially of Aspects of the Theory of Syntax employed a phrase-structure grammar—a grammar in which the syntactic elements of a language are defined by means of rewrite rules that specify their smaller constituents (e.g., “S → NP + VP,” or “a sentence may be rewritten as a noun phrase and a verb phrase”)—a large number of “obligatory” and “optional” transformations, and two levels of structure: a “deep structure,” where semantic interpretation takes place, and a “surface structure,” where phonetic interpretation takes place. These early grammars were difficult to contrive, and their complexity and language-specificity made it very difficult to see how they could constitute a solution to Plato’s problem.
2 - In Chomsky’s later theories, deep structure ceased to be the locus of semantic interpretation. Phrase-structure grammars too were virtually eliminated by the end of the 1970s; the task they performed was taken over by the operation of “projecting” individual lexical items and their properties into more complex structures by means of “X-bar theory.” Transformations during this transitional period were reduced to a single operation, “Move α” (“Move alpha”), which amounted to “move any element in a derivation anywhere”—albeit within a system of robust constraints. Following the introduction of the “minimalist program” (MP) in the early 1990s, deep structure (and surface structure) disappeared altogether. Move α, and thus modification of structure from one derivational step to another, was replaced by “Move” and later by “internal Merge,” a variant of “external Merge,” itself a crucial basic operation that takes two elements (such as words) and makes of them a set. In the early 21st century, internal and external Merge, along with parameters and microparameters, remained at the core of Chomsky’s efforts to construct grammars.
2 - Throughout the development of these approaches to the science of language, there were continual improvements in simplicity and formal elegance in the theories on offer; the early phrase-structure components, transformational components, and deep and surface structures were all eliminated, replaced by much simpler systems. Indeed, an MP grammar for a specific language could in principle consist entirely of Merge (internal and external) together with some parametric settings. MP aims to achieve both of the major original goals that Chomsky set for a theory of language in Aspects of the Theory of Syntax: that it be descriptively adequate, in the sense that the grammars it provides generate all and only the grammatical expressions of the language in question, and that it be explanatorily adequate, in the sense that it provides a descriptively adequate grammar for any natural language as represented in the mind of a given individual. MP grammars thus provide a solution to Plato’s problem, explaining how any individual readily acquires what Chomsky calls an “I-language”—“I” for internal, individual, and intensional (that is, described by a grammar). But they also speak to other desiderata of a natural science: they are much simpler, and they are much more easily accommodated to another science, namely biology.
2 - Human conceptual and linguistic creativity involves several mental faculties and entails the existence of some kind of mental organization. It depends on perceptual-articulatory systems and conceptual-intentional systems, of course, but on many others too, such as vision. According to Chomsky, the mind comprises an extensive cluster of innate “modules,” one of which is language. Each module operates automatically, independently of individual control, on the basis of a distinct, domain-specific set of rules that take determinate inputs from some modules and yield determinate outputs for others. In earlier work these operations were called “derivations”; more recently they have been called “computations.” The various modules interact in complex ways to yield perception, thought, and a large number of other cognitive products.
2 - The language module seems to play a role in coordinating the products of other modules. The generative—specifically, recursive—properties of language enable humans to combine arbitrary concepts together in indefinitely many ways, thereby making the range of human thought virtually unlimited. When concepts are paired with sounds in lexical items (words), humans can say virtually anything and cooperate and make plans with each other. The fact that the language faculty yields this kind of flexibility suggests that the emergence of language in human evolutionary history coincided with the appearance of other cognitive capacities based on recursion, including quantification.
2 - As suggested earlier, UG, or the language faculty narrowly understood (FLN), may consist entirely of Merge and perhaps some parameters specific to language. This raises the question of what the biological basis of FLN must be. What distinctive fact of human biology, or the human genome, makes FLN unique to humans? In a 2005 article, “Three Factors in Language Design,” Chomsky pointed out that there is more to organic development and growth than biological (genomic) specification and environmental input. A third factor is general conditions on growth resulting from restrictions on possible physical structures and restrictions on data analysis, including those that might figure in computational systems (such as language). For example, a bee’s genome does not have to direct it to build hives in a hexagonal lattice. The lattice is a requirement imposed by physics, since this structure is the most stable and efficient of the relevant sort. Analogous points can be made about the growth, structure, and operation of the human brain. If the parameters of UG are not specified by the language-specific parts of the human genome but are instead the result of third factors, the only language-specific information that the genome would need to carry is an instruction set for producing a single principle, Merge (which takes external and internal forms). And if this is the case, then the appearance of language could have been brought about by a single genetic mutation in a single individual, so long as that mutation were transmissible to progeny. Obviously, the relevant genes would provide great advantages to any human who possessed them. A saltational account such as this has some evidence behind it: 50,000 to 100,000 years ago, humans began to observe the heavens, to draw and paint, to wonder, and to develop explanations of natural phenomena—and the migration from Africa began. Plausibly, the introduction of the computational system of language led to this remarkable cognitive awakening.
2 - Chomsky’s political views seem to be supported to some extent by his approach to the study of language and mind, which implies that the capacity for creativity is an important element of human nature. Chomsky often notes, however, that there is only an “abstract” connection between his theories of language and his politics. A close connection would have to be based on a fully developed science of human nature, through which fundamental human needs could be identified or deduced. But there is nothing like such a science. Even if there were, the connection would additionally depend on the assumption that the best form of political organization is one that maximizes the satisfaction of human needs. And then there would remain the question of what practical measures should be implemented to satisfy those needs. Clearly, questions such as this cannot be settled by scientific means.
2 - Although Chomsky was always interested in politics, he did not become publicly involved in it until 1964, when he felt compelled to lend his voice to protests against the U.S. role in the Vietnam War (or, as he prefers to say, the U.S. invasion of Vietnam), at no small risk to his career and his personal safety. He has argued that the Vietnam War was only one in a series of cases in which the United States used its military power to gain or consolidate economic control over increasingly larger areas of the developing world. In the same vein, he regards the domestic political scene of the United States and other major capitalist countries as theatres in which major corporations and their elite managers strive to protect and enhance their economic privileges and political power.
2 - In democracies like the United States, in which the compliance of ordinary citizens cannot be guaranteed by force, this effort requires a form of “propaganda”: the powerful must make ordinary citizens believe that vesting economic control of society in the hands of a tiny minority of the population is to their benefit. Part of this project involves enlisting the help of “intellectuals”—the class of individuals (primarily journalists and academics) who collect, disseminate, and interpret political and economic information for the public. Regrettably, Chomsky argues, this task has proved remarkably easy.
2 - As a responsible (rather than mercenary) member of the intellectual class, Chomsky believes that it is his obligation to provide ordinary citizens with the information they needed to draw their own conclusions and to make their own decisions about vital political and economic issues. As he wrote in Powers and Prospects (1996),
2 - In one of his first political essays, “The Responsibility of Intellectuals” (1967), Chomsky presented case after case in which intellectuals in positions of power, including prominent journalists, failed to tell the truth or deliberately lied to the public in order to conceal the aims and consequences of the United States’ involvement in the Vietnam War. In their two-volume work The Political Economy of Human Rights (1979) and later in Manufacturing Consent: The Political Economy of the Mass Media (1988), Chomsky and the economist Edward Herman analyzed the reporting of journalists in the mainstream (i.e., corporate-owned) media on the basis of statistically careful studies of historical and contemporary examples. Their work provided striking evidence of selection, skewing of data, filtering of information, and outright invention in support of assumptions that helped to justify the controlling influence of corporations in U.S. foreign policy and domestic politics.
2 - The studies in these and other works made use of paired examples to show how very similar events can be reported in very different ways, depending upon whether and how state and corporate interests may be affected. In The Political Economy of Human Rights, for example, Chomsky and Herman compared reporting on Indonesia’s military invasion and occupation of East Timor with reporting on the behaviour of the communist Khmer Rouge regime in Cambodia. The events in the two cases took place in approximately the same part of the world and at approximately the same time (the mid- to late 1970s). As a proportion of population, the number of East Timorese tortured and murdered by the Indonesian military was approximately the same as the number of Cambodians tortured and murdered by the Khmer Rouge. And yet the mainstream media in the United States devoted much more attention to the second case (more than 1,000 column inches in the New York Times) than to the first (about 70 column inches). Moreover, reporting on the actions of the Khmer Rouge contained many clear cases of exaggeration and fabrication, whereas reporting on the actions of Indonesia portrayed them as essentially benign. In the case of the Khmer Rouge, however, exaggerated reports of atrocities aided efforts by the United States to maintain the Cold War and to protect and expand its access to the region’s natural resources (including East Timorese oil deposits) through client states. Indonesia, on the other hand, was just such a state, heavily supported by U.S. military and economic aid. Although ordinary Americans were not in a position to do anything about the Khmer Rouge, they were capable of doing something about their country’s support for Indonesia, in particular by voting their government out of office. But the media’s benign treatment of the invasion made it extremely unlikely that they would be motivated to do so. According to Chomsky, this and many other examples demonstrate that prominent journalists and other intellectuals in the United States function essentially as “commissars” on behalf of elite interests. As he wrote in Necessary Illusions (1988):
2 - Some of Chomsky’s critics have claimed that his political and media studies portray journalists as actively engaged in a kind of conspiracy—an extremely unlikely conspiracy, of course, given the degree of coordination and control it would require. Chomsky’s response is simply that the assumption of conspiracy is unnecessary. The behaviour of journalists in the mainstream media is exactly what one would expect, on average, given the power structure of the institutions in which they are employed, and it is predictable in the same sense and for the same reasons that the behaviour of the president of General Motors is predictable. In order to succeed—in order to be hired and promoted—media personnel must avoid questioning the interests of the corporations they work for or the interests of the elite minority who run those corporations. Because journalists naturally do not wish to think of themselves as mercenaries (no one does), they engage in what amounts to a form of self-deception. They typically think of themselves as stalwart defenders of the truth (as suggested by the slogan of the New York Times, “All the news that’s fit to print”), but when state or corporate interests are at stake they act otherwise, in crucially important ways. In short, very few of them are willing or even able to live up to their responsibility as intellectuals to bring the truth about matters of human significance to an audience that can do something about them.

3 - Napoleon I (born August 15, 1769, Ajaccio, Corsica—died May 5, 1821, St. Helena Island) was a French general, first consul (1799–1804), and emperor of the French (1804–1814/15), one of the most celebrated personages in the history of the West. He revolutionized military organization and training; sponsored the Napoleonic Code, the prototype of later civil-law codes; reorganized education; and established the long-lived Concordat with the papacy.
3 - Napoleon’s many reforms left a lasting mark on the institutions of France and of much of western Europe. But his driving passion was the military expansion of French dominion, and, though at his fall he left France little larger than it had been at the outbreak of the Revolution in 1789, he was almost unanimously revered during his lifetime and until the end of the Second Empire under his nephew Napoleon III as one of history’s great heroes.
3 - Napoleon was born on Corsica shortly after the island’s cession to France by the Genoese. He was the fourth, and second surviving, child of Carlo Buonaparte, a lawyer, and his wife, Letizia Ramolino. His father’s family, of ancient Tuscan nobility, had emigrated to Corsica in the 16th century.
3 - Carlo Buonaparte had married the beautiful and strong-willed Letizia when she was only 14 years old; they eventually had eight children to bring up in very difficult times. The French occupation of their native country was resisted by a number of Corsicans led by Pasquale Paoli. Carlo Buonaparte joined Paoli’s party, but, when Paoli had to flee, Buonaparte came to terms with the French. Winning the protection of the governor of Corsica, he was appointed assessor for the judicial district of Ajaccio in 1771. In 1778 he obtained the admission of his two eldest sons, Joseph and Napoleon, to the Collège d’Autun.
3 - A Corsican by birth, heredity, and childhood associations, Napoleon continued for some time after his arrival in Continental France to regard himself a foreigner; yet from age nine he was educated in France as other Frenchmen were. While the tendency to see in Napoleon a reincarnation of some 14th-century Italian condottiere is an overemphasis on one aspect of his character, he did, in fact, share neither the traditions nor the prejudices of his new country: remaining a Corsican in temperament, he was first and foremost, through both his education and his reading, a man of the 18th century.
3 - Napoleon was educated at three schools: briefly at Autun, for five years at the military college of Brienne, and finally for one year at the military academy in Paris. It was during Napoleon’s year in Paris that his father died of a stomach cancer in February 1785, leaving his family in straitened circumstances. Napoleon, although not the eldest son, assumed the position of head of the family before he was 16. In September he graduated from the military academy, ranking 42nd in a class of 58.
3 - He was made second lieutenant of artillery in the regiment of La Fère, a kind of training school for young artillery officers. Garrisoned at Valence, Napoleon continued his education, reading much, in particular works on strategy and tactics. He also wrote Lettres sur la Corse (“Letters on Corsica”), in which he reveals his feeling for his native island. He went back to Corsica in September 1786 and did not rejoin his regiment until June 1788. By that time the agitation that was to culminate in the French Revolution had already begun. A reader of Voltaire and of Rousseau, Napoleon believed that a political change was imperative, but, as a career officer, he seems not to have seen any need for radical social reforms.
3 - When in 1789 the National Assembly, which had convened to establish a constitutional monarchy, allowed Paoli to return to Corsica, Napoleon asked for leave and in September joined Paoli’s group. But Paoli had no sympathy for the young man, whose father had deserted his cause and whom he considered to be a foreigner. Disappointed, Napoleon returned to France, and in April 1791 he was appointed first lieutenant to the 4th regiment of artillery, garrisoned at Valence. He at once joined the Jacobin Club, a debating society initially favouring a constitutional monarchy, and soon became its president, making speeches against nobles, monks, and bishops. In September 1791 he got leave to go back to Corsica again for three months. Elected lieutenant colonel in the national guard, he soon fell out with Paoli, its commander in chief. When he failed to return to France, he was listed as a deserter in January 1792. But in April France declared war against Austria, and his offense was forgiven.
3 - Apparently through patronage, Napoleon was promoted to the rank of captain but did not rejoin his regiment. Instead he returned to Corsica in October 1792, where Paoli was exercising dictatorial powers and preparing to separate Corsica from France. Napoleon, however, joined the Corsican Jacobins, who opposed Paoli’s policy. When civil war broke out in Corsica in April 1793, Paoli had the Buonaparte family condemned to “perpetual execration and infamy,” whereupon they all fled to France.
3 - Napoleon Bonaparte, as he may henceforth be called (though the family did not drop the spelling Buonaparte until after 1796), rejoined his regiment at Nice in June 1793. In his Le Souper de Beaucaire (Supper at Beaucaire), written at this time, he argued vigorously for united action by all republicans rallied round the Jacobins, who were becoming progressively more radical, and the National Convention, the Revolutionary assembly that in the preceding fall had abolished the monarchy.
3 - At the end of August 1793, the National Convention’s troops had taken Marseille but were halted before Toulon, where the royalists had called in British forces. With the commander of the National Convention’s artillery wounded, Bonaparte got the post through the commissioner to the army, Antoine Saliceti, who was a Corsican deputy and a friend of Napoleon’s family. Bonaparte was promoted to major in September and adjutant general in October. He received a bayonet wound on December 16, but on the next day the British troops, harassed by his artillery, evacuated Toulon. On December 22 Bonaparte, age 24, was promoted to brigadier general in recognition of his decisive part in the capture of the town.
3 - Augustin de Robespierre, the commissioner to the army, wrote to his brother Maximilien, by then virtual head of the government and one of the leading figures of the Reign of Terror, praising the “transcendent merit” of the young republican officer. In February 1794 Bonaparte was appointed commandant of the artillery in the French Army of Italy. Robespierre fell from power in Paris on 9 Thermidor, year II (July 27, 1794). When the news reached Nice, Bonaparte, regarded as a protégé of Robespierre, was arrested on a charge of conspiracy and treason. He was freed in September but was not restored to his command.
3 - The following March he refused an offer to command the artillery in the Army of the West, which was fighting the counterrevolution in the Vendée. The post seemed to hold no future for him, and he went to Paris to justify himself. Life was difficult on half pay, especially as he was carrying on an affair with Désirée Clary, daughter of a rich Marseille businessman and sister of Julie, the bride of his elder brother, Joseph. Despite his efforts in Paris, Napoleon was unable to obtain a satisfactory command, because he was feared for his intense ambition and for his relations with the Montagnards, the more radical members of the National Convention. He then considered offering his services to the sultan of Turkey.
3 - Bonaparte was still in Paris in October 1795 when the National Convention, on the eve of its dispersal, submitted the new constitution of the year III of the First Republic to a referendum, together with decrees according to which two-thirds of the members of the National Convention were to be reelected to the new legislative assemblies. The royalists, hoping that they would soon be able to restore the monarchy, instigated a revolt in Paris to prevent these measures from being put into effect. Paul Barras, who had been entrusted with dictatorial powers by the National Convention, was unwilling to rely on the commander of the troops of the interior; instead, knowing of Bonaparte’s services at Toulon, he appointed him second in command. Thus, it was Napoleon who shot down the columns of rebels marching against the National Convention (13 Vendémiaire year IV; October 5, 1795), thereby saving the National Convention and the republic.
3 - Bonaparte became commander of the Army of the Interior and, consequently, was henceforth aware of every political development in France. He became the respected adviser on military matters to the new government, the Directory. Also at this time, he came to know an attractive Creole, Joséphine Tascher de La Pagerie, who was the widow of General Alexandre de Beauharnais (guillotined during the Reign of Terror), the mother of two children, and a woman of many love affairs.
3 - From every point of view, a new life was opening for Bonaparte. Having proved his loyalty to the Directory, he was appointed commander in chief of the Army of Italy in March 1796. He had been trying to obtain that post for several weeks so that he could personally conduct part of the plan of campaign adopted by the Directory on his advice. He married Joséphine on March 9 and left for the army two days later.
3 - From every point of view, a new life was opening for Bonaparte. Having proved his loyalty to the Directory, he was appointed commander in chief of the Army of Italy in March 1796. He had been trying to obtain that post for several weeks so that he could personally conduct part of the plan of campaign adopted by the Directory on his advice. He married Joséphine on March 9 and left for the army two days later.
3 - He took the offensive on April 12 and successively defeated and separated the Austrian and the Sardinian armies and then marched on Turin. King Victor Amadeus III of Sardinia asked for an armistice; and, at the peace treaty in Paris on May 15, Nice and Savoy, occupied by the French since 1792, were annexed to France. Bonaparte continued the war against the Austrians and occupied Milan but was held up at Mantua. While his army was besieging this great fortress, he signed armistices with the duke of Parma, with the duke of Modena, and finally with Pope Pius VI.
3 - At the same time, he took an interest in the political organization of Italy. A plan for its “republicanization” by a group of Italian “patriots” led by Filippo Buonarroti had to be shelved when Buonarroti was arrested for complicity in François-Noël Babeuf’s conspiracy against the Directory. Thereafter, Bonaparte, without discarding the Italian patriots altogether, restricted their freedom of action. He set up a republican regime in Lombardy but kept a close watch on its leaders, and in October 1796 he created the Cisalpine Republic by merging Modena and Reggio nell’Emilia with the papal states of Bologna and Ferrara occupied by the French army. Then he sent an expedition to recover Corsica, which the British had evacuated.
3 - Austrian armies advanced four times from the Alps to relieve Mantua but were defeated each time by Bonaparte. After the last Austrian defeat, at Rivoli in January 1797, Mantua capitulated. Next he marched on Vienna. He was about 60 miles (100 km) from that capital when the Austrians sued for an armistice. By the preliminaries of peace, Austria ceded the southern Netherlands to France and recognized the Lombard republic but received in exchange some territory belonging to the old Republic of Venice, which was partitioned between Austria, France, and Lombardy. Bonaparte then consolidated and reorganized the northern Italian republics and encouraged Jacobin—radical republican—propaganda in Venetia. Some Italian patriots hoped that these developments would soon lead to the formation of a single and indivisible “Italian Republic” modeled on the French.
3 - Meanwhile, Bonaparte grew uneasy at the successes of the royalists in the French elections in the spring of 1797 and advised the Directory to oppose them, if necessary, by force. He sent General Pierre Augereau to Paris, along with several officers and men to back the coup d’état of 18 Fructidor, year V (September 4, 1797), which eliminated the royalists’ friends from the government and legislative councils and also enhanced Bonaparte’s prestige. Thus, Bonaparte could conclude the Treaty of Campo Formio with Austria as he thought best. The Directory was displeased, however, because the treaty ceded Venice to the Austrians and did not secure the left bank of the Rhine for France. On the other hand, it raised Bonaparte’s popularity to its peak, for he had gained victory for France after five years of war on the Continent.
3 - Only the war at sea, against the British, continued. The directors, who wanted to launch an invasion of the British Isles, appointed Bonaparte to command the army assembled for this purpose along the English Channel. After a rapid inspection in February 1798, he announced that the operation could not be undertaken until France had command of the sea. Instead, he suggested that France strike at the sources of Great Britain’s wealth by occupying Egypt and threatening the route to India. This proposal, seconded by Charles-Maurice de Talleyrand, the foreign minister, was accepted by the directors, who were glad to get rid of their ambitious young general.
3 - The expedition, thanks to some fortunate coincidences, was at first a great success: Malta, the great fortress of the Hospitallers, was occupied on June 10, 1798, Alexandria taken by storm on July 1, and all of the delta of the Nile rapidly overrun. On August 1, however, the French squadron at anchor in Abū Qīr Bay was completely destroyed by Admiral Horatio Nelson’s fleet in the Battle of the Nile, so that Napoleon found himself confined to the land that he had conquered. He proceeded to introduce Western political institutions, administration, and technical skills in Egypt; but Turkey, nominally suzerain over Egypt, declared war on France in September. To prevent a Turkish invasion of Egypt and also perhaps to attempt a return to France by way of Anatolia, Bonaparte marched into Syria in February 1799. His progress northward was halted at Acre, where the British withstood a siege, and in May Bonaparte began a disastrous retreat to Egypt.
3 - The Battle of the Nile showed Europe that Bonaparte was not invincible, and Great Britain, Austria, Russia, and Turkey formed a new coalition against France. The French armies in Italy were defeated in the spring of 1799 and had to abandon the greater part of the peninsula. These defeats led to disturbances in France itself. The coup d’état of 30 Prairial, year VII (June 18, 1799), expelled the men of moderate views from the Directory and brought into it men who were considered Jacobins. Yet the situation remained confused, and one of the new directors, Emmanuel Sieyès, was convinced that only military dictatorship could prevent a restoration of the monarchy: “I am looking for a sabre,” he said. Bonaparte did not take long to make up his mind. He would leave his army and return to France—in order to save the republic, of course, but also to take advantage of the new circumstances and to seize power. The Directory had, in fact, ordered his return, but he had not received the order, so that it was actually in disregard of his instructions that he left Egypt with a few companions on August 22, 1799. Their two frigates surprisingly escaped interception by the British, and Bonaparte arrived in Paris on October 14.
3 - By this time French victories in Switzerland and Holland had averted the danger of invasion, and the counterrevolutionary risings within France had more or less failed. A coup d’état could therefore no longer be justified by any need to save the republic. Sieyès, however, had not given up his project, and now he had his “sabre.” From the end of October he and Bonaparte were in league together planning the coup, and on 18–19 Brumaire, year VIII (November 9–10, 1799), it was carried out: the directors were forced to resign, the members of the legislative councils were dispersed, and a new government, the Consulate, was set up. The three consuls were Bonaparte and two of the directors who had resigned, Sieyès and Pierre-Roger Ducos. But it was Bonaparte who was henceforth the master of France.
3 - Bonaparte, now 30 years old, was thin and short and wore his hair cut close—le petit tondu, the “little crop-head,” as he was called. Not much was known about his personality, but people had confidence in a man who had always been victorious (the Nile and Acre were forgotten) and who had managed to negotiate the brilliant Treaty of Campo Formio. He was expected to bring back peace, to end disorder, and to consolidate the political and social “conquests” of the Revolution. He was indeed exceptionally intelligent, prompt to make decisions, and indefatigably hardworking but also insatiably ambitious. He seemed to be the man of the Revolution because it was due to the Revolution that he had climbed at so early an age to the highest place in the state. He was not to forget it; but, more than a man of the Revolution, he was a man of the 18th century, the most enlightened of the enlightened despots, a true son of Voltaire. He did not believe in the sovereignty of the people, in the popular will, or in parliamentary debate. Yet he put his confidence more in reasoning than in reason and may be said to have preferred “men of talent”—mathematicians, jurists, and statesmen, for instance, however cynical or mercenary they might be—to “technicians” in the true sense of the word. He believed that an enlightened and firm will could do anything if it had the support of bayonets; he despised and feared the masses; and, as for public opinion, he considered that he could mold and direct it as he pleased. He has been called the most “civilian” of generals, but essentially he never ceased to be a soldier.
3 - Bonaparte imposed a dictatorship on France, but its true character was at first disguised by the constitution of the year VIII (4 Nivôse, year VIII; December 25, 1799), drawn up by Sieyès. This constitution did not guarantee the “rights of man” or make any mention of “liberty, equality, and fraternity,” but it did reassure the partisans of the Revolution by proclaiming the irrevocability of the sale of national property and by upholding the legislation against the émigrés. It gave immense powers to the first consul, leaving only a nominal role to his two colleagues. The first consul—namely, Bonaparte—was to appoint ministers, generals, civil servants, magistrates, and the members of the Council of State and even was to have an overwhelming influence in the choice of members for the three legislative assemblies, though their members were theoretically to be chosen by universal suffrage. Submitted to a plebiscite, the constitution won by an overwhelming majority in February 1800.
3 - The Consulate’s work of administrative reform, undertaken at Bonaparte’s instigation, was to be more lasting than the constitution and so more important for France. At the head of the government was the Council of State, created by the first consul and often effectively presided over by him; it was to play an important part both as the source of the new legislation and as an administrative tribunal. At the head of the administration of the départements were the prefects, who carried on the tradition of the intendants of the ancien régime, supervising the application of the laws and acting as the instruments of centralization. The judicial system was profoundly changed: whereas from the beginning of the Revolution judges had been elected, henceforth they were to be nominated by the government, their independence assured by their irremovability from office. The police organization was greatly strengthened. The financial administration was considerably improved: instead of the municipalities, special officials were entrusted with the collecting of direct taxes; the franc was stabilized; and the Banque de France, owned partly by shareholders and partly by the state, was created. Education was transformed into a major public service; secondary education was given a semimilitary organization, and the university faculties were reestablished. Primary education, however, was still neglected.
3 - Bonaparte shared Voltaire’s belief that the people needed a religion. Personally, he was indifferent to religion: in Egypt he had said that he wanted to become a Muslim. Yet he considered that religious peace had to be restored to France. As early as 1796, when he was concluding the armistice in Italy with Pope Pius VI, he had tried to persuade the pope to retract his briefs against the French priests who had accepted the Civil Constitution of the Clergy, which in practice nationalized the church. Pius VII, who succeeded Pius VI in March 1800, was more accommodating than his predecessor, and, 10 months after negotiations were opened with him, the Concordat of 1801 was signed reconciling the church and the Revolution. The pope recognized the French republic and called for the resignation of all former bishops; new prelates were to be designated by the first consul and instituted by the pope; and the sale of the property of the clergy was officially recognized by Rome. The concordat, in fact, admitted freedom of worship and the lay character of the state.
3 - The codification of the civil law, first undertaken in 1790, was at last completed under the Consulate. The code, promulgated on March 21, 1804, and later known as the Napoleonic Code, gave permanent form to the great gains of the Revolution: individual liberty, freedom of work, freedom of conscience, the lay character of the state, and equality before the law; but, at the same time, it protected landed property, gave greater liberty to employers, and showed little concern for employees. It maintained divorce but granted only limited legal rights to women.
3 - The army received the most careful attention. The first consul retained in outline the system instituted by the Revolution: recruitment by forced conscription but with the possibility of replacement by substitutes; the mixing of the conscripts with old soldiers; and the eligibility of all for promotion to the highest ranks. Nevertheless, the creation of the Academy of Saint-Cyr to produce infantry officers made it easier for the sons of bourgeois families to pursue a military career. Moreover, the École Polytechnique, founded by the National Convention, was militarized in order to provide officers for the artillery and engineers. Yet Bonaparte was not concerned about introducing new technical inventions into his army. He put his trust in the “legs of his soldiers”: his basic strategic idea was a fast-moving army.
3 - The first consul spent the winter and spring of 1799–1800 reorganizing the army and preparing for an attack on Austria alone, Russia having withdrawn from the anti-French coalition. With his usual quick assessment of the situation, he saw the strategic importance of the Swiss Confederation, from which he would be free to outflank the Austrian armies either in Germany or in Italy as he might see fit. His past successes made him choose Italy. Taking his army across the Great St. Bernard Pass before the snow melted, he appeared unexpectedly behind the Austrian army besieging Genoa. The Battle of Marengo in June gave the French command of the Po valley as far as the Adige, and in December another French army defeated the Austrians in Germany. Austria was forced to sign the Treaty of Lunéville of February 1801, whereby France’s right to the natural frontiers that Julius Caesar had given to Gaul—namely, the Rhine, the Alps, and the Pyrenees—was recognized.
3 - Great Britain alone remained at war with France, but it soon tired of the struggle. Preliminaries of peace, concluded in London in October 1801, put an end to hostilities, and peace was signed at Amiens on March 27, 1802.
3 - General peace was reestablished in Europe. The first consul’s prestige increased still more, and his friends—at his suggestion—proposed that a “token of national gratitude” should be offered to him. In May 1802 it was decided that the French people should vote in referendum on the following question: “Shall Napoleon Bonaparte be consul for life?” In August an overwhelming vote granted him the prolongation of his consulate as well as the right to designate his successor.
3 - Bonaparte’s conception of international peace differed from that of the British, for whom the Treaty of Amiens represented an absolute limit beyond which they were under no circumstances prepared to go. The British even hoped to take back some of the concessions they had been forced to make. For Bonaparte, on the other hand, the Treaty of Amiens marked the starting point for a new French ascendancy. He was, first of all, intent on reserving half of Europe as a market for France without lowering customs duties—to the indignation of British merchants. To revive France’s expansion overseas, he also intended to recover Saint-Domingue (Haiti; governed from 1798 by the black leader Toussaint Louverture), to occupy Louisiana (ceded to France by Spain in 1800), perhaps to reconquer Egypt, and at any rate to extend French influence in the Mediterranean and in the Indian Ocean. In continental Europe he advanced beyond France’s natural frontiers, incorporating Piedmont into France, imposing a more centralized government on the Swiss Confederation, and in Germany compensating the princes dispossessed of territory on the Rhine under the Treaty of Lunéville with shares of the secularized ecclesiastical states.
3 - Great Britain was alarmed by this expansion of France in peacetime and found it scarcely tolerable that one state should command the coastline of the Continent from Genoa to Antwerp. The immediate occasion of Franco-British rupture, however, was the problem of Malta. According to the Treaty of Amiens, the British, who had taken the island on the collapse of the French occupation, should have restored it to the Hospitallers; but the British, on the pretext that the French had not yet evacuated certain Neapolitan ports, refused to leave the island. Franco-British relations became strained, and in May 1803 the British declared war.
3 - In the hope of consolidating his own position, Fouché now suggested to Bonaparte that the best way to discourage conspiracy would be to transform the life consulate into a hereditary empire, which, because of the fact that there would be an heir, would remove all hope of changing the regime by assassination. Bonaparte readily accepted the suggestion, and on May 18, 1804, the empire was proclaimed.
3 - Though there was little change in the organization of the government of France, Napoleon as emperor revived a number of institutions similar to those of the ancien régime. In the first place, he wanted to be consecrated by the pope himself, so that his coronation should be even more impressive than that of the kings of France. Pius VII agreed to come to Paris, and the ceremony, which seemed equally outrageous to royalists and to the old soldiers of the Revolution, took place in Notre-Dame on December 2, 1804. At the last moment, the emperor took the crown from the pope and set it on his own head himself.
3 - The imperial regime also instituted its symbols and titles. Princely titles were brought back for the members of Napoleon’s family in 1804, and an imperial nobility was created in 1808. As opposition was still lively, Napoleon intensified his propaganda and imposed an increasingly strict censorship on the press. A dictatorial regime allowed him to carry on his wars for years without worrying about French public opinion. Having been president of the Italian Republic (as the Cisalpine Republic was renamed) since January 1802, Napoleon in March 1805 was proclaimed king of Italy and crowned in Milan in May.
3 - From 1803 to 1805 Napoleon had only the British to fight; and again France could hope for victory only by landing an army in the British Isles, whereas the British could defeat Napoleon only by forming a Continental coalition against him. Napoleon began to prepare an invasion again, this time with greater conviction and on a larger scale. He gathered nearly 2,000 ships between Brest and Antwerp and concentrated his Grand Army in the camp at Boulogne (1803). Even so, the problem was the same as in 1798: to cross the Channel, the French had to have control of the sea.
3 - Still far inferior to the British navy, the French fleet needed the help of the Spanish, and even then the two fleets together could not hope to defeat more than one of the British squadrons. Spain was induced to declare war on Great Britain in December 1804, and it was decided that French and Spanish squadrons massed in the Antilles should lure a British squadron into these waters and defeat it, thus making the balance roughly equal between the Franco-Spanish navy and the British. A battle in the entrance to the Channel could then be fought with some chance of success.
3 - The plan failed. The French squadron from the Mediterranean, under Admiral Pierre de Villeneuve, found itself alone at the appointed meeting place in the Antilles. Pursued by Nelson and not daring to attack him, it turned back toward Europe and took refuge in Cádiz in July 1805; there the British blockaded it. Accused of cowardice by the angry Napoleon, Villeneuve resolved to run the blockade, with the support of a Spanish squadron; but on October 21, 1805, he was attacked by Nelson off Cape Trafalgar. Nelson was killed in the battle, but the Franco-Spanish fleet was totally destroyed. The British had won a decisive victory, which eliminated the danger of invasion and gave them freedom of movement at sea.
3 - The British had also succeeded in organizing a new anti-French coalition consisting of Austria, Russia, Sweden, and Naples. On July 24, 1805, three months before Trafalgar, Napoleon had ordered the Grand Army from Boulogne to the Danube (thus ruling out an invasion of England even if the French had won at Trafalgar). In the week preceding Trafalgar, the Grand Army won an outstanding victory over the Austrians at Ulm, and on November 13 Napoleon entered Vienna. On December 2, 1805, in his greatest victory, he defeated the combined Austrian and Russian armies in the Battle of Austerlitz. By the Treaty of Pressburg, Austria renounced all influence in Italy and ceded Venetia and Dalmatia to Napoleon, as well as extensive territory in Germany to his protégés Bavaria, Württemberg, and Baden. The French then proceeded to dethrone the Bourbons in the Kingdom of Naples, which was bestowed on Napoleon’s brother Joseph. In July 1806 the Confederation of the Rhine was founded—soon to embrace all of western Germany in a union under French protection.
3 - In September 1806 Prussia entered the war against France, and on October 14 the Prussian armies were defeated at Jena and at Auerstädt. The Russians put up a better resistance at Eylau in February 1807 but were routed at Friedland in June. In Warsaw Napoleon fell in love with Countess Marie Walewska, a Polish patriot who hoped that Napoleon would resurrect her country. Napoleon had a son by her.
3 - The Russian emperor Alexander I could have continued the struggle, but he was tired of the alliance with the British. He met Napoleon at Tilsit, in northern Prussia near the Russian frontier. There, on a raft anchored in the middle of the Nemen River, they signed treaties that created the Grand Duchy of Warsaw from the Polish provinces detached from Prussia and, in effect, divided control of Europe between the emperors, Napoleon taking the west and Alexander the east. Alexander even made a vague promise of a land attack against the British possessions in India.
3 - As Napoleon could no longer think of invading England, he tried to induce capitulation by stifling the British economy. By closing all of Europe to British merchandise, he hoped to bring about a revolt of the British unemployed that could force the government to sue for peace. He forbade all trade with the British Isles, ordered the confiscation of all goods coming from English factories or from the British colonies, and condemned as fair prize not only every British ship but also every ship that had touched the coasts of England or its colonies.
3 - For the blockade to succeed, it had to be enforced rigorously throughout Europe. But, from the beginning, England’s old ally Portugal showed itself reluctant to comply, for the blockade would mean its commercial ruin. Napoleon decided to break down Portuguese opposition by force. Charles IV of Spain let the French troops cross his kingdom, and they occupied Lisbon; but the prolonged presence of Napoleon’s soldiers in the north of Spain led to insurrection. When Charles IV abdicated in favour of his son Ferdinand VII, Napoleon, seeing the opportunity to rid Europe of its last Bourbon rulers, summoned the Spanish royal family to Bayonne in April 1808 and obtained the abdication of both Charles and Ferdinand; they were interned in Talleyrand’s château. After the bloody suppression of an uprising in Madrid, insurrection spread across the whole country, for the Spaniards would not accept Joseph Bonaparte, king of Naples, as their new king.
3 - The subsequent defeat of his forces in Spain and Portugal were sensational blows to Napoleon’s prestige. Soon the Iberian Peninsula, up in arms, became a bridgehead on the Continent for the British. Under the energetic Arthur Wellesley (later 1st duke of Wellington), in command from 1809, the Anglo-Spanish-Portuguese forces were to achieve decisive successes.
3 - At the Congress of Erfurt (September–October 1808), a conference with Alexander I, Napoleon assembled a great concourse of princes to impress the Russian emperor in an attempt to extract promises of help. Whether impressed or not, Alexander would make no definite commitment. Alexander’s refusal, furthermore, was partly prompted by Talleyrand, who had become dismayed by Napoleon’s policies and was already negotiating with the Russian emperor behind his master’s back.
3 - By early 1809, however, with most of the Grand Army thrown into Spain, Napoleon seemed on the point of overcoming the revolt. Then, in April, Austria launched an attack in Bavaria in the hope of rousing all of Germany against the French. Napoleon once again defeated the Habsburgs (July 6) and by the Treaty of Schönbrunn (October 14, 1809) obtained the Illyrian Provinces, thus rounding out the “Continental System.”
3 - In 1810 Napoleon’s fortunes were at their zenith, despite some failures in Spain and Portugal. He considered himself Charlemagne’s heir. He repudiated Joséphine, who had not given him a child, so that he could marry Marie-Louise, daughter of the Austrian emperor Francis I. The birth of a son, the king of Rome, in March 1811 seemed to assure the future of his empire—now at its greatest extent, including not only the Illyrian Provinces but also Etruria (Tuscany), some of the Papal States, Holland, and the German states bordering the North Sea. The empire was surrounded by a ring of vassal states ruled over by the emperor’s relatives: the Kingdom of Westphalia (Jérôme Bonaparte); the Kingdom of Spain (Joseph Bonaparte); the Kingdom of Italy (with Eugène de Beauharnais, Joséphine’s son, as viceroy); the Kingdom of Naples (Joachim Murat, Napoleon’s brother-in-law); and the Principality of Lucca and Piombino (Félix Bacciochi, another brother-in-law). Other territories were closely bound to the empire by treaties: the Swiss Confederation (of which Napoleon was the mediator), the Confederation of the Rhine, and the Grand Duchy of Warsaw. Even Austria seemed bound to France by Napoleon’s marriage to Marie-Louise.
3 - The political map of Europe, which had been so complicated before 1796, was now greatly simplified. Yet the frontiers did not coincide either with geographic features or with “nationalities.” Whatever he may later have said, Napoleon, while he was in power, was not interested in realizing either German or Italian unity. Yet, by reducing the number of states, by pushing the frontiers about, by amalgamating populations, and by propagating institutions like those that the Revolution and nationalism had created in France, he prepared the ground for German and Italian unification. National feeling in Europe, stirred by French ideas and by contact with Frenchmen, in turn gave rise to the first resistance against French domination. From 1809 onward, Spanish guerrillas, supported by British troops, were harassing the French, and the Spanish national Cortes (parliament), convened at Cádiz by the insurrectionaries, in 1812 promulgated a constitution inspired by the ideas of the French Revolution of 1789 and by British institutions.
3 - Since the Congress of Erfurt, the Russian emperor had shown himself less and less inclined to deal with Napoleon as a trusted partner. In the spring of 1812, therefore, Napoleon massed his forces in Poland to intimidate Alexander. After some last attempts at agreement, in late June his Grand Army—about 600,000 men, including contingents extorted from Prussia and from Austria—began to cross the Nemen River. The Russians retreated, adopting a scorched-earth policy. Napoleon’s army did not reach the approaches to Moscow until the beginning of September. The Russian commander in chief, Mikhail I. Kutuzov, engaged it at Borodino on September 7. The fight was savage, bloody, and indecisive, but a week later Napoleon entered Moscow, which the Russians had abandoned. On that same day, a huge fire broke out, destroying the greater part of the town. Moreover, Alexander unexpectedly refused to treat with Napoleon. Withdrawal was necessary, and the premature onset of winter made it disastrous. After the difficult crossing of the Berezina River in November, fewer than 10,000 men fit for combat remained with Napoleon’s main force.
3 - This catastrophe heartened all the peoples of Europe to defy Napoleon. In Germany the news unleashed an outbreak of anti-French demonstrations. The Prussian contingents deserted the Grand Army in December and turned against the French. The Austrians also withdrew their troops and adopted an increasingly hostile attitude, and in Italy the people began to turn their backs on Napoleon.
3 - Even in France, signs of discontent with the regime were becoming more frequent. In Paris a malcontent general, Claude-François de Malet, nearly succeeded in carrying out a coup d’état after announcing on October 23, 1812, that Napoleon had died in Russia. This incident was a major factor in Napoleon’s decision to hasten back to France ahead of the Grand Army. Arriving in Paris on December 18, he proceeded to stiffen the dictatorship, to raise money by various expedients, and to levy new troops.
3 - Thus, in 1813 the forces arrayed against France were no longer armies of mercenaries but were those of nations fighting for their freedom as the French had fought for theirs in 1792 and 1793; and the French themselves, for all their courage, had lost their former enthusiasm. The emperor’s ideal of conquest was no longer that of the nation.
3 - In May 1813 Napoleon won some successes against the Russians and Prussians at the Battles of Lützen and Bautzen, but his decimated army needed reinforcements. The armed mediation of Austria induced Napoleon to agree to an armistice, during which a congress was held at Prague. There Austria proposed very favourable conditions: the French Empire was to return to its natural limits; the Grand Duchy of Warsaw and the Confederation of the Rhine were to be dissolved; and Prussia was to return to its frontiers of 1805. Napoleon made the mistake of hesitating too long. The congress closed on August 10 before his reply arrived, and Austria declared war.
3 - The French were even worse off than in the spring. The allies were gaining new troops every day, as one German contingent after another left Napoleon to go over to the other side. The greatest debacle since Napoleon came to power was the Battle of Leipzig, or “Battle of the Nations” (October 16–19, 1813), in which the Grand Army was torn to shreds. That defeat degenerated fast into collapse. The French armies in Spain, forced to retreat, had been defeated in June, and by October the British were attacking their defenses north of the Pyrenees. In Italy the Austrians took the offensive, crossed the Adige River, and occupied Romagna. Murat, now openly a traitor to the emperor who had made him king of Naples, entered into negotiations with the Viennese court. The Dutch and the Belgians demonstrated against Napoleon.
3 - In January 1814 France was being attacked on all its frontiers. The allies cleverly announced that they were fighting not against the French people but against Napoleon alone, since in November 1813 he had rejected the terms offered by the Austrian foreign minister Klemens, Fürst (prince) von Metternich, which would have preserved the natural frontiers of France. The extraordinary strategic feats achieved by the emperor during the first three months of 1814 with the army of young conscripts were not enough; he could neither defeat the allies, with their overwhelming numerical superiority, nor arouse the majority of the French people from their resentful torpor. The Legislative Assembly and the Senate, formerly so docile, were now asking for peace and for civil and political liberties.
3 - By the Treaty of Chaumont of March 1814, Austria, Russia, Prussia, and Great Britain bound themselves together for 20 years, undertook not to negotiate separately, and promised to continue the struggle until Napoleon was overthrown. When the allied armies arrived before Paris on March 30, Napoleon had moved east to attack their rear guard. The Parisian authorities, no longer overawed by the emperor, lost no time in treating with the allies. As president of the provisional government, Talleyrand proclaimed the deposition of the emperor and, without consulting the French people, began to negotiate with Louis XVIII, the brother of the executed Louis XVI. Napoleon had only reached Fontainebleau when he heard that Paris had capitulated. Persuaded that further resistance was useless, he finally abdicated on April 6.
3 - By the Treaty of Fontainebleau, the allies granted him the island of Elba as a sovereign principality, an annual income of two million francs to be provided by France, and a guard of 400 volunteers. Also he retained the title of emperor. After unsuccessfully trying to poison himself, Napoleon spoke his farewell to his “Old Guard,” and after a hazardous journey, during which he narrowly escaped assassination, he arrived at Elba on May 4.
3 - “I want from now on to live like a justice of the peace,” Napoleon declared on his little island. But a man of such energy and imagination could hardly be expected to resign himself to defeat at age 45.
3 - In France, moreover, the Bourbon Restoration was soon exposed to criticism. Though in 1814 the majority of the French people were tired of the emperor, they had expressed no wish for the return of the Bourbons. They were strongly attached to the essential achievements of the Revolution, and Louis XVIII had come back “in the baggage train of the foreigners” with the last surviving émigrés who had “learnt nothing and forgotten nothing” and whose influence seemed to threaten most of the Revolution’s achievements. The apathy of April 1814 quickly gave way to mistrust. Old hatreds were revived, resistance organized, and conspiracies formed.
3 - From Elba Napoleon kept a close watch on the Continent. He knew that some of the diplomats at Vienna, where a congress was deciding the fate of Europe, considered Elba, between Corsica and Italy, too close to France and to Italy and wanted to banish him to a distant island in the Atlantic. Also he accused Austria of preventing Marie-Louise and his son from coming to join him (in fact, she had taken a lover and had no intention of going to live with her husband). In addition, the French government refused to pay Napoleon’s allowance, so that he was in danger of being reduced to penury.
3 - All these considerations drove Napoleon to action. Decisive as ever, he returned to France like a thunderbolt. On March 1, 1815, he landed at Cannes with a detachment of his guard. As he crossed the Alps, the republican peasants rallied round him, and near Grenoble he won over the soldiers dispatched to arrest him. On March 20 he was in Paris.
3 - Napoleon was brought back to power as the embodiment of the spirit of the Revolution rather than as the emperor who had fallen a year before. To rally the mass of Frenchmen to his cause, he should have allied himself with the Jacobins, but this he dared not do. Unable to escape from the bourgeoisie whose predominance he himself had assured and who feared above all else a revival of the radical experiments of 1793 and 1794, he could only set up a political regime scarcely distinguishable from that of Louis XVIII. Enthusiasm ebbed fast, and the Napoleonic adventure seemed a dead end.
3 - To oppose the allied troops massing on the frontiers, Napoleon mustered an army with which he marched into Belgium and defeated the Prussians at Ligny on June 16, 1815. Two days later, at Waterloo, he met the British under Wellington, the victor of the Peninsular War. A savage battle followed. Napoleon was in sight of victory when the Prussians under Gebhard Blücher arrived to reinforce the British, and soon, despite the heroism of the Old Guard, Napoleon was defeated.
3 - Back in Paris, the parliament forced Napoleon to abdicate; he did so, in favour of his son, on June 22, 1815. On July 3 he was at Rochefort, intending to take ship for the United States, but a British squadron prevented any French vessel from leaving the port. Napoleon then decided to appeal to the British government for protection. His request granted, he boarded the Bellerophon on July 15. The allies were agreed on one point: Napoleon was not to go back to Elba. Nor did they like the idea of his going off to America. It would have suited them if he had fallen a victim to the “White Terror” of the returned counterrevolutionaries or if Louis XVIII had had him summarily tried and executed. Great Britain had no choice but to send him to detention in a far-off island. The British government announced that the island of St. Helena in the southern Atlantic had been chosen for his residence; because of its remote position, Napoleon would enjoy much greater freedom than would be possible elsewhere. Napoleon protested eloquently: “I appeal to history!”
3 - On October 15, 1815, Napoleon disembarked in St. Helena with those followers who were voluntarily accompanying him into exile: General Henri-Gratien Bertrand, grand marshal of the palace, and his wife; the comte Charles de Montholon, aide-de-camp, and his wife; General Gaspard Gourgaud; Emmanuel Las Cases, the former chamberlain; and several servants. After a short stay at the house of a wealthy English merchant, they moved to Longwood, originally built for the lieutenant governor.
3 - Napoleon settled down to a life of routine. He got up late, breakfasting about 10:00 am, but seldom went out. He was free to go anywhere on the island so long as he was accompanied by an English officer, but he soon refused to comply with this condition and so shut himself up in the grounds of Longwood. He wrote and talked much. At first Las Cases acted as his secretary, compiling what was later to be the Mémorial de Sainte-Hélène (first published in 1823). From 7:00 to 8:00 pm Napoleon had dinner, after which a part of the evening was spent in reading aloud—Napoleon liked to hear the classics. Then they played cards. About midnight Napoleon went to bed. Some of his time was devoted to learning English, and he eventually began reading English newspapers; but he also had a large number of French books sent from Europe, which he read attentively and annotated.
3 - St. Helena had a healthful climate, and Napoleon’s food was good, carefully prepared, and plentiful. His inactivity undoubtedly contributed to the deterioration of his health. The man who for 20 years had played so great a role in the world and who had marched north, south, east, and west across Europe could hardly be expected to endure the monotony of existence on a little island, aggravated by the self-imposed life of a recluse. He had also more intimate reasons for unhappiness: Marie-Louise sent no word to him, and he may have learned of her liaison with the Austrian officer appointed to watch over her, Adam, Graf (count) von Neipperg (whom she eventually married in secret without waiting for Napoleon’s death). Nor did he have any news of his son, the former king of Rome, who was now living in Vienna with the title of duke of Reichstadt. Though the severity of Sir Hudson Lowe has been much exaggerated, it is certain that this “jailer,” who arrived as governor of St. Helena in April 1816, did nothing to make Napoleon’s life easier. Napoleon from the start disliked him as the former commander of the Corsican rangers, a band of volunteers composed largely of enemies of the Bonaparte family. Always anxious to carry out his instructions exactly, Lowe came into conflict with Las Cases. He saw Las Cases as Napoleon’s confidant and had him arrested and expelled. Thenceforward, relations between the governor and Napoleon were limited strictly to those stipulated by the regulations.
3 - Napoleon showed the first signs of illness at the end of 1817; he seems to have had an ulcer or a cancer of the stomach. The Irish doctor Barry O’Meara, having asked in vain for a change in the conditions under which Napoleon lived, was dismissed; so also was his successor John Stokoe, who was likewise thought to be well-disposed toward Napoleon. The undistinguished Corsican doctor who took their place, Francesco Antommarchi, prescribed a treatment that could do nothing to cure his patient. It is uncertain, however, whether Napoleon’s disease was curable at all, even by 21st-century methods. There has been continuing controversy about the cause of his death, but the evidence used by some to support the theory that Napoleon was poisoned is not considered conclusive by many scholars.
3 - From the beginning of 1821, the illness became rapidly worse. From March, Napoleon was confined to bed. In April he dictated his last will: I wish my ashes to rest on the banks of the Seine, in the midst of that French people which I have loved so much.…I die before my time, killed by the English oligarchy and its hired assassins.
3 - On May 5 he spoke a few coherent phrases: “My God…the French nation…my son…head of the army.” He died at 5:49 pm on that day, not yet 52 years old. His body was dressed in his favourite uniform, that of the Chasseurs de la Garde, covered by the gray overcoat that he had worn at Marengo. The funeral was conducted simply, but with due propriety, in the Rupert Valley, where Napoleon had sometimes walked, beside a stream in which two willows were reflected. The stone covering his tomb bore no name, only the words “Ci-Gît” (“Here Lies”).
3 - Napoleon’s fall set loose a torrent of hostile books designed to sully his reputation. One of the least violent of these was the pamphlet De Buonaparte, des Bourbons, et de la nécessité de se rallier à nos princes légitimes, pour le bonheur de la France et celui de l’Europe (1814; On Buonaparte and the Bourbons, and the Necessity of Rallying Around Our Legitimate Princes, for the Safety of France and of Europe) by the vicomte de Chateaubriand, a well-known writer of royalist sympathies. But this anti-Napoleonic literature soon died down, while the task of defending Napoleon was taken up. Lord Byron had published his “Ode to Napoleon Buonaparte” as early as 1814; the German poet Heinrich Heine wrote his ballad “Die Grenadiere”; and in 1817 the French novelist Stendhal began his biography Vie de Napoléon (Life of Napoleon). At the same time, the emperor’s most faithful supporters were working toward his rehabilitation, talking about him, and distributing reminders of him, including engravings. They idealized his life (“What a novel my life is!” he himself had said) and began to create the Napoleonic legend.
3 - As soon as the emperor was dead, the legend grew rapidly. Memoirs, notes, and narratives by those who had followed him into exile contributed substantially to it. In 1822 O’Meara, in London, had his Napoleon in Exile; or, A Voice from Saint Helena published; in 1823 the publication of the Mémoires pour servir à l’histoire de France sous Napoléon, écrits à Sainte-Hélène sous sa dictée (Memoirs of the History of France During the Reign of Napoleon, Dictated by the Emperor at St. Helena) by Montholon and Gourgaud, began; Las Cases, in his famous Mémorial, presented the emperor as a republican opposed to war who had fought only when Europe forced him to fight in defense of freedom; and in 1825 Antommarchi published his Derniers moments de Napoléon (The Last Days of Emperor Napoleon). Thereafter the number of works in Napoleon’s honour increased continually; among them were Victor Hugo’s “Ode à la Colonne” (“Ode to the Column”), the 28 volumes of the Victoires et conquêtes des Français (“Victories and Conquests of the French”), edited by Charles-Louis-Fleury Panckoucke, and Sir Walter Scott’s Life of Napoleon Buonaparte, Emperor of the French. Neither police action nor prosecutions could prevent books, pictures, and objects evoking the imperial saga from multiplying in France.
3 - After the July Revolution of 1830, which created the “Bourgeois Monarchy” under Louis-Philippe, thousands of Tricolor flags appeared in windows, and the government had not only to tolerate the growth of the legend but even to promote it. In 1833 the statue of Napoleon was put back on the top of the column in the Place Vendôme in Paris, and in 1840 the king’s son François, prince de Joinville, was sent in a warship to fetch the emperor’s remains from St. Helena to the banks of the Seine in accordance with his last wishes. A magnificent funeral was held in Paris in December 1840, and Napoleon’s body was conveyed through the Arc de Triomphe in the Place de l’Étoile to entombment under the dome of the Invalides.
3 - Napoleon’s nephew Louis-Napoléon exploited the legend in order to seize power in France. Though his attempts at Strasbourg in 1836 and at Boulogne in 1840 were failures, it was chiefly because of the growth of the legend that he won election to the presidency of the Second Republic with an overwhelming majority in 1848 and was able to carry out the coup d’état of December 1851 and make himself emperor in 1852.
3 - The disastrous end of the Second Empire in 1870 damaged the Napoleonic legend and gave rise to a new anti-Napoleonic literature, best represented by Hippolyte Taine’s Origines de la France contemporaine (1876–94; The Origins of Contemporary France). World Wars I and II, however, together with the experience of the 20th-century dictatorships, made it possible to judge Napoleon more fairly. Any comparison with Stalin or Hitler, for instance, can only be to Napoleon’s advantage. He was tolerant; he released the Jews from the ghettos; and he showed respect for human life. Brought up on the rationalist Encyclopédie and on the writings of the philosophies of the Enlightenment, he remained above all a man of the 18th century, the last of the “enlightened despots.” One of the gravest accusations made against Napoleon is that he was the “Corsican ogre” who sacrificed millions of men to his ambition. Precise calculations show that the Napoleonic Wars of 1800–15 cost France itself about 500,000 casualties—i.e., about one-sixtieth of the population—with another 500,000 imprisoned or missing. The loss of these young men did not greatly affect the growth of the population, however.
3 - The social structure of France changed little under the First Empire. It remained roughly what the Revolution had made it: a great mass of peasants comprising three-fourths of the population—about half of them working owners of their farms or sharecroppers and the other half with too little land for their own subsistence and hiring themselves out as labourers. Industry, stimulated by the war and the blockade of English goods, made remarkable progress in northern and eastern France, whence exports could be sent to central Europe; but it declined in the south and west because of the closing of the Mediterranean and the Atlantic. The great migrations from rural areas toward industry in the towns began only after 1815. The nobility would probably have declined more swiftly if Napoleon had not restored it, but it could never recover its former privileges.
3 - Above all, Napoleon left durable institutions, the “granite masses” on which modern France has been built up: the administrative system of the prefects, the Napoleonic Code, the judicial system, the Banque de France and the country’s financial organization, the centralized university, and the military academies. Napoleon changed the history both of France and of the world.

4 - Marie Curie (born November 7, 1867, Warsaw, Congress Kingdom of Poland, Russian Empire—died July 4, 1934, near Sallanches, France) was a Polish-born French physicist, famous for her work on radioactivity and twice a winner of the Nobel Prize. With Henri Becquerel and her husband, Pierre Curie, she was awarded the 1903 Nobel Prize for Physics. She was the sole winner of the 1911 Nobel Prize for Chemistry. She was the first woman to win a Nobel Prize, and she is the only woman to win the award in two different fields.
4 - From childhood she was remarkable for her prodigious memory, and at the age of 16 she won a gold medal on completion of her secondary education at the Russian lycée. Because her father, a teacher of mathematics and physics, lost his savings through bad investment, she had to take work as a teacher and, at the same time, took part clandestinely in the nationalist “free university,” reading in Polish to women workers. At the age of 18 she took a post as governess, where she suffered an unhappy love affair. From her earnings she was able to finance her sister Bronisława’s medical studies in Paris, with the understanding that Bronisława would in turn later help her to get an education.
4 - In 1891 Skłodowska went to Paris and, now using the name Marie, began to follow the lectures of Paul Appell, Gabriel Lippmann, and Edmond Bouty at the Sorbonne. There she met physicists who were already well known—Jean Perrin, Charles Maurain, and Aimé Cotton. Skłodowska worked far into the night in her student-quarters garret and virtually lived on bread and butter and tea. She came first in the licence of physical sciences in 1893. She began to work in Lippmann’s research laboratory and in 1894 was placed second in the licence of mathematical sciences. It was in the spring of that year that she met Pierre Curie.
4 - Their marriage (July 25, 1895) marked the start of a partnership that was soon to achieve results of world significance, in particular the discovery of polonium (so called by Marie in honour of her native land) in the summer of 1898 and that of radium a few months later. Following Henri Becquerel’s discovery (1896) of a new phenomenon (which she later called “radioactivity”), Marie Curie, looking for a subject for a thesis, decided to find out if the property discovered in uranium was to be found in other matter. She discovered that this was true for thorium at the same time as G.C. Schmidt did.
4 - Turning her attention to minerals, she found her interest drawn to pitchblende, a mineral whose activity, superior to that of pure uranium, could be explained only by the presence in the ore of small quantities of an unknown substance of very high activity. Pierre Curie then joined her in the work that she had undertaken to resolve this problem and that led to the discovery of the new elements, polonium and radium. While Pierre Curie devoted himself chiefly to the physical study of the new radiations, Marie Curie struggled to obtain pure radium in the metallic state—achieved with the help of the chemist André-Louis Debierne, one of Pierre Curie’s pupils. On the results of this research, Marie Curie received her doctorate of science in June 1903 and, with Pierre, was awarded the Davy Medal of the Royal Society. Also in 1903 they shared with Becquerel the Nobel Prize for Physics for the discovery of radioactivity.
4 - The birth of her two daughters, Irène and Ève, in 1897 and 1904, did not interrupt Marie’s intensive scientific work. She was appointed lecturer in physics at the École Normale Supérieure for girls in Sèvres (1900) and introduced there a method of teaching based on experimental demonstrations. In December 1904 she was appointed chief assistant in the laboratory directed by Pierre Curie.
4 - The sudden death of Pierre Curie (April 19, 1906) was a bitter blow to Marie Curie, but it was also a decisive turning point in her career: henceforth she was to devote all her energy to completing alone the scientific work that they had undertaken. On May 13, 1906, she was appointed to the professorship that had been left vacant on her husband’s death; she was the first woman to teach in the Sorbonne. In 1908 she became titular professor, and in 1910 her fundamental treatise on radioactivity was published. In 1911 she was awarded the Nobel Prize for Chemistry, for the isolation of pure radium. In 1914 she saw the completion of the building of the laboratories of the Radium Institute (Institut du Radium) at the University of Paris.
4 - Throughout World War I, Marie Curie, with the help of her daughter Irène, devoted herself to the development of the use of X-radiography. In 1918 the Radium Institute, the staff of which Irène had joined, began to operate in earnest, and it was to become a universal centre for nuclear physics and chemistry. Marie Curie, now at the highest point of her fame and, from 1922, a member of the Academy of Medicine, devoted her researches to the study of the chemistry of radioactive substances and the medical applications of these substances.
4 - In 1921, accompanied by her two daughters, Marie Curie made a triumphant journey to the United States, where Pres. Warren G. Harding presented her with a gram of radium bought as the result of a collection among American women. She gave lectures, especially in Belgium, Brazil, Spain, and Czechoslovakia. She was made a member of the International Commission on Intellectual Co-operation by the Council of the League of Nations. In addition, she had the satisfaction of seeing the development of the Curie Foundation in Paris and the inauguration in 1932 in Warsaw of the Radium Institute, of which her sister Bronisława became director.
4 - One of Marie Curie’s outstanding achievements was to have understood the need to accumulate intense radioactive sources, not only to treat illness but also to maintain an abundant supply for research in nuclear physics; the resultant stockpile was an unrivaled instrument until the appearance after 1930 of particle accelerators. The existence in Paris at the Radium Institute of a stock of 1.5 grams of radium in which, over a period of several years, radium D and polonium had accumulated made a decisive contribution to the success of the experiments undertaken in the years around 1930 and in particular of those performed by Irène Curie in conjunction with Frédéric Joliot, whom she had married in 1926 (see Joliot-Curie, Frédéric and Irène). This work prepared the way for the discovery of the neutron by Sir James Chadwick and, above all, for the discovery in 1934 by Irène and Frédéric Joliot-Curie of artificial radioactivity.
4 - A few months after this discovery, Marie Curie died as a result of aplastic anemia caused by the action of radiation. Her contribution to physics had been immense, not only in her own work, the importance of which had been demonstrated by the award to her of two Nobel Prizes, but because of her influence on subsequent generations of nuclear physicists and chemists. Marie Curie, together with Irène Joliot-Curie, wrote the entry on radium for the 13th edition (1926) of the Encyclopædia Britannica.
4 - In 1995 Marie Curie’s ashes were enshrined in the Panthéon in Paris; she was the first woman to receive this honour for her own achievements. Her office and laboratory in the Curie Pavilion of the Radium Institute are preserved as the Curie Museum.

5 - Presley grew up dirt-poor in Tupelo, Mississippi, moved to Memphis as a teenager, and, with his family, was off welfare for only a few weeks when producer Sam Phillips at Sun Records, a local blues label, responded to his audition tape with a phone call. Several weeks worth of recording sessions ensued with a band consisting of Presley, guitarist Scotty Moore, and bassist Bill Black. Their repertoire consisted of the kind of material for which Presley would become famous: blues and country songs, Tin Pan Alley ballads, and gospel hymns. Presley knew some of this music from the radio, some of it from his parents’ Pentecostal church and the group sings he attended at the Rev. H.W. Brewster’s Black Memphis church, and some of it from the Beale Street blues clubs he began frequenting as a teenager.
5 - Presley was already a flamboyant personality, with relatively long greased-back hair and wild-colored clothing combinations, but his full musical personality did not emerge until he and the band began playing with blues singer Arthur (“Big Boy”) Crudup’s song “That’s All Right Mama” in July 1954. They arrived at a startling synthesis, eventually dubbed rockabilly, retaining many of the original’s blues inflections but with Presley’s high tenor voice adding a lighter touch and with the basic rhythm striking a much more supple groove. This sound was the hallmark of the five singles Presley released on Sun over the next year. Although none of them became a national hit, by August 1955, when he released the fifth, “Mystery Train,” arguably his greatest record ever, he had attracted a substantial Southern following for his recordings, his live appearances in regional roadhouses and clubs, and his radio performances on the nationally aired Louisiana Hayride. (A key musical change came when drummer D.J. Fontana was added, first for the Hayride shows but also on records beginning with “Mystery Train.”)
5 - Presley’s management was then turned over to Colonel Tom Parker, a country music hustler who had made stars of Eddy Arnold and Hank Snow. Parker arranged for Presley’s song catalog and recording contract to be sold to major New York City-based enterprises, Hill and Range and RCA Victor, respectively. Sun received a total of $35,000; Elvis got $5,000. He began recording at RCA’s studios in Nashville, Tennessee, with a somewhat larger group of musicians but still including Moore, Black, and Fontana, and began to create a national sensation with a series of hits: “Heartbreak Hotel,” “Don’t Be Cruel,” and “Love Me Tender” (all 1956), “All Shook Up” (1957), and more.
5 - From 1956 through 1958 he completely dominated the pop music charts and ushered in the age of rock and roll, opening doors for both white and Black rock artists. His television appearances, especially those on Ed Sullivan’s Sunday night variety show, set records for the size of the audiences. Even his films, a few slight vehicles, were box office smashes.
5 - Presley became the teen idol of his decade, greeted everywhere by screaming hordes of young women, and, when it was announced in early 1958 that he had been drafted and would enter the U.S. Army, there was that rarest of all pop culture events, a moment of true grief. More important, he served as the great cultural catalyst of his period. Elvis projected a mixed vision of humility and self-confidence, of intense commitment and comic disbelief in his ability to inspire frenzy. He inspired literally thousands of musicians—initially those more or less like-minded Southerners, from Jerry Lee Lewis and Carl Perkins on down, who were the first generation of rockabillies, and, later, people who had far different combinations of musical and cultural influences and ambitions. From John Lennon to Bruce Springsteen, Bob Dylan to Prince, it was impossible to think of a rock star of any importance who did not owe an explicit debt to Presley.
5 - Beyond even that, Presley inspired his audience. “It was like he whispered his dream in all our ears and then we dreamed it,” said Springsteen at the time of Presley’s death. You did not have to want to be a rock and roll star or even a musician to want to be like Elvis—which meant, ultimately, to be free and uninhibited and yet still a part of the everyday. Literally millions of people—an entire generation or two—defined their sense of personal style and ambition in terms that Elvis first personified.
5 - As a result, he was anything but universally adored. Those who did not worship him found him despicable (no one found him ignorable). Preachers and pundits declared him an anathema, his Pentecostally derived hip-swinging stage style and breathy vocal asides obscene. Racists denounced him for mingling Black music with white (and Presley was always scrupulous in crediting his Black sources, one of the things that made him different from the Tin Pan Alley writers and singers who had for decades lifted Black musical styles without credit). He was pronounced responsible for all teenage hooliganism and juvenile delinquency. Yet, in every appearance on television, he appeared affable, polite, and soft-spoken, almost shy. It was only with a band at his back and a beat in his ear that he became “Elvis the Pelvis.”
5 - In 1959, while stationed in West Germany—where he served as a soldier rather than joining the Special Services entertainment division—Presley met Priscilla Beaulieu, who was 14 years old at the time (Presley was 24). They started a romantic relationship that continued after Presley returned to the United States in 1960. When he resumed his musical career, those who regarded him as commercial hype without talent expected him to fade away. Instead, he continued to have hits from recordings stockpiled just before he entered the army.
5 - Presley picked up pretty much where he had left off, churning out a series of more than 30 movies (from Blue Hawaii [1961] to Change of Habit [1969]) over the next eight years, almost none of which fit any genre other than “Elvis movie,” which meant a light comedic romance with musical interludes. Most had accompanying soundtrack albums, and together the movies and the records made him a rich man, although they nearly ruined him as any kind of artist. Presley did his best work in the 1960s on singles either unconnected to the films or only marginally stuck into them, recordings such as “It’s Now or Never (‘O Sole Mio’)” (1960), “Are You Lonesome Tonight?” and “Little Sister” (both 1961), “Can’t Help Falling in Love” and “Return to Sender” (both 1962), and “Viva Las Vegas” (1964). Presley was no longer a controversial figure: he had become one more predictable mass entertainer, a personage of virtually no interest to the rock audience that had expanded so much with the advent of the new sounds of the Beatles, the Rolling Stones, and Bob Dylan.
5 - By 1968 the changes in the music world had overtaken Presley—both movie grosses and record sales had fallen. In December his one-man Christmas TV special aired: a tour de force of rock and roll and rhythm and blues, it restored much of his dissipated credibility. In 1969 he released a single having nothing to do with a film, “Suspicious Minds”; it went to number one. He also began doing concerts again and quickly won back a sizable following, although it was not nearly as universal as his audience in the 1950s; in the main, it was Southern and Midwestern, working-class, and overwhelmingly female. For much of the next decade, he was again one of the top live attractions in the United States. (For a variety of reasons, he never performed outside North America.) Presley was now a mainstream American entertainer, an icon but not so much an idol.
5 - In 1967 he married Priscilla Beaulieu without much furor. The next year he became a parent with the birth of their daughter, Lisa Marie Presley. Elvis Presley and Priscilla Presley eventually grew apart separating in 1972 and divorcing the following year.
5 - Presley made no more movies, although there was a good concert film, Elvis on Tour (1972). His recordings were of uneven quality, but on each album he included a song or two that had focus and energy. Hit songs were harder to come by—“Suspicious Minds” was his last number one and “Burning Love” (1972) his final Top Ten entry. But, thanks to concerts, spectaculars best described by critic Jon Landau as an apotheosis of American musical comedy, he remained a big money earner. He now lacked the ambition and power of his early work, but that may have been a good thing: he never seemed a dated relic of the 1950s trying to catch up to trends but was just a performer, unrelentingly himself.
5 - However, Presley had also developed a lethal lifestyle. Spending almost all his time when not on the road in Graceland, his Memphis estate (actually just a big Southern colonial house decorated somewhere between banal modernity and garish faux-Vegas opulence), he lived nocturnally, surrounded by sycophants and stuffed with greasy foods and a variety of prescription drugs. His shows deteriorated in the final two years of his life, and his recording career came to a virtual standstill. Presley never seemed confident in his status, never entirely certain that he would not collapse back into sharecropper poverty, and, as a result, he seems to have become immobilized; the man who had risked everything, including potential ridicule, to make himself a success now lived in the lockstep regimen of an addict and recluse. Finally, in the summer of 1977, the night before he was to begin yet another concert tour, he died of a heart attack brought on largely by drug abuse. He was 42 years old.
5 - Almost immediately upon hearing of his death, mourners from around the world gathered at Graceland to say farewell to the poor boy who had lived out the American dream. In a way, that mourning has never ceased: Graceland remains one of the country’s top tourist attractions, and Presley’s albums and other artifacts continue to sell briskly. Each August crowds flock to Graceland—which, under the direction of Priscilla Presley, first opened to the public in 1982—to honor him on the anniversary not of his birth but of his death. From time to time, rumors cropped up that he did not really die, that his death was a fake designed to free him from fame. Elvis impersonators are legion. His biggest fans—working-class white women, almost exclusively—passed their fanaticism on to their children, or at least to a surprising number of daughters. “Elvis has left the building,” but those who are still inside have decided to carry on regardless. Once more, Elvis Presley is triumphant, although this triumph is shadowed by something far less than happiness.

6 - socialism, social and economic doctrine that calls for public rather than private ownership or control of property and natural resources. According to the socialist view, individuals do not live or work in isolation but live in cooperation with one another. Furthermore, everything that people produce is in some sense a social product, and everyone who contributes to the production of a good is entitled to a share in it. Society as a whole, therefore, should own or at least control property for the benefit of all its members.
6 - This conviction puts socialism in opposition to capitalism, which is based on private ownership of the means of production and allows individual choices in a free market to determine how goods and services are distributed. Socialists complain that capitalism necessarily leads to unfair and exploitative concentrations of wealth and power in the hands of the relative few who emerge victorious from free-market competition—people who then use their wealth and power to reinforce their dominance in society. Because such people are rich, they may choose where and how to live, and their choices in turn limit the options of the poor. As a result, terms such as individual freedom and equality of opportunity may be meaningful for capitalists but can only ring hollow for working people, who must do the capitalists’ bidding if they are to survive. As socialists see it, true freedom and true equality require social control of the resources that provide the basis for prosperity in any society. Karl Marx and Friedrich Engels made this point in Manifesto of the Communist Party (1848) when they proclaimed that in a socialist society “the condition for the free development of each is the free development of all.”
6 - This fundamental conviction nevertheless leaves room for socialists to disagree among themselves with regard to two key points. The first concerns the extent and the kind of property that society should own or control. Some socialists have thought that almost everything except personal items such as clothing should be public property; this is true, for example, of the society envisioned by the English humanist Sir Thomas More in his Utopia (1516). Other socialists, however, have been willing to accept or even welcome private ownership of farms, shops, and other small or medium-sized businesses.
6 - The second disagreement concerns the way in which society is to exercise its control of property and other resources. In this case the main camps consist of loosely defined groups of centralists and decentralists. On the centralist side are socialists who want to invest public control of property in some central authority, such as the state—or the state under the guidance of a political party, as was the case in the Soviet Union. Those in the decentralist camp believe that decisions about the use of public property and resources should be made at the local, or lowest-possible, level by the people who will be most directly affected by those decisions. This conflict has persisted throughout the history of socialism as a political movement.
6 - The origins of socialism as a political movement lie in the Industrial Revolution. Its intellectual roots, however, reach back almost as far as recorded thought—even as far as Moses, according to one history of the subject. Socialist or communist ideas certainly play an important part in the ideas of the ancient Greek philosopher Plato, whose Republic depicts an austere society in which men and women of the “guardian” class share with each other not only their few material goods but also their spouses and children. Early Christian communities also practiced the sharing of goods and labour, a simple form of socialism subsequently followed in certain forms of monasticism. Several monastic orders continue these practices today.
6 - Christianity and Platonism were combined in More’s Utopia, which apparently recommends communal ownership as a way of controlling the sins of pride, envy, and greed. Land and houses are common property on More’s imaginary island of Utopia, where everyone works for at least two years on the communal farms and people change houses every 10 years so that no one develops pride of possession. Money has been abolished, and people are free to take what they need from common storehouses. All the Utopians live simply, moreover, so that they are able to meet their needs with only a few hours of work a day, leaving the rest for leisure.
6 - More’s Utopia is not so much a blueprint for a socialist society as it is a commentary on the failings he perceived in the supposedly Christian societies of his day. Religious and political turmoil, however, soon inspired others to try to put utopian ideas into practice. Common ownership was one of the aims of the brief Anabaptist regime in the Westphalian city of Münster during the Protestant Reformation, and several communist or socialist sects sprang up in England in the wake of the Civil Wars (1642–51). Chief among them was the Diggers, whose members claimed that God had created the world for people to share, not to divide and exploit for private profit. When they acted on this belief by digging and planting on land that was not legally theirs, they ran afoul of Oliver Cromwell’s Protectorate, which forcibly disbanded them.
6 - Whether utopian or practical, these early visions of socialism were largely agrarian. This remained true as late as the French Revolution, when the journalist François-Noël Babeuf and other radicals complained that the Revolution had failed to fulfill the ideals of liberty, equality, and fraternity. Adherence to “the precious principle of equality,” Babeuf argued, requires the abolition of private property and common enjoyment of the land and its fruits. Such beliefs led to his execution for conspiring to overthrow the government. The publicity that followed his trial and death, however, made him a hero to many in the 19th century who reacted against the emergence of industrial capitalism.
6 - Conservatives who saw the settled life of agricultural society disrupted by the insistent demands of industrialism were as likely as their radical counterparts to be outraged by the self-interested competition of capitalists and the squalor of industrial cities. The radicals distinguished themselves, however, by their commitment to equality and their willingness to envision a future in which industrial power and capitalism were divorced. To their moral outrage at the conditions that were reducing many workers to pauperism, the radical critics of industrial capitalism added a faith in the power of people to put science and an understanding of history to work in the creation of a new and glorious society. The term socialist came into use about 1830 to describe these radicals, some of the most important of whom subsequently acquired the title of “utopian” socialists.
6 - One of the first utopian socialists was the French aristocrat Claude-Henri de Saint-Simon. Saint-Simon did not call for public ownership of productive property, but he did advocate public control of property through central planning, in which scientists, industrialists, and engineers would anticipate social needs and direct the energies of society to meet them. Such a system would be more efficient than capitalism, according to Saint-Simon, and it even has the endorsement of history itself. Saint-Simon believed that history moves through a series of stages, each of which is marked by a particular arrangement of social classes and a set of dominant beliefs. Thus, feudalism, with its landed nobility and monotheistic religion, was giving way to industrialism, a complex form of society characterized by its reliance on science, reason, and the division of labour. In such circumstances, Saint-Simon argued, it makes sense to put the economic arrangements of society in the hands of its most knowledgeable and productive members, so that they may direct economic production for the benefit of all.
6 - Another early socialist, Robert Owen, was himself an industrialist. Owen first attracted attention by operating textile mills in New Lanark, Scot., that were both highly profitable and, by the standards of the day, remarkably humane: no children under age 10 were employed. Owen’s fundamental belief was that human nature is not fixed but formed. If people are selfish, depraved, or vicious, it is because social conditions have made them so. Change the conditions, he argued, and people will change; teach them to live and work together in harmony, and they will do so. Thus, Owen set out in 1825 to establish a model of social organization, New Harmony, on land he had purchased in the U.S. state of Indiana. This was to be a self-sufficient, cooperative community in which property was commonly owned. New Harmony failed within a few years, taking most of Owen’s fortune with it, but he soon turned his attention to other efforts to promote social cooperation—trade unions and cooperative businesses, in particular.
6 - Similar themes mark the writings of François-Marie-Charles Fourier, a French clerk whose imagination, if not his fortune, was as extravagant as Owen’s. Modern society breeds selfishness, deception, and other evils, Fourier charged, because institutions such as marriage, the male-dominated family, and the competitive market confine people to repetitive labour or a limited role in life and thus frustrate the need for variety. By setting people at odds with each other in the competition for profits, moreover, the market in particular frustrates the desire for harmony. Accordingly, Fourier envisioned a form of society that would be more in keeping with human needs and desires. Such a “phalanstery,” as he called it, would be a largely self-sufficient community of about 1,600 people organized according to the principle of “attractive labour,” which holds that people will work voluntarily and happily if their work engages their talents and interests. All tasks become tiresome at some point, however, so each member of the phalanstery would have several occupations, moving from one to another as his interest waned and waxed. Fourier left room for private investment in his utopian community, but every member was to share in ownership, and inequality of wealth, though permitted, was to be limited.
6 - The ideas of common ownership, equality, and a simple life were taken up in the visionary novel Voyage en Icarie (1840; Travels in Icaria), by the French socialist Étienne Cabet. Icaria was to be a self-sufficient community, combining industry with farming, of about one million people. In practice, however, the Icaria that Cabet founded in Illinois in the 1850s was about the size of a Fourierist phalanstery, and dissension among the Icarians prompted Cabet to depart in 1856.
6 - Other socialists in France began to agitate and organize in the 1830s and ’40s; they included Louis Blanc, Louis-Auguste Blanqui, and Pierre-Joseph Proudhon. Blanc, the author of L’Organisation du travail (1839; The Organization of Labour), promoted a scheme of state-financed but worker-controlled “social workshops” that would guarantee work for everyone and lead gradually to a socialist society. Blanqui, by contrast, was a revolutionary who spent more than 33 years in prison for his insurrectionary activities. Socialism cannot be achieved without the conquest of state power, he argued, and this conquest must be the work of a small group of conspirators. Once in power, the revolutionaries would form a temporary dictatorship that would confiscate the property of the wealthy and establish state control of major industries.
6 - In Qu’est-ce que la propriété? (1840; What Is Property?), Proudhon memorably declared, “Property is theft!” This assertion was not quite as bold as it appears, however, since Proudhon had in mind not property in general but property that is worked by anyone other than its owner. In contrast to a society dominated by capitalists and absentee landlords, Proudhon’s ideal was a society in which everyone had an equal claim, either alone or as part of a small cooperative, to possess and use land and other resources as needed to make a living. Such a society would operate on the principle of mutualism, according to which individuals and groups would exchange products with one another on the basis of mutually satisfactory contracts. All this would be accomplished, ideally, without the interference of the state, for Proudhon was an anarchist who regarded the state as an essentially coercive institution. Yet his anarchism did not prevent him from urging Napoleon III to make free bank credit available to workers for the establishment of mutualist cooperatives—a proposal the emperor declined to adopt.
6 - Despite their imagination and dedication to the cause of the workers, none of the early socialists met with the full approval of Karl Marx, who is unquestionably the most important theorist of socialism. In fact, Marx and his longtime friend and collaborator Friedrich Engels were largely responsible for attaching the label “utopian,” which they intended to be derogatory, to Saint-Simon, Fourier, and Owen, whose “fantastic pictures of future society” they contrasted to their own “scientific” approach to socialism. The path to socialism proceeds not through the establishment of model communities that set examples of harmonious cooperation to the world, according to Marx and Engels, but through the clash of social classes. “The history of all hitherto existing society is the history of class struggles,” they proclaimed in the Manifesto of the Communist Party. A scientific understanding of history shows that these struggles will culminate in the triumph of the working class and the establishment of socialism.
6 - According to Engels, the basic elements of Marx’s theory are to be found in German philosophy, French socialism, and British economics. Of these, German philosophy was surely the formative influence on Marx’s thinking. Born in Trier in the German Rhineland, Marx was a philosophy student at the University of Berlin when the idealism of G.W.F. Hegel dominated German philosophy. Hegel maintained that history is the story of the unfolding or realization of “spirit”—a process that requires struggle, agony, and the overcoming of obstacles to the attainment of self-knowledge. Just as individual persons cannot realize their potential—especially the potential for freedom—if they remain forever in a childish or adolescent condition, so spirit must develop throughout history in a dialectical fashion. That is, individuals and even nations are characters in a drama that proceeds through the clash of opposing ideas and interests to a greater self-awareness and appreciation of freedom. Slavery, for example, was long taken for granted as a natural and acceptable practice, but the slave’s struggle to be recognized as a person was bringing an end to slavery as master and slave came to recognize their common humanity—and thus to liberate themselves, and spirit, from a false sense of the master’s superiority.
6 - Like Hegel, Marx understood history as the story of human labour and struggle. However, whereas for Hegel history was the story of spirit’s self-realization through human conflict, for Marx it was the story of struggles between classes over material or economic interests and resources. In place of Hegel’s philosophical idealism, in other words, Marx developed a materialist or economic theory of history. Before people can do anything else, he held, they must first produce what they need to survive, which is to say that they are subject to necessity. Freedom for Marx is largely a matter of overcoming necessity. Necessity compels people to labour so that they may survive, and only those who are free from this compulsion will be free to develop their talents and potential. This is why, throughout history, freedom has usually been restricted to members of the ruling class, who use their control of the land and other means of production to exploit the labour of the poor and subservient. The masters in slaveholding societies, the landowning aristocracy in feudal times, and the bourgeoisie who control the wealth in capitalist societies have all enjoyed various degrees of freedom, but they have done so at the expense of the slaves, serfs, and industrial workers, or proletarians, who have provided the necessary labour.
6 - For Marx, capitalism is both a progressive force in history and an exploitative system that alienates capitalists and workers alike from their true humanity. It is progressive because it has made possible the industrial transformation of the world, thereby unleashing the productive power to free everyone from necessity. Yet it is exploitative in that capitalism condemns the proletarians, who own nothing but their labour power, to lives of grinding labour while enabling the capitalists to reap the profits. This is a volatile situation, according to Marx, and its inevitable result will be a war that will end all class divisions. Under the pressure of depressions, recessions, and competition for jobs, the workers will become conscious that they form a class, the proletariat, that is oppressed and exploited by their class enemy, the bourgeoisie. Armed with this awareness, they will overthrow the bourgeoisie in a series of spontaneous uprisings, seizing control of factories, mines, railroads, and other means of production, until they have gained control of the government and converted it into a revolutionary dictatorship of the proletariat. Under socialism or communism—Marx and Engels drew no clear or consistent distinction between the two—government itself will eventually wither away as people gradually lose the selfish attitudes inculcated by private ownership of the means of production. Freed from necessity and exploitation, people will finally live in a true community that gives “each individual the means of cultivating his gifts in all directions.”
6 - Marx maintained that the revolution by which socialism would be achieved was ordained by the logic of capitalism itself, as the capitalists’ competition for profits led them to create their own “grave diggers” in the proletariat. Even the role of the revolutionary, such as Marx, was confined to that of “midwife,” for revolutionaries could do no more than speed along the inevitable revolution and ease its birth pangs.
6 - This, at least, was Marx’s more or less “official” doctrine. In his writings and political activities, however, he added several qualifications. He acknowledged, for example, that socialism might supplant capitalism peacefully in England, the United States, and other countries where the proletariat was gaining the franchise; he also said that it might be possible for a semifeudal country such as Russia to become socialist without first passing through capitalist industrialism. Moreover, Marx played an important part in the International Working Men’s Association, or First International, formed in 1864 by a group of labour leaders who were neither exclusively revolutionary nor even entirely committed to socialism. In short, Marx was not the inflexible economic determinist he is sometimes taken to be. But he was convinced that history was on the side of socialism and that the equal development of all people to be achieved under socialism would be the fulfillment of history.
6 - By the time of Marx’s death in 1883, many socialists had begun to call themselves “Marxists.” His influence was particularly strong within the Social Democratic Party of Germany (SPD), which was formed in 1875 by the merger of a Marxist party and a party created by Marx’s German rival, Ferdinand Lassalle. According to Marx’s Critique of the Gotha Programme (1891), Lassalle had “conceived the workers’ movement from the narrowest national standpoint”; that is, Lassalle had concentrated on converting Germany to socialism, whereas Marx thought that socialism had to be an international movement. Even worse, Lassalle and his followers had sought to gain control of the state through elections in hopes of using “state aid” to establish producers’ cooperatives. Marx’s belief in the revolutionary transformation of society soon prevailed in the SPD, but his controversy with Lassalle and the Lassalleans testifies to the existence of other important currents in socialist thought in the late 19th century.
6 - Caught up in these currents were men and women who seemed to agree on little but their condemnation of capitalism. Many prominent socialists were militant atheists, for example, but others expressly connected socialism to religion. Even the rationalist Saint-Simon had called for a “new Christianity” that would join Christian social teachings with modern science and industry to create a society that would satisfy basic human needs. His followers attempted to put this idea into practice, giving rise to a Saint-Simonian sect sometimes called “the religion of the engineers.” This combination of an appeal to universal brotherhood and a faith in enlightened management also animated the best-selling utopian novel Looking Backward (1888), by the American journalist Edward Bellamy. In England the Anglican clergymen Frederick Denison Maurice and Charles Kingsley initiated a Christian socialist movement at the end of the 1840s on the grounds that the competitive individualism of laissez-faire capitalism was incompatible with the spirit of Christianity. Similar concerns inspired socialists in other countries, including the Russian novelist, anarchist, and pacifist Leo Tolstoy.
6 - Although neither Christianity nor any other religion was a dominant force within socialist theory or politics, the connection between Christianity and socialism persisted through the 20th century. One manifestation of this connection was liberation theology—sometimes characterized as an attempt to marry Marx and Jesus—which emerged among Roman Catholic theologians in Latin America in the 1960s. Another, perhaps more modest, manifestation is the Christian Socialist Movement in Britain, which affiliates itself with the British Labour Party. Several members of Parliament have belonged to the Christian Socialist Movement, including Prime Minister Gordon Brown, the son of a Methodist minister, and his predecessor, Tony Blair, an Anglican who converted to Catholicism not long after he left office.
6 - Neither Tolstoy’s religion nor his pacifism was shared by the earlier flamboyant Russian anarchist Mikhail Bakunin, who held that religion, capitalism, and the state are forms of oppression that must be smashed if people are ever to be free. As he stated in an early essay, “The Reaction in Germany” (1842), “The passion for destruction is also a creative passion.” This belief led Bakunin into one uprising or conspiracy after another throughout his life. It also led him into a controversy with Marx that contributed to disintegration of the International Working Men’s Association in the 1870s. Bakunin shared Marx’s vision of a classless, stateless community in which the means of production would be under community control; however, he vehemently rejected Marx’s claim that the dictatorship of the proletariat was a necessary step on the way to communism. To the contrary, Bakunin argued, the dictatorship of the proletariat threatened to become even more oppressive than the bourgeois state, which at least had a militant and organized working class to check its growth.
6 - Anarcho-communism took less-extreme forms in the hands of two later Russian émigrés, Peter Kropotkin and Emma Goldman. Kropotkin used science and history to try to demonstrate that anarchism is not foolishly optimistic. In Mutual Aid (1897) he drew on Charles Darwin’s theory of evolution to argue that, contrary to popular notions of social Darwinism, the groups that prospered in evolutionary terms were those that practiced cooperation. Goldman, who came to prominence as “Red Emma” in the United States, campaigned against religion, capitalism, the state, and marriage, which she condemned in “Marriage and Love” (1910) as an institution that “makes a parasite of woman, an absolute dependent.” She also served a prison term for advocating birth control.
6 - As the anarcho-communists argued for a form of socialism so decentralized that it required the abolition of the state, a milder and markedly centralist version of socialism, Fabianism, emerged in Britain. Fabian Socialism was so called because the members of the Fabian Society admired the tactics of the Roman general Fabius Cunctator (Fabius the Delayer), who avoided pitched battles and gradually wore down Hannibal’s forces. Instead of revolution, the Fabians favoured “gradualism” as the way to bring about socialism. Their notion of socialism, like Saint-Simon’s, entailed social control of property through an effectively and impartially administered state—a government of enlightened experts. The Fabians themselves were mostly middle-class intellectuals—including George Bernard Shaw, Sidney and Beatrice Webb, Graham Wallas, and H.G. Wells—who thought that persuasion and education were more likely to lead to socialism, however gradually, than violent class warfare. Rather than form their own political party or work through trade unions, moreover, the Fabians aimed at gaining influence within existing parties. They eventually exercised considerable influence within Britain’s Labour Party, though they had little to do with its formation in the early 1900s.
6 - Near the anarcho-communists on the decentralist side of socialism were the syndicalists. Inspired in part by Proudhon’s ideas, syndicalism developed at the end of the 19th century out of the French trade-union movement—syndicat being the French word for trade union. It was a significant force in Italy and Spain in the early 20th century until it was crushed by the fascist regimes in those countries. In the United States, syndicalism appeared in the guise of the Industrial Workers of the World, or “Wobblies,” founded in 1905.
6 - The hallmarks of syndicalism were workers’ control and “direct action.” Syndicalists such as Fernand Pelloutier distrusted both the state, which they regarded as an agent of capitalism, and political parties, which they thought were incapable of achieving radical change. Their aim was to replace capitalism and the state with a loose federation of local workers’ groups, which they meant to bring about through direct action—especially a general strike of workers that would bring down the government as it brought the economy to a halt. Georges Sorel elaborated on this idea in his Réflexions sur la violence (1908; Reflections on Violence), in which he treated the general strike not as the inevitable result of social developments but as a “myth” that could lead to the overthrow of capitalism if only enough people could be inspired to act on it.
6 - Related to syndicalism but nearer to Fabianism in its reformist tactics, Guild Socialism was an English movement that attracted a modest following in the first two decades of the 20th century. Inspired by the medieval guild, an association of craftsmen who determined their own working conditions and activities, theorists such as Samuel G. Hobson and G.D.H. Cole advocated the public ownership of industries and their organization into guilds, each of which would be under the democratic control of its trade union. The role of the state was less clear: some guild socialists envisioned it as a coordinator of the guilds’ activities, while others held that its functions should be limited to protection or policing. In general, however, the guild socialists were less inclined to invest power in the state than were their Fabian compatriots.
6 - In 1889, on the centenary of the French Revolution, a Second International emerged from two rival socialist conventions in Paris. Intended as a revival of the International Working Men’s Association, this new organization was dominated by Marxists in general and the SPD in particular. By this time the SPD was both officially Marxist and a force to be reckoned with in German politics. Despite Otto von Bismarck’s attempts to suppress it, Wilhelm Liebknecht, August Bebel, and other leaders had transformed the SPD into a mass party. But its considerable success—the SPD won almost one-fifth of the votes cast in the parliamentary elections of 1890, for example—raised the question of whether socialism might be achieved through the ballot box rather than through revolution. The “orthodox” position, as developed by the SPD’s chief theorist, Karl Kautsky, tried to reconcile the SPD’s electoral practice with Marx’s revolutionary doctrine. But others had begun to think that it would be better to recognize that circumstances had changed and to revise Marx’s doctrine accordingly.
6 - Foremost among the “revisionists” was Eduard Bernstein, an SPD leader who became an associate of Engels while living in England to escape Bismarck’s harassment. Bernstein was also exposed to the Fabians while in England, and their example encouraged him to question aspects of Marx’s theory. Like others, Bernstein observed that the living and working conditions of the proletariat were not growing more desperate, as Marx had predicted, but were on the contrary improving, largely as a result of trade-union activity and the extension of the franchise. This led him to conclude that the revolutionary overthrow of capitalism was neither necessary nor desirable. A gradual, peaceful transformation to socialism, he argued in Evolutionary Socialism (1899), would be safer than the revolutionary route, with its dangerously vague and potentially tyrannical dictatorship of the proletariat.
6 - Bernstein’s writings drew a swift and hostile reaction from his SPD comrades, Kautsky in particular, and from revolutionary Marxists elsewhere. After several years of polemical war between revisionists and orthodox Marxists, the revisionists eventually triumphed within the SPD, which gradually abandoned its revolutionary pretenses. Nevertheless, some stalwarts, such as Rosa Luxemburg, remained faithful to the spirit of revolutionary Marxism.
6 - Among the remaining orthodox Marxists was the Russian revolutionary V.I. Ulyanov, better known by his pseudonym Lenin. As the leader of the Bolshevik, or “majority,” faction of the Russian Social-Democratic Workers’ Party, Lenin himself had been accused of straying from the Marxist path. The problem for Russian Marxists was that Russia in the late 19th century remained a semifeudal country with barely the beginnings of industrial capitalism. To be sure, Marx had allowed that it might be possible for a country such as Russia to move directly from feudalism to socialism, but the standard position among Marxists was that capitalism was a necessary stage of economic and historical development; otherwise, there would be neither the productive power to overcome necessity nor the revolutionary proletariat to win freedom for all as it emancipated itself from capitalist exploitation.
6 - This had been the standard position among Russian Marxists too, but it was not Lenin’s. Lenin had little faith in the revolutionary potential of the proletariat, arguing in What Is to Be Done? (1902) that the workers, left to themselves, would fight only for better wages and working conditions; they therefore needed to be educated, enlightened, and led to revolution by a “vanguard” party of professional revolutionaries. Moreover, the authoritarian nature of the Russian government required that the vanguard party be conspiratorial, disciplined, and elitist. Lenin’s Russian-Marxist rivals disputed these points, but his manipulation of the vote at a party congress enabled him to label them the Menshevik, or “minority,” faction.
6 - Lenin’s commitment to revolution thus put him at odds with those who advocated a revised, evolutionary Marxism. In Imperialism, the Highest Stage of Capitalism (1916), Lenin argued against the revisionists, stating that the improvement in conditions enjoyed by the proletariat of Europe and the United States was a kind of bribe made possible by the “superprofits” that their countries’ capitalists were extracting from the labour and resources of the poorer parts of the world. But imperialism would also be the last stage of capitalism, for it was bound to expose the contradictions of capitalism not only in the industrial countries but also in the countries exploited by the imperialistic powers—hence the possibility of revolution in a country that had not itself gone through capitalism.
6 - Lenin wrote Imperialism during World War I, which proved to be a watershed in the history of socialism. In the years before war broke out in August 1914, most European socialists had held that the only war the proletariat should fight was the class war against the bourgeoisie. When the war began, however, socialists were forced to choose between international socialism and their countries, and they generally chose the latter—though there were notable exceptions, Luxemburg and Lenin among them. Once the SPD’s contingent in the Reichstag voted to issue war credits, socialists in other countries fell into line behind their own governments. The Second International lingered for a time, but to no effective purpose.
6 - World War I also inflicted severe hardships on the Russian people, thereby contributing to the collapse of the tsarist regime and creating an opportunity for revolution, which the Bolsheviks seized in the Russian Revolution of 1917. Lenin’s standing among revolutionary Marxists soared, though Luxemburg and others deplored the way in which the dictatorship of the proletariat was becoming a dictatorship of the All-Russian Communist Party, as the Bolsheviks named themselves in 1918. Still, the communists’ victory gave Luxemburg and other revolutionaries hope that the Russian example would inspire socialist revolutions elsewhere.
6 - For his part, Lenin feared that his regime could not survive without the aid of friendly—and therefore socialist—neighbours. Accordingly, he called a meeting in Moscow to establish a Third International, or Communist International (Comintern). The response from other countries was tepid, and, by the time the delegates convened in March 1919, the prospects for a new international had been further dimmed by the failure of the Spartacus Revolt of the new Communist Party of Germany—a failure that claimed the lives of Luxemburg and Karl Liebknecht (the son of Wilhelm Liebknecht), who were summarily executed by counterrevolutionary forces in 1919 (see also Spartacus League). Lenin pressed on with the formation of the Comintern, but it was soon apparent that it was an agent of the new Union of Soviet Socialist Republics (formally created in 1922) and not of international socialism as such. Indeed, by this time a fissure had clearly developed between communists on the one hand and socialists, or social democrats, on the other.
6 - The division took institutional form as communist parties emerged in one country after another to challenge existing socialist parties and their common enemy, capitalism. In general, the communists were revolutionary Marxists who adhered to what came to be called Marxism-Leninism. Their socialist rivals—variously known as socialists, social democrats, and labourites—were a more diverse group, including both revisionists and non-Marxists, but they were united in their commitment to peaceful, democratic tactics. They were also less likely than the communists to claim that history was moving inexorably toward the demise of capitalism and more likely to appeal to ethical considerations. In England, for example, the reformer Richard Henry Tawney found a receptive audience within the Labour Party when he rested the case for socialism on its promotion of fellowship, the dignity of work, and the equal worth of all members of society.
6 - On the communist side, the standard was set by the increasingly totalitarian regime of Joseph Stalin in the Soviet Union. Lenin’s death in 1924 led to a power struggle between Stalin and Leon Trotsky. Stalin not only won the struggle but eventually ordered the deaths of Trotsky and other rivals—and of millions more who opposed or resisted his policies. While professing to be a revolutionary in the Marxist-Leninist tradition, Stalin concentrated his efforts on building “socialism in one country,” largely through a program of forced collectivization and industrialization.
6 - There were occasional deviations from the Marxist-Leninist line, as in the case of Antonio Gramsci, who helped to found the Italian Communist Party in 1921. Gramsci resisted the tendency to reduce Marx’s theory to economic terms, focusing instead on the way in which the “hegemony” of the ruling classes over schools, churches, the media, and other cultural institutions encouraged workers to acquiesce in their exploitation. But Gramsci’s attempt to convince other communists of the revolutionary potential of cultural transformation was restricted by his imprisonment, from 1926 until shortly before his death in 1937, by the fascist regime of Benito Mussolini.
6 - Fascist oppression, in fact, was a major problem for communists and socialists alike, not only in Italy but subsequently in Spain under Francisco Franco and in Germany under Adolf Hitler. Socialist parties had drawn enough votes in Germany, Britain, and France to participate in or even to lead coalition governments in the 1920s and ’30s, and in Sweden the Swedish Social Democratic Workers’ Party won control of the government in 1932 with a promise to make their country into a “people’s home” based on “equality, concern, cooperation, and helpfulness.” Wherever fascists took power, however, communists and socialists were among the first to be suppressed.
6 - Nor were there any signal victories for socialism outside Europe in the years between the world wars. Although Eugene V. Debs won nearly one million votes in the U.S. presidential election of 1920, his showing represented less than 4 percent of the votes cast and remains the electoral high point for American socialists. In India, Mahatma Gandhi attracted a mass following, but his popularity owed more to his campaign for independence from Britain than to the traces of socialism in his philosophy.
6 - In China another mass movement for national liberation developed at this time, though it was explicitly communist. Its leader, Mao Zedong, helped to found the Chinese Communist Party (CCP) in 1921. After a disastrous beginning—the Comintern had pushed the Chinese communists into an alliance with the nationalist leader Chiang Kai-shek, who attacked the communists as soon as he thought it expedient—Mao retreated to the fields and hills to rebuild the CCP. While remaining faithful to Lenin’s notion of the communist party as the revolutionary vanguard, Mao proceeded to lead a guerilla movement that established its power base among the peasantry, which he regarded as a rural proletariat. In Mao’s hands, moreover, the concept of nation largely replaced that of class, with China represented as a poor and oppressed proletarian nation that had to rise against the oppressing imperialist nations and their bourgeois underlings.
6 - World War II forged an uneasy alliance between communists and socialists—and between liberals and conservatives—in their common struggle against fascism. The alliance soon disintegrated, however, as the Soviet Union established communist regimes in the eastern European countries it had occupied at the end of the war. The Cold War that ensued deepened the fissure between communists and other socialists, the latter seeing themselves as democrats opposed to the one-party rule of the Soviet Union and its satellites. The Labour Party, for example, won a parliamentary majority in the British elections of 1945 and subsequently established a national health care system and public control of major industries and utilities; when the party lost its majority in 1951, it peacefully relinquished the offices of government to the victorious Conservatives.
6 - The communists also claimed to be democrats, but their notion of “people’s democracy” rested on the belief that the people were not yet capable of governing themselves. Thus, Mao declared, after Chiang Kai-shek’s forces were driven from mainland China in 1949, that the new People’s Republic of China was to be a “people’s democratic dictatorship”; that is, the CCP would rule in the interests of the people by suppressing their enemies and building socialism. Freedom of expression and political competition were bourgeois, counterrevolutionary ideas. This became the justification for one-party rule by other communist regimes in North Korea, Vietnam, Cuba, and elsewhere.
6 - Meanwhile, the socialist parties of Europe were modifying their positions and enjoying frequent electoral success. The Scandinavian socialists set the example of “mixed economies” that combined largely private ownership with government direction of the economy and substantial welfare programs, and other socialist parties followed suit. Even the SPD, in its Bad Godesberg program of 1959, dropped its Marxist pretenses and committed itself to a “social market economy” involving “as much competition as possible—as much planning as necessary.” Although some welcomed this blurring of boundaries between socialism and welfare-state liberalism as a sign of “the end of ideology,” the more radical student left of the 1960s complained that there was little choice between capitalism, the “obsolete communism” of the Marxist-Leninists, and the bureaucratic socialism of western Europe.
6 - Elsewhere, the withdrawal of European colonial powers from Africa and the Middle East created opportunities for new forms of socialism. Terms such as African socialism and Arab socialism were frequently invoked in the 1950s and ’60s, partly because the old colonial powers were identified with capitalist imperialism. In practice, these new kinds of socialism typically combined appeals to indigenous traditions, such as communal land ownership, with the Marxist-Leninist model of one-party rule for the purpose of rapid modernization. In Tanzania, for example, Julius Nyerere developed an egalitarian program of ujamaa (Swahili: “familyhood”) that collectivized village farmlands and attempted, unsuccessfully, to achieve economic self-sufficiency—all under the guidance of a one-party state.
6 - In Asia, by contrast, no distinctive form of socialism emerged. Aside from the communist regimes, Japan was the only country in which a socialist party gained a sizable and enduring following, to the point of occasionally controlling the government or participating in a governing coalition.
6 - Nor has there been a peculiarly Latin American contribution to socialist theory. The regime of Fidel Castro in Cuba tended to follow the Marxist-Leninist path in the 1950s and ’60s, though with increasing moderation in later years, especially after the collapse of the Soviet Union in 1991. Liberation theology called on Christians to give priority to the needs of the poor, but it has not developed an explicitly socialist program. Perhaps the most distinctively Latin American expression of socialist impulses was Venezuelan Pres. Hugo Chávez’s call for a “Bolivarian Revolution.” Apart from the appeal to Simón Bolívar’s reputation as a liberator, however, Chávez did not establish a connection between socialism and Bolívar’s thoughts and deeds.
6 - In many ways, however, the attempt by Salvador Allende to unite Marxists and other reformers in a socialist reconstruction of Chile is most representative of the direction that Latin American socialists have taken since the late 20th century. Elected by a plurality vote in a three-way election in 1970, Allende tried to nationalize foreign corporations and redistribute land and wealth to the poor. These efforts provoked domestic and foreign opposition, which led, in the midst of economic turmoil, to a military coup and Allende’s death—though whether by his or someone else’s hand is not clear.
6 - Several socialist (or socialist-leaning) leaders have followed Allende’s example in winning election to office in Latin American countries. Chávez led the way in 1999 and was followed in the early 21st century by successful electoral campaigns by self-proclaimed socialist or distinctly left-of-centre leaders in Brazil, Chile, Argentina, Uruguay, and Bolivia. Although it would be too much to say that these leaders have shared a common program, they have tended to support increased welfare provision for the poor, nationalization of some foreign corporations, redistribution of land from large landholders to peasants, and resistance to the “neoliberal” policies of the World Bank and the International Monetary Fund.
6 - The most important development in the recent history of socialism is undoubtedly the collapse of communism, first in eastern Europe in 1989 and then in the Soviet Union itself in 1991. Communist parties continued to exist, of course, and some of them remained in power—e.g., in North Korea, Vietnam, Cuba, and China. But by the late 20th century little of Marxism remained in the policies of the CCP, as economic reforms increasingly favoured private ownership of productive property and encouraged market competition. What did remain was the Leninist insistence on one-party rule.
6 - Mikhail Gorbachev’s attempts at glasnost (“openness”) and perestroika (“restructuring”), initiated after he became general secretary of the Communist Party of the Soviet Union in 1985, signaled a move away from one-party rule and the inefficient command economy, in which wages, prices, production, and distribution were determined by bureaucrats. Gorbachev intended perestroika to increase productivity and raise living standards without going far in the direction of a market economy. But glasnost created political opportunities for those who were unhappy with communism, as the downfall of the eastern European regimes indicated; ultimately it prompted a reaction—an attempted coup by a group of hard-line communists in 1991—that failed so swiftly and spectacularly that the Soviet Union itself disintegrated. By the end of the 20th century, communism, though not quite dead, certainly seemed to be dying.
6 - Beginning in the late 20th century, the advent of what many considered a “postindustrial” economy, in which knowledge and information count for more than labour and material production, raised doubts about the relevance of socialism, which was in theory and in practice primarily a response to industrial capitalism. This conviction led to much talk of a “third way”—that is, a centre-left position that would preserve the socialist commitment to equality and welfare while abandoning class-based politics and public ownership of the means of production. In 1995 the British Labour Party under Tony Blair embraced the third way by forsaking its long-standing commitment to the nationalization of basic industries; in general elections two years later, the Labour Party won a landslide victory, and Blair served as prime minister for the next 10 years. Other heads of government who professed the third way in the 1990s included Pres. Bill Clinton of the United States, Chancellor Gerhard Schröder of Germany, and Prime Minister Wim Kok of the Netherlands.
6 - Critics on the left complained that the third way reduced equality to an equal chance to compete in economies in which the rich were growing ever richer and the poor were increasingly disadvantaged. Such a position, they insisted, is hardly socialist. But even these critics seldom called for a return to a centralist form of socialism; instead, they were more likely to advocate a decentralist form of market socialism. As the name implies, market socialism blends elements of a free-market economy with social ownership and control of property. Proposals have varied, but the basic idea is that businesses will compete for profits, as in capitalism, but they will be owned, or at least governed, by those who work in them. The workers in every business will choose their supervisors, control their working conditions, set the prices of their products, and decide how to share the profits—or to cope with the losses—of their enterprise. Market socialism is thus a form of “workplace democracy,” or “economic democracy,” that enables workers not only to vote in political contests but also to have a say in the economic decisions that affect them daily in their work.
6 - If socialism has a future, it may well lie in some form of market socialism. Market socialism promises neither the utopia of the early socialists nor the brave new world that Marx and his followers envisioned as the fulfillment of history. But it does promise to promote cooperation and solidarity rather than competitive individualism, and it aims at reducing, if not eliminating, the class divisions that foster exploitation and alienation. In these respects, this modest, decentralized version of socialism continues to sound the themes that have long inspired people to take up the cause of socialism. Even in Latin America and other places where socialists continue to call for direct, public ownership of natural resources and major industries, they nevertheless leave room for private competition for profits in the marketplace. In one way or another, socialists now seem more interested in bringing the free market under control than in eliminating it completely.

7 - linguistics, the scientific study of language. The word was first used in the middle of the 19th century to emphasize the difference between a newer approach to the study of language that was then developing and the more traditional approach of philology. The differences were and are largely matters of attitude, emphasis, and purpose. The philologist is concerned primarily with the historical development of languages as it is manifest in written texts and in the context of the associated literature and culture. The linguist, though he may be interested in written texts and in the development of languages through time, tends to give priority to spoken languages and to the problems of analyzing them as they operate at a given point in time.
7 - The field of linguistics may be divided in terms of three dichotomies: synchronic versus diachronic, theoretical versus applied, and microlinguistics versus macrolinguistics. A synchronic description of a language describes the language as it is at a given time; a diachronic description is concerned with the historical development of the language and the structural changes that have taken place in it. The goal of theoretical linguistics is the construction of a general theory of the structure of language or of a general theoretical framework for the description of languages; the aim of applied linguistics is the application of the findings and techniques of the scientific study of language to practical tasks, especially to the elaboration of improved methods of language teaching. The terms microlinguistics and macrolinguistics are not yet well established, and they are, in fact, used here purely for convenience. The former refers to a narrower and the latter to a much broader view of the scope of linguistics. According to the microlinguistic view, languages should be analyzed for their own sake and without reference to their social function, to the manner in which they are acquired by children, to the psychological mechanisms that underlie the production and reception of speech, to the literary and the aesthetic or communicative function of language, and so on. In contrast, macrolinguistics embraces all of these aspects of language. Various areas within macrolinguistics have been given terminological recognition: psycholinguistics, sociolinguistics, anthropological linguistics, dialectology, mathematical and computational linguistics, and stylistics. Macrolinguistics should not be identified with applied linguistics. The application of linguistic methods and concepts to language teaching may well involve other disciplines in a way that microlinguistics does not. But there is, in principle, a theoretical aspect to every part of macrolinguistics, no less than to microlinguistics.
7 - A large portion of this article is devoted to theoretical, synchronic microlinguistics, which is generally acknowledged as the central part of the subject; it will be abbreviated henceforth as theoretical linguistics.
7 - Linguistic speculation and investigation, insofar as is known, has gone on in only a small number of societies. To the extent that Mesopotamian, Chinese, and Arabic learning dealt with grammar, their treatments were so enmeshed in the particularities of those languages and so little known to the European world until recently that they have had virtually no impact on Western linguistic tradition. Chinese linguistic and philological scholarship stretches back for more than two millennia, but the interest of those scholars was concentrated largely on phonetics, writing, and lexicography; their consideration of grammatical problems was bound up closely with the study of logic.
7 - Certainly the most interesting non-Western grammatical tradition—and the most original and independent—is that of India, which dates back at least two and one-half millennia and which culminates with the grammar of Panini, of the 5th century bce. There are three major ways in which the Sanskrit tradition has had an impact on modern linguistic scholarship. As soon as Sanskrit became known to the Western learned world, the unravelling of comparative Indo-European grammar ensued, and the foundations were laid for the whole 19th-century edifice of comparative philology and historical linguistics. But, for this, Sanskrit was simply a part of the data; Indian grammatical learning played almost no direct part. Nineteenth-century workers, however, recognized that the native tradition of phonetics in ancient India was vastly superior to Western knowledge, and this had important consequences for the growth of the science of phonetics in the West. Third, there is in the rules or definitions (sutras) of Panini a remarkably subtle and penetrating account of Sanskrit grammar. The construction of sentences, compound nouns, and the like is explained through ordered rules operating on underlying structures in a manner strikingly similar in part to modes of modern theory. As might be imagined, this perceptive Indian grammatical work held great fascination for 20th-century theoretical linguists. A study of Indian logic in relation to Paninian grammar alongside Aristotelian and Western logic in relation to Greek grammar and its successors could bring illuminating insights.
7 - Whereas in ancient Chinese learning a separate field of study that might be called grammar scarcely took root, in ancient India a sophisticated version of this discipline developed early alongside the other sciences. Even though the study of Sanskrit grammar may originally have had the practical aim of keeping the sacred Vedic texts and their commentaries pure and intact, the study of grammar in India in the 1st millennium bce had already become an intellectual end in itself.
7 - The emergence of grammatical learning in Greece is less clearly known than is sometimes implied, and the subject is more complex than is often supposed; here only the main strands can be sampled. The term hē grammatikē technē (“the art of letters”) had two senses. It meant the study of the values of the letters and of accentuation and prosody and, in this sense, was an abstract intellectual discipline; and it also meant the skill of literacy and thus embraced applied pedagogy. This side of what was to become “grammatical” learning was distinctly applied, particular, and less exalted by comparison with other pursuits. Most of the developments associated with theoretical grammar grew out of philosophy and criticism; and in these developments a repeated duality of themes crosses and intertwines.
7 - Much of Greek philosophy was occupied with the distinction between that which exists “by nature” and that which exists “by convention.” So in language it was natural to account for words and forms as ordained by nature (by onomatopoeia—i.e., by imitation of natural sounds) or as arrived at arbitrarily by a social convention. This dispute regarding the origin of language and meanings paved the way for the development of divergences between the views of the “analogists,” who looked on language as possessing an essential regularity as a result of the symmetries that convention can provide, and the views of the “anomalists,” who pointed to language’s lack of regularity as one facet of the inescapable irregularities of nature. The situation was more complex, however, than this statement would suggest. For example, it seems that the anomalists among the Stoics credited the irrational quality of language precisely to the claim that language did not exactly mirror nature. In any event, the anomalist tradition in the hands of the Stoics brought grammar the benefit of their work in logic and rhetoric. This led to the distinction that, in modern theory, is made with the terms signifiant (“what signifies”) and signifié (“what is signified”) or, somewhat differently and more elaborately, with “expression” and “content”; and it laid the groundwork of modern theories of inflection, though by no means with the exhaustiveness and fine-grained analysis reached by the Sanskrit grammarians.
7 - The Alexandrians, who were analogists working largely on literary criticism and text philology, completed the development of the classical Greek grammatical tradition. Dionysius Thrax, in the 2nd century bce, produced the first systematic grammar of Western tradition; it dealt only with word morphology. The study of sentence syntax was to wait for Apollonius Dyscolus, of the 2nd century ce. Dionysius called grammar “the acquaintance with [or observation of] what is uttered by poets and writers,” using a word meaning a less general form of knowledge than what might be called “science.” His typically Alexandrian literary goal is suggested by the headings in his work: pronunciation, poetic figurative language, difficult words, true and inner meanings of words, exposition of form-classes, literary criticism. Dionysius defined a sentence as a unit of sense or thought, but it is difficult to be sure of his precise meaning.
7 - The Romans, who largely took over, with mild adaptations to their highly similar language, the total work of the Greeks, are important not as originators but as transmitters. Aelius Donatus, of the 4th century ce, and Priscian, an African of the 6th century, and their colleagues were slightly more systematic than their Greek models but were essentially retrospective rather than original. Up to this point a field that was at times called ars grammatica was a congeries of investigations, both theoretical and practical, drawn from the work and interests of literacy, scribeship, logic, epistemology, rhetoric, textual philosophy, poetics, and literary criticism. Yet modern specialists in the field still share their concerns and interests. The anomalists, who concentrated on surface irregularity and who looked then for regularities deeper down (as the Stoics sought them in logic) bear a resemblance to contemporary scholars of the transformationalist school. And the philological analogists with their regularizing surface segmentation show striking kinship of spirit with the modern school of structural (or taxonomic or glossematic) grammatical theorists.
7 - It is possible that developments in grammar during the Middle Ages constitute one of the most misunderstood areas of the field of linguistics. It is difficult to relate this period coherently to other periods and to modern concerns because surprisingly little is accessible and certain, let alone analyzed with sophistication. By the mid-20th century the majority of the known grammatical treatises had not yet been made available in full to modern scholarship, so not even their true extent could be classified with confidence. These works must be analyzed and studied in the light of medieval learning, especially the learning of the schools of philosophy then current, in order to understand their true value and place.
7 - The field of linguistics has almost completely neglected the achievements of this period. Students of grammar have tended to see as high points in their field the achievements of the Greeks, the Renaissance growth and “rediscovery” of learning (which led directly to modern school traditions), the contemporary flowering of theoretical study (people usually find their own age important and fascinating), and, since the mid-20th century, the astonishing monument of Panini. Many linguists have found uncongenial the combination of medieval Latin learning and premodern philosophy. Yet medieval scholars might reasonably be expected to have bequeathed to modern scholarship the fruits of more than ordinarily refined perceptions of a certain order. These scholars used, wrote in, and studied Latin, a language that, though not their native tongue, was one in which they were very much at home; such scholars in groups must often have represented a highly varied linguistic background.
7 - Some of the medieval treatises continue the tradition of grammars of late antiquity; so there are versions based on Donatus and Priscian, often with less incorporation of the classical poets and writers. Another genre of writing involves simultaneous consideration of grammatical distinctions and scholastic logic; modern linguists are probably inadequately trained to deal with these writings.
7 - Certainly the most obviously interesting theorizing to be found in this period is contained in the “speculative grammar” of the modistae, who were so called because the titles of their works were often phrased De modis significandi tractatus (“Treatise Concerning the Modes of Signifying”). For the development of the Western grammatical tradition, work of this genre was the second great milestone after the crystallization of Greek thought with the Stoics and Alexandrians. The scholastic philosophers were occupied with relating words and things—i.e., the structure of sentences with the nature of the real world—hence their preoccupation with signification. The aim of the grammarians was to explore how a word (an element of language) matched things apprehended by the mind and how it signified reality. Since a word cannot signify the nature of reality directly, it must stand for the thing signified in one of its modes or properties; it is this discrimination of modes that the study of categories and parts of speech is all about. Thus the study of sentences should lead one to the nature of reality by way of the modes of signifying.
7 - The modistae did not innovate in discriminating categories and parts of speech; they accepted those that had come down from the Greeks through Donatus and Priscian. The great contribution of these grammarians, who flourished between the mid-13th and mid-14th century, was their insistence on a grammar to explicate the distinctions found by their forerunners in the languages known to them. Whether they made the best choice in selecting logic, metaphysics, and epistemology (as they knew them) as the fields to be included with grammar as a basis for the grand account of universal knowledge is less important than the breadth of their conception of the place of grammar. Before the modistae, grammar had not been viewed as a separate discipline but had been considered in conjunction with other studies or skills (such as criticism, preservation of valued texts, foreign-language learning). The Greek view of grammar was rather narrow and fragmented; the Roman view was largely technical. The speculative medieval grammarians (who dealt with language as a speculum, “mirror” of reality) inquired into the fundamentals underlying language and grammar. They wondered whether grammarians or philosophers discovered grammar, whether grammar was the same for all languages, what the fundamental topic of grammar was, and what the basic and irreducible grammatical primes are. Signification was reached by imposition of words on things; i.e., the sign was arbitrary. Those questions sound remarkably like current issues of linguistics, which serves to illustrate how slow and repetitious progress in the field is. While the modistae accepted, by modern standards, a restrictive set of categories, the acumen and sweep they brought to their task resulted in numerous subtle and fresh syntactic observations. A thorough study of the medieval period would greatly enrich the discussion of current questions.
7 - It is customary to think of the Renaissance as a time of great flowering. There is no doubt that linguistic and philological developments of this period are interesting and significant. Two new sets of data that modern linguists tend to take for granted became available to grammarians during this period: (1) the newly recognized vernacular languages of Europe, for the protection and cultivation of which there subsequently arose national academies and learned institutions that live down to the present day; and (2) the languages of Africa, East Asia, the New World, and, later, of Siberia, Central Asia, New Guinea, Oceania, the Arctic, and Australia, which the voyages of discovery opened up. Earlier, the only non-Indo-European grammar at all widely accessible was that of the Hebrews (and to some extent Arabic); Semitic in fact shares many categories with Indo-European in its grammar. Indeed, for many of the exotic languages, scholarship barely passed beyond the most rudimentary initial collection of word lists; grammatical analysis was scarcely approached.
7 - In the field of grammar, the Renaissance did not produce notable innovation or advance. Generally speaking, there was a strong rejection of speculative grammar and a relatively uncritical resumption of late Roman views (as stated by Priscian). This was somewhat understandable in the case of Latin or Greek grammars, since here the task was less evidently that of intellectual inquiry and more that of the schools, with the practical aim of gaining access to the newly discovered ancients. But, aside from the fact that, beginning in the 15th century, serious grammars of European vernaculars were actually written, it is only in particular cases and for specific details (e.g., a mild alteration in the number of parts of speech or cases of nouns) that real departures from Roman grammar can be noted. Likewise, until the end of the 19th century, grammars of the exotic languages, written largely by missionaries and traders, were cast almost entirely in the Roman model, to which the Renaissance had added a limited medieval syntactic ingredient.
7 - From time to time a degree of boldness may be seen in France: Petrus Ramus, a 16th-century logician, worked within a taxonomic framework of the surface shapes of words and inflections, such work entailing some of the attendant trivialities that modern linguistics has experienced (e.g., by dividing up Latin nouns on the basis of equivalence of syllable count among their case forms). In the 17th century a group of Jansenists (followers of the Flemish Roman Catholic reformer Cornelius Otto Jansen) associated with the abbey of Port-Royal in France produced a grammar that has exerted noteworthy continuing influence, even in contemporary theoretical discussion. Drawing their basic view from scholastic logic as modified by rationalism, these people aimed to produce a philosophical grammar that would capture what was common to the grammars of languages—a general grammar, but not aprioristically universalist. This grammar attracted attention from the mid-20th century because it employs certain syntactic formulations that resemble rules of modern transformational grammar.
7 - Roughly from the 15th century to World War II, however, the version of grammar available to the Western public (together with its colonial expansion) remained basically that of Priscian with only occasional and subsidiary modifications, and the knowledge of new languages brought only minor adjustments to the serious study of grammar. As education became more broadly disseminated throughout society by the schools, attention shifted from theoretical or technical grammar as an intellectual preoccupation to prescriptive grammar suited to pedagogical purposes, which started with Renaissance vernacular nationalism. Grammar increasingly parted company with its older fellow disciplines within philosophy as they moved over to the domain known as natural science, and technical academic grammatical study increasingly became involved with issues represented by empiricism versus rationalism and their successor manifestations on the academic scene.
7 - Nearly down to the present day, the grammar of the schools has had only tangential connections with the studies pursued by professional linguists; for most people prescriptive grammar has become synonymous with “grammar,” and the prevailing view held by educated people regards grammar as an item of folk knowledge open to speculation by all, and in nowise a formal science requiring adequate preparation such as is assumed for chemistry.
7 - It is generally agreed that the most outstanding achievement of linguistic scholarship in the 19th century was the development of the comparative method, which comprised a set of principles whereby languages could be systematically compared with respect to their sound systems, grammatical structure, and vocabulary and shown to be “genealogically” related. As French, Italian, Portuguese, Romanian, Spanish, and the other Romance languages had evolved from Latin, so Latin, Greek, and Sanskrit as well as the Celtic, Germanic, and Slavic languages and many other languages of Europe and Asia had evolved from some earlier language, to which the name Indo-European or Proto-Indo-European is now customarily applied. That all the Romance languages were descended from Latin and thus constituted one “family” had been known for centuries; but the existence of the Indo-European family of languages and the nature of their genealogical relationship was first demonstrated by the 19th-century comparative philologists. (The term philology in this context is not restricted to the study of literary languages.)
7 - The main impetus for the development of comparative philology came toward the end of the 18th century, when it was discovered that Sanskrit bore a number of striking resemblances to Greek and Latin. An English orientalist, Sir William Jones, though he was not the first to observe these resemblances, is generally given the credit for bringing them to the attention of the scholarly world and putting forward the hypothesis, in 1786, that all three languages must have “sprung from some common source, which perhaps no longer exists.” By this time, a number of texts and glossaries of the older Germanic languages (Gothic, Old High German, and Old Norse) had been published, and Jones realized that Germanic as well as Old Persian and perhaps Celtic had evolved from the same “common source.” The next important step came in 1822, when the German scholar Jacob Grimm, following the Danish linguist Rasmus Rask (whose work, being written in Danish, was less accessible to most European scholars), pointed out in the second edition of his comparative grammar of Germanic that there were a number of systematic correspondences between the sounds of Germanic and the sounds of Greek, Latin, and Sanskrit in related words. Grimm noted, for example, that where Gothic (the oldest surviving Germanic language) had an f, Latin, Greek, and Sanskrit frequently had a p (e.g., Gothic fotus, Latin pedis, Greek podós, Sanskrit padás, all meaning “foot”); when Gothic had a p, the non-Germanic languages had a b; when Gothic had a b, the non-Germanic languages had what Grimm called an “aspirate” (Latin f, Greek ph, Sanskrit bh). In order to account for these correspondences he postulated a cyclical “soundshift” (Lautverschiebung) in the prehistory of Germanic, in which the original “aspirates” became voiced unaspirated stops (bh became b, etc.), the original voiced unaspirated stops became voiceless (b became p, etc.), and the original voiceless (unaspirated) stops became “aspirates” (p became f). Grimm’s term, “aspirate,” it will be noted, covered such phonetically distinct categories as aspirated stops (bh, ph), produced with an accompanying audible puff of breath, and fricatives (f ), produced with audible friction as a result of incomplete closure in the vocal tract.
7 - In the work of the next 50 years the idea of sound change was made more precise, and, in the 1870s, a group of scholars known collectively as the Junggrammatiker (“young grammarians,” or Neogrammarians) put forward the thesis that all changes in the sound system of a language as it developed through time were subject to the operation of regular sound laws. Though the thesis that sound laws were absolutely regular in their operation (unless they were inhibited in particular instances by the influence of analogy) was at first regarded as most controversial, by the end of the 19th century it was quite generally accepted and had become the cornerstone of the comparative method. Using the principle of regular sound change, scholars were able to reconstruct “ancestral” common forms from which the later forms found in particular languages could be derived. By convention, such reconstructed forms are marked in the literature with an asterisk. Thus, from the reconstructed Proto-Indo-European word for “ten,” *dekm, it was possible to derive Sanskrit daśa, Greek déka, Latin decem, and Gothic taihun by postulating a number of different sound laws that operated independently in the different branches of the Indo-European family. The question of sound change is dealt with in greater detail in the section entitled Historical (diachronic) linguistics.
7 - Analogy has been mentioned in connection with its inhibition of the regular operation of sound laws in particular word forms. This was how the Neogrammarians thought of it. In the course of the 20th century, however, it came to be recognized that analogy, taken in its most general sense, plays a far more important role in the development of languages than simply that of sporadically preventing what would otherwise be a completely regular transformation of the sound system of a language. When a child learns to speak he tends to regularize the anomalous, or irregular, forms by analogy with the more regular and productive patterns of formation in the language; e.g., he will tend to say “comed” rather than “came,” “dived” rather than “dove,” and so on, just as he will say “talked,” “loved,” and so forth. The fact that the child does this is evidence that he has learned or is learning the regularities or rules of his language. He will go on to “unlearn” some of the analogical forms and substitute for them the anomalous forms current in the speech of the previous generation. But in some cases, he will keep a “new” analogical form (e.g., “dived” rather than “dove”), and this may then become the recognized and accepted form.
7 - One of the most original, if not one of the most immediately influential, linguists of the 19th century was the learned Prussian statesman Wilhelm von Humboldt (died 1835). His interests, unlike those of most of his contemporaries, were not exclusively historical. Following the German philosopher Johann Gottfried von Herder (1744–1803), he stressed the connection between national languages and national character: this was but a commonplace of romanticism. More original was Humboldt’s theory of “inner” and “outer” form in language. The outer form of language was the raw material (the sounds) from which different languages were fashioned; the inner form was the pattern, or structure, of grammar and meaning that was imposed upon this raw material and differentiated one language from another. This “structural” conception of language was to become dominant, for a time at least, in many of the major centres of linguistics by the middle of the 20th century. Another of Humboldt’s ideas was that language was something dynamic, rather than static, and was an activity itself rather than the product of activity. A language was not a set of actual utterances produced by speakers but the underlying principles or rules that made it possible for speakers to produce such utterances and, moreover, an unlimited number of them. This idea was taken up by a German philologist, Heymann Steinthal, and, what is more important, by the physiologist and psychologist Wilhelm Wundt, and thus influenced late 19th- and early 20th-century theories of the psychology of language. Its influence, like that of the distinction of inner and outer form, can also be seen in the thought of Ferdinand de Saussure, a Swiss linguist. But its full implications were probably not perceived and made precise until the middle of the 20th century, when the U.S. linguist Noam Chomsky re-emphasized it and made it one of the basic notions of generative grammar (see below Transformational-generative grammar).
7 - Many other interesting and important developments occurred in 19th-century linguistic research, among them work in the areas of phonetics and dialectology. Research in both these fields was promoted by the Neogrammarians’ concern with sound change and by their insistence that prehistoric developments in languages were of the same kind as developments taking place in the languages and dialects currently spoken. The development of phonetics in the West was also strongly influenced at this period, as were many of the details of the more philological analysis of the Indo-European languages, by the discovery of the works of the Indian grammarians who, from the time of the Sanskrit grammarian Panini, if not before, had arrived at a much more comprehensive and scientific theory of phonetics, phonology, and morphology than anything achieved in the West until the modern period.
7 - The term structuralism was used as a slogan and rallying cry by a number of different schools of linguistics, and it is necessary to realize that it has somewhat different implications according to the context in which it is employed. It is convenient first to draw a broad distinction between European and American structuralism and then to treat them separately.
7 - Structural linguistics in Europe is generally said to have begun in 1916 with the posthumous publication of the Cours de Linguistique Générale (Course in General Linguistics) of Ferdinand de Saussure. Much of what is now considered as Saussurean can be seen, though less clearly, in the earlier work of Humboldt, and the general structural principles that Saussure was to develop with respect to synchronic linguistics in the Cours had been applied almost 40 years before (1879) by Saussure himself in a reconstruction of the Indo-European vowel system. The full significance of the work was not appreciated at the time. Saussure’s structuralism can be summed up in two dichotomies (which jointly cover what Humboldt referred to in terms of his own distinction of inner and outer form): (1) langue versus parole and (2) form versus substance. By langue, best translated in its technical Saussurean sense as language system, is meant the totality of regularities and patterns of formation that underlie the utterances of a language; by parole, which can be translated as language behaviour, is meant the actual utterances themselves. Just as two performances of a piece of music given by different orchestras on different occasions will differ in a variety of details and yet be identifiable as performances of the same piece, so two utterances may differ in various ways and yet be recognized as instances, in some sense, of the same utterance. What the two musical performances and the two utterances have in common is an identity of form, and this form, or structure, or pattern, is in principle independent of the substance, or “raw material,” upon which it is imposed. “Structuralism,” in the European sense then, refers to the view that there is an abstract relational structure that underlies and is to be distinguished from actual utterances—a system underlying actual behaviour—and that this is the primary object of study for the linguist.
7 - Two important points arise here: first, that the structural approach is not in principle restricted to synchronic linguistics; second, that the study of meaning, as well as the study of phonology and grammar, can be structural in orientation. In both cases “structuralism” is opposed to “atomism” in the European literature. It was Saussure who drew the terminological distinction between synchronic and diachronic linguistics in the Cours; despite the undoubtedly structural orientation of his own early work in the historical and comparative field, he maintained that, whereas synchronic linguistics should deal with the structure of a language system at a given point in time, diachronic linguistics should be concerned with the historical development of isolated elements—it should be atomistic. Whatever the reasons that led Saussure to take this rather paradoxical view, his teaching on this point was not generally accepted, and scholars soon began to apply structural concepts to the diachronic study of languages. The most important of the various schools of structural linguistics to be found in Europe in the first half of the 20th century included the Prague school, most notably represented by Nikolay Sergeyevich Trubetskoy (died 1938) and Roman Jakobson (died 1982), both Russian émigrés, and the Copenhagen (or glossematic) school, centred around Louis Hjelmslev (died 1965). John Rupert Firth (died 1960) and his followers, sometimes referred to as the London school, were less Saussurean in their approach, but, in a general sense of the term, their approach may also be described appropriately as structural linguistics.
7 - American and European structuralism shared a number of features. In insisting upon the necessity of treating each language as a more or less coherent and integrated system, both European and American linguists of this period tended to emphasize, if not to exaggerate, the structural uniqueness of individual languages. There was especially good reason to take this point of view given the conditions in which American linguistics developed from the end of the 19th century. There were hundreds of indigenous American Indian languages that had never been previously described. Many of these were spoken by only a handful of speakers and, if they were not recorded before they became extinct, would be permanently inaccessible. Under these circumstances, such linguists as Franz Boas (died 1942) were less concerned with the construction of a general theory of the structure of human language than they were with prescribing sound methodological principles for the analysis of unfamiliar languages. They were also fearful that the description of these languages would be distorted by analyzing them in terms of categories derived from the analysis of the more familiar Indo-European languages.
7 - After Boas, the two most influential American linguists were Edward Sapir (died 1939) and Leonard Bloomfield (died 1949). Like his teacher Boas, Sapir was equally at home in anthropology and linguistics, the alliance of which disciplines has endured to the present day in many American universities. Boas and Sapir were both attracted by the Humboldtian view of the relationship between language and thought, but it was left to one of Sapir’s pupils, Benjamin Lee Whorf, to present it in a sufficiently challenging form to attract widespread scholarly attention. Since the republication of Whorf’s more important papers in 1956, the thesis that language determines perception and thought has come to be known as the Sapir-Whorf hypothesis, or the theory of linguistic relativity.
7 - Sapir’s work has always held an attraction for the more anthropologically inclined American linguists. But it was Bloomfield who prepared the way for the later phase of what is now thought of as the most distinctive manifestation of American “structuralism.” When he published his first book in 1914, Bloomfield was strongly influenced by Wundt’s psychology of language. In 1933, however, he published a drastically revised and expanded version with the new title Language; this book dominated the field for the next 30 years. In it Bloomfield explicitly adopted a behaviouristic approach to the study of language, eschewing in the name of scientific objectivity all reference to mental or conceptual categories. Of particular consequence was his adoption of the behaviouristic theory of semantics according to which meaning is simply the relationship between a stimulus and a verbal response. Because science was still a long way from being able to give a comprehensive account of most stimuli, no significant or interesting results could be expected from the study of meaning for some considerable time, and it was preferable, as far as possible, to avoid basing the grammatical analysis of a language on semantic considerations. Bloomfield’s followers pushed even further the attempt to develop methods of linguistic analysis that were not based on meaning. One of the most characteristic features of “post-Bloomfieldian” American structuralism, then, was its almost complete neglect of semantics.
7 - Another characteristic feature, one that was to be much criticized by Chomsky, was its attempt to formulate a set of “discovery procedures”—procedures that could be applied more or less mechanically to texts and could be guaranteed to yield an appropriate phonological and grammatical description of the language of the texts. Structuralism, in this narrower sense of the term, is represented, with differences of emphasis or detail, in the major American textbooks published during the 1950s.
7 - The most significant development in linguistic theory and research in the 20th century was the rise of generative grammar, and, more especially, of transformational-generative grammar, or transformational grammar, as it came to be known. Two versions of transformational grammar were put forward in the mid-1950s, the first by Zellig S. Harris and the second by Noam Chomsky, his pupil. It was Chomsky’s system that attracted the most attention. As first presented by Chomsky in Syntactic Structures (1957), transformational grammar can be seen partly as a reaction against post-Bloomfieldian structuralism and partly as a continuation of it. What Chomsky reacted against most strongly was the post-Bloomfieldian concern with discovery procedures. In his opinion, linguistics should set itself the more modest and more realistic goal of formulating criteria for evaluating alternative descriptions of a language without regard to the question of how these descriptions had been arrived at. The statements made by linguists in describing a language should, however, be cast within the framework of a far more precise theory of grammar than had hitherto been the case, and this theory should be formalized in terms of modern mathematical notions. Within a few years, Chomsky had broken with the post-Bloomfieldians on a number of other points also. He had adopted what he called a “mentalistic” theory of language, by which term he implied that the linguist should be concerned with the speaker’s creative linguistic competence and not his performance, the actual utterances produced. He had challenged the post-Bloomfieldian concept of the phoneme (see below), which many scholars regarded as the most solid and enduring result of the previous generation’s work. And he had challenged the structuralists’ insistence upon the uniqueness of every language, claiming instead that all languages were, to a considerable degree, cut to the same pattern—they shared a certain number of formal and substantive universals.
7 - The effect of Chomsky’s ideas was phenomenal. It is hardly an exaggeration to say that there was no major theoretical issue in linguistics that was debated in terms other than those in which he chose to define it, and every school of linguistics tended to define its position in relation to his. Among the rival schools in the mid-20th century were tagmemics, stratificational grammar, and the Prague school.
7 - Tagmemics was the system of linguistic analysis developed by the U.S. linguist Kenneth L. Pike and his associates in connection with their work as Bible translators. Its foundations were laid during the 1950s, when Pike differed from the post-Bloomfieldian structuralists on a number of principles, and it was further elaborated afterward. Tagmemic analysis was used for analyzing a great many previously unrecorded languages, especially in Central and South America and in West Africa.
7 - Stratificational grammar, developed by the U.S. linguist Sydney M. Lamb, was seen by some linguists in the 1960s and ’70s as an alternative to transformational grammar. Stratificational grammar is perhaps best characterized as a radical modification of post-Bloomfieldian linguistics, but it has many features that link it with European structuralism.
7 - The Prague school has been mentioned above for its importance in the period immediately following the publication of Saussure’s Cours. Many of its characteristic ideas (in particular, the notion of distinctive features in phonology) were taken up by other schools. But there was further development in Prague of the functional approach to syntax (see below). The work of M.A.K. Halliday derived much of its original inspiration from Firth (above), but Halliday provided a more systematic and comprehensive theory of the structure of language than Firth had, and it was quite extensively illustrated.
7 - This section is concerned mainly with a version of structuralism (which may also be called descriptive linguistics) developed by scholars working in a post-Bloomfieldian tradition.
7 - With the great progress made in phonetics in the late 19th century, it had become clear that the question whether two speech sounds were the same or not was more complex than might appear at first sight. Two utterances of what was taken to be the same word might differ quite perceptibly from one occasion of utterance to the next. Some of this variation could be attributed to a difference of dialect or accent and is of no concern here. But even two utterances of the same word by the same speaker might vary from one occasion to the next. Variation of this kind, though it is generally less obvious and would normally pass unnoticed, is often clear enough to the trained phonetician and is measurable instrumentally. It is known that the “same” word is being uttered, even if the physical signal produced is variable, in part, because the different pronunciations of the same word will cluster around some acoustically identifiable norm. But this is not the whole answer, because it is actually impossible to determine norms of pronunciation in purely acoustic terms. Once it has been decided what counts as “sameness” of sound from the linguistic point of view, the permissible range of variation for particular sounds in particular contexts can be measured, and, within certain limits, the acoustic cues for the identification of utterances as “the same” can be determined.
7 - What is at issue is the difference between phonetic and phonological (or phonemic) identity, and for these purposes it will be sufficient to define phonetic identity in terms solely of acoustic “sameness.” Absolute phonetic identity is a theoretical ideal never fully realized. From a purely phonetic point of view, sounds are more or less similar, rather than absolutely the same or absolutely different. Speech sounds considered as units of phonetic analysis in this article are called phones, and, following the normal convention, are represented by enclosing the appropriate alphabetic symbol in square brackets. Thus, [p] will refer to a p sound (i.e., what is described more technically as a voiceless, bilabial stop); and [pit] will refer to a complex of three phones—a p sound, followed by an i sound, followed by a t sound. A phonetic transcription may be relatively broad (omitting much of the acoustic detail) or relatively narrow (putting in rather more of the detail), according to the purpose for which it is intended. A very broad transcription will be used in this article except when finer phonetic differences must be shown.
7 - Phonological, or phonemic, identity was referred to above as “sameness of sound from the linguistic point of view.” Considered as phonological units—i.e., from the point of view of their function in the language—sounds are described as phonemes and are distinguished from phones by enclosing their appropriate symbol (normally, but not necessarily, an alphabetic one) between two slash marks. Thus, /p/ refers to a phoneme that may be realized on different occasions of utterance or in different contexts by a variety of more or less different phones. Phonological identity, unlike phonetic similarity, is absolute: two phonemes are either the same or different, they cannot be more or less similar. For example, the English words “bit” and “pit” differ phonemically in that the first has the phoneme /b/ and the second has the phoneme /p/ in initial position. As the words are normally pronounced, the phonetic realization of /b/ will differ from the phonetic realization of /p/ in a number of different ways: it will be at least partially voiced (i.e., there will be some vibration of the vocal cords), it will be without aspiration (i.e., there will be no accompanying slight puff of air, as there will be in the case of the phone realizing /p/), and it will be pronounced with less muscular tension. It is possible to vary any one or all of these contributory differences, making the phones in question more or less similar, and it is possible to reduce the phonetic differences to the point that the hearer cannot be certain which word, “bit” or “pit,” has been uttered. But it must be either one or the other; there is no word with an initial sound formed in the same manner as /p/ or /b/ that is halfway between the two. This is what is meant by saying that phonemes are absolutely distinct from one another—they are discrete rather than continuously variable.
7 - How it is known whether two phones realize the same phoneme or not is dealt with differently by different schools of linguists. The “orthodox” post-Bloomfieldian school regards the first criterion to be phonetic similarity. Two phones are not said to realize the same phoneme unless they are sufficiently similar. What is meant by “sufficiently similar” is rather vague, but it must be granted that for every phoneme there is a permissible range of variation in the phones that realize it. As far as occurrence in the same context goes, there are no serious problems. More critical is the question of whether two phones occurring in different contexts can be said to realize the same phoneme or not. To take a standard example from English: the phone that occurs at the beginning of the word “pit” differs from the phone that occurs after the initial /s/ of “spit.” The “p sound” occurring after the /s/ is unaspirated (i.e., it is pronounced without any accompanying slight puff of air). The aspirated and unaspirated “p sounds” may be symbolized rather more narrowly as [ph] and [p] respectively. The question then is whether [ph] and [p] realize the same phoneme /p/ or whether each realizes a different phoneme. They satisfy the criterion of phonetic similarity, but this, though a necessary condition of phonemic identity, is not a sufficient one.
7 - The next question is whether there is any pair of words in which the two phones are in minimal contrast (or opposition); that is, whether there is any context in English in which the occurrence of the one rather than the other has the effect of distinguishing two or more words (in the way that [ph] versus [b] distinguishes the so-called minimal pairs “pit” and “bit,” “pan” and “ban,” and so on). If there is, it can be said that, despite their phonetic similarity, the two phones realize (or “belong to”) different phonemes—that the difference between them is phonemic. If there is no context in which the two phones are in contrast (or opposition) in this sense, it can be said that they are variants of the same phoneme—that the difference between them is nonphonemic. Thus, the difference between [ph] and [p] in English is nonphonemic; the two sounds realize, or belong to, the same phoneme, namely /p/. In several other languages—e.g., Hindi—the contrast between such sounds as [ph] and [p] is phonemic, however. The question is rather more complicated than it has been represented here. In particular, it should be noted that [p] is phonetically similar to [b] as well as to [ph] and that, although [ph] and [b] are in contrast, [p] and [b] are not. It would thus be possible to regard [p] and [b] as variants of the same phoneme. Most linguists, however, have taken the alternative view, assigning [p] to the same phoneme as [ph]. Here it will suffice to note that the criteria of phonetic similarity and lack of contrast do not always uniquely determine the assignment of phones to phonemes. Various supplementary criteria may then be invoked.
7 - Phones that can occur and do not contrast in the same context are said to be in free variation in that context, and, as has been shown, there is a permissible range of variation for the phonetic realization of all phonemes. More important than free variation in the same context, however, is systematically determined variation according to the context in which a given phoneme occurs. To return to the example used above: [p] and [ph], though they do not contrast, are not in free variation either. Each of them has its own characteristic positions of occurrence, and neither occurs, in normal English pronunciation, in any context characteristic for the other (e.g., only [ph] occurs at the beginning of a word, and only [p] occurs after s). This is expressed by saying that they are in complementary distribution. (The distribution of an element is the whole range of contexts in which it can occur.) Granted that [p] and [ph] are variants of the same phoneme /p/, it can be said that they are contextually, or positionally, determined variants of it. To use the technical term, they are allophones of /p/. The allophones of a phoneme, then, are its contextually determined variants and they are in complementary distribution.
7 - The post-Bloomfieldians made the assignment of phones to phonemes subject to what is now generally referred to as the principle of bi-uniqueness. The phonemic specification of a word or utterance was held to determine uniquely its phonetic realization (except for free variation), and, conversely, the phonetic description of a word or utterance was held to determine uniquely its phonemic analysis. Thus, if two words or utterances are pronounced alike, then they must receive the same phonemic description; conversely, two words or utterances that have been given the same phonemic analysis must be pronounced alike. The principle of bi-uniqueness was also held to imply that, if a given phone was assigned to a particular phoneme in one position of occurrence, then it must be assigned to the same phoneme in all its other positions of occurrence; it could not be the allophone of one phoneme in one context and of another phoneme in other contexts.
7 - A second important principle of the post-Bloomfieldian approach was its insistence that phonemic analysis should be carried out prior to and independently of grammatical analysis. Neither this principle nor that of bi-uniqueness was at all widely accepted outside the post-Bloomfieldian school, and they have been abandoned by the generative phonologists (see below).
7 - Phonemes of the kind referred to so far are segmental; they are realized by consonantal or vocalic (vowel) segments of words, and they can be said to occur in a certain order relative to one another. For example, in the phonemic representation of the word “bit,” the phoneme /b/ precedes /i/, which precedes /t/. But nonsegmental, or suprasegmental, aspects of the phonemic realization of words and utterances may also be functional in a language. In English, for example, the noun “import” differs from the verb “import” in that the former is accented on the first and the latter on the second syllable. This is called a stress accent: the accented syllable is pronounced with greater force or intensity. Many other languages distinguish words suprasegmentally by tone. For example, in Mandarin Chinese the words haò “day” and haǒ “good” are distinguished from one another in that the first has a falling tone and the second a falling-rising tone; these are realized, respectively, as (1) a fall in the pitch of the syllable from high to low and (2) a change in the pitch of the syllable from medium to low and back to medium. Stress and tone are suprasegmental in the sense that they are “superimposed” upon the sequence of segmental phonemes. The term tone is conventionally restricted by linguists to phonologically relevant variations of pitch at the level of words. Intonation, which is found in all languages, is the variation in the pitch contour or pitch pattern of whole utterances, of the kind that distinguishes (either of itself or in combination with some other difference) statements from questions or indicates the mood or attitude of the speaker (as hesitant, surprised, angry, and so forth). Stress, tone, and intonation do not exhaust the phonologically relevant suprasegmental features found in various languages, but they are among the most important.
7 - A complete phonological description of a language includes all the segmental phonemes and specifies which allophones occur in which contexts. It also indicates which sequences of phonemes are possible in the language and which are not: it will indicate, for example, that the sequences /bl/ and /br/ are possible at the beginning of English words but not /bn/ or /bm/. A phonological description also identifies and states the distribution of the suprasegmental features. Just how this is to be done, however, has been rather more controversial in the post-Bloomfieldian tradition. Differences between the post-Bloomfieldian approach to phonology and approaches characteristic of other schools of structural linguistics will be treated below.
7 - The grammatical description of many, if not all, languages is conveniently divided into two complementary sections: morphology and syntax. The relationship between them, as generally stated, is as follows: morphology accounts for the internal structure of words, and syntax describes how words are combined to form phrases, clauses, and sentences.
7 - There are many words in English that are fairly obviously analyzable into smaller grammatical units. For example, the word “unacceptability” can be divided into un-, accept, abil-, and -ity (abil- being a variant of -able). Of these, at least three are minimal grammatical units, in the sense that they cannot be analyzed into yet smaller grammatical units—un-, abil-, and ity. The status of accept, from this point of view, is somewhat uncertain. Given the existence of such forms as accede and accuse, on the one hand, and of except, exceed, and excuse, on the other, one might be inclined to analyze accept into ac- (which might subsequently be recognized as a variant of ad-) and -cept. The question is left open. Minimal grammatical units like un-, abil-, and -ity are what Bloomfield called morphemes; he defined them in terms of the “partial phonetic-semantic resemblance” holding within sets of words. For example, “unacceptable,” “untrue,” and “ungracious” are phonetically (or, phonologically) similar as far as the first syllable is concerned and are similar in meaning in that each of them is negative by contrast with a corresponding positive adjective (“acceptable,” “true,” “gracious”). This “partial phonetic-semantic resemblance” is accounted for by noting that the words in question contain the same morpheme (namely, un-) and that this morpheme has a certain phonological form and a certain meaning.
7 - Bloomfield’s definition of the morpheme in terms of “partial phonetic-semantic resemblance” was considerably modified and, eventually, abandoned entirely by some of his followers. Whereas Bloomfield took the morpheme to be an actual segment of a word, others defined it as being a purely abstract unit, and the term morph was introduced to refer to the actual word segments. The distinction between morpheme and morph (which is, in certain respects, parallel to the distinction between phoneme and phone) may be explained by means of an example. If a morpheme in English is posited with the function of accounting for the grammatical difference between singular and plural nouns, it may be symbolized by enclosing the term plural within brace brackets. Now the morpheme [plural] is represented in a number of different ways. Most plural nouns in English differ from the corresponding singular forms in that they have an additional final segment. In the written forms of these words, it is either -s or -es (e.g., “cat” : “cats”; “dog” : “dogs”; “fish” : “fishes”). The word segments written -s or -es are morphs. So also is the word segment written -en in “oxen.” All these morphs represent the same morpheme. But there are other plural nouns in English that differ from the corresponding singular forms in other ways (e.g., “mouse” : “mice”; “criterion” : “criteria”; and so on) or not at all (e.g., “this sheep” : “these sheep”). Within the post-Bloomfieldian framework no very satisfactory account of the formation of these nouns could be given. But it was clear that they contained (in some sense) the same morpheme as the more regular plurals.
7 - Morphs that are in complementary distribution and represent the same morpheme are said to be allomorphs of that morpheme. For example, the regular plurals of English nouns are formed by adding one of three morphs on to the form of the singular: /s/, /z/, or /iz/ (in the corresponding written forms both /s/ and /z/ are written -s and /iz/ is written -es). Their distribution is determined by the following principle: if the morph to which they are to be added ends in a “sibilant” sound (e.g., s, z, sh, ch), then the syllabic allomorph /iz/ is selected (e.g., fish-es /fiš-iz/, match-es /mač-iz/); otherwise the nonsyllabic allomorphs are selected, the voiceless allomorph /s/ with morphs ending in a voiceless consonant (e.g., cat-s /kat-s/) and the voiced allomorph /z/ with morphs ending in a vowel or voiced consonant (e.g., flea-s /fli-z/, dog-s /dog-z/). These three allomorphs, it will be evident, are in complementary distribution, and the alternation between them is determined by the phonological structure of the preceding morph. Thus the choice is phonologically conditioned.
7 - Very similar is the alternation between the three principal allomorphs of the past participle ending, /id/, /t/, and /d/, all of which correspond to the -ed of the written forms. If the preceding morph ends with /t/ or /d/, then the syllabic allomorph /id/ is selected (e.g., wait-ed /weit-id/). Otherwise, if the preceding morph ends with a voiceless consonant, one of the nonsyllabic allomorphs is selected—the voiceless allomorph /t/ when the preceding morph ends with a voiceless consonant (e.g., pack-ed /pak-t/) and the voiced allomorph /d/ when the preceding morph ends with a vowel or voiced consonant (e.g., row-ed /rou-d/; tame-d /teim-d/). This is another instance of phonological conditioning. Phonological conditioning may be contrasted with the principle that determines the selection of yet another allomorph of the past participle morpheme. The final /n/ of show-n or see-n (which marks them as past participles) is not determined by the phonological structure of the morphs show and see. For each English word that is similar to “show” and “see” in this respect, it must be stated as a synchronically inexplicable fact that it selects the /n/ allomorph. This is called grammatical conditioning. There are various kinds of grammatical conditioning.
7 - Alternation of the kind illustrated above for the allomorphs of the plural morpheme and the /id/, /d/, and /t/ allomorphs of the past participle is frequently referred to as morphophonemic. Some linguists have suggested that it should be accounted for not by setting up three allomorphs each with a distinct phonemic form but by setting up a single morph in an intermediate morphophonemic representation. Thus, the regular plural morph might be said to be composed of the morphophoneme /Z/ and the most common past-participle morph of the morphophoneme /D/. General rules of morphophonemic interpretation would then convert /Z/ and /D/ to their appropriate phonetic form according to context. This treatment of the question foreshadows, on the one hand, the stratificational treatment and, on the other, the generative approach, though they differ considerably in other respects.
7 - An important concept in grammar and, more particularly, in morphology is that of free and bound forms. A bound form is one that cannot occur alone as a complete utterance (in some normal context of use). For example, -ing is bound in this sense, whereas wait is not, nor is waiting. Any form that is not bound is free. Bloomfield based his definition of the word on this distinction between bound and free forms. Any free form consisting entirely of two or more smaller free forms was said to be a phrase (e.g., “poor John” or “ran away”), and phrases were to be handled within syntax. Any free form that was not a phrase was defined to be a word and to fall within the scope of morphology. One of the consequences of Bloomfield’s definition of the word was that morphology became the study of constructions involving bound forms. The so-called isolating languages, which make no use of bound forms (e.g., Vietnamese), would have no morphology.
7 - The principal division within morphology is between inflection and derivation (or word formation). Roughly speaking, inflectional constructions can be defined as yielding sets of forms that are all grammatically distinct forms of single vocabulary items, whereas derivational constructions yield distinct vocabulary items. For example, “sings,” “singing,” “sang,” and “sung” are all inflectional forms of the vocabulary item traditionally referred to as “the verb to sing”; but “singer,” which is formed from “sing” by the addition of the morph -er (just as “singing” is formed by the addition of -ing), is one of the forms of a different vocabulary item. When this rough distinction between derivation and inflection is made more precise, problems occur. The principal consideration, undoubtedly, is that inflection is more closely integrated with and determined by syntax. But the various formal criteria that have been proposed to give effect to this general principle are not uncommonly in conflict in particular instances, and it probably must be admitted that the distinction between derivation and inflection, though clear enough in most cases, is in the last resort somewhat arbitrary.
7 - Bloomfield and most other linguists have discussed morphological constructions in terms of processes. Of these, the most widespread throughout the languages of the world is affixation; i.e., the attachment of an affix to a base. For example, the word “singing” can be described as resulting from the affixation of -ing to the base sing. (If the affix is put in front of the base, it is a prefix; if it is put after the base, it is a suffix; and if it is inserted within the base, splitting it into two discontinuous parts, it is an infix.) Other morphological processes recognized by linguists need not be mentioned here, but reference may be made to the fact that many of Bloomfield’s followers from the mid-1940s were dissatisfied with the whole notion of morphological processes. Instead of saying that -ing was affixed to sing they preferred to say that sing and -ing co-occurred in a particular pattern or arrangement, thereby avoiding the implication that sing is in some sense prior to or more basic than -ing. The distinction of morpheme and morph (and the notion of allomorphs) was developed in order to make possible the description of the morphology and syntax of a language in terms of “arrangements” of items rather than in terms of “processes” operating upon more basic items. Nowadays, the opposition to “processes” is, except among the stratificationalists, almost extinct. It has proved to be cumbersome, if not impossible, to describe the relationship between certain linguistic forms without deriving one from the other or both from some common underlying form, and most linguists no longer feel that this is in any way reprehensible.
7 - Syntax, for Bloomfield, was the study of free forms that were composed entirely of free forms. Central to his theory of syntax were the notions of form classes and constituent structure. (These notions were also relevant, though less central, in the theory of morphology.) Bloomfield defined form classes, rather imprecisely, in terms of some common “recognizable phonetic or grammatical feature” shared by all the members. He gave as examples the form class consisting of “personal substantive expressions” in English (defined as “the forms that, when spoken with exclamatory final pitch, are calls for a person’s presence or attention”—e.g., “John,” “Boy,” “Mr. Smith”); the form class consisting of “infinitive expressions” (defined as “forms which, when spoken with exclamatory final pitch, have the meaning of a command”—e.g., “run,” “jump,” “come here”); the form class of “nominative substantive expressions” (e.g., “John,” “the boys”); and so on. It should be clear from these examples that form classes are similar to, though not identical with, the traditional parts of speech and that one and the same form can belong to more than one form class.
7 - What Bloomfield had in mind as the criterion for form class membership (and therefore of syntactic equivalence) may best be expressed in terms of substitutability. Form classes are sets of forms (whether simple or complex, free or bound), any one of which may be substituted for any other in a given construction or set of constructions throughout the sentences of the language.
7 - The smaller forms into which a larger form may be analyzed are its constituents, and the larger form is a construction. For example, the phrase “poor John” is a construction analyzable into, or composed of, the constituents “poor” and “John.” Because there is no intermediate unit of which “poor” and “John” are constituents that is itself a constituent of the construction “poor John,” the forms “poor” and “John” may be described not only as constituents but also as immediate constituents of “poor John.” Similarly, the phrase “lost his watch” is composed of three word forms—“lost,” “his,” and “watch”—all of which may be described as constituents of the construction. Not all of them, however, are its immediate constituents. The forms “his” and “watch” combine to make the intermediate construction “his watch”; it is this intermediate unit that combines with “lost” to form the larger phrase “lost his watch.” The immediate constituents of “lost his watch” are “lost” and “his watch”; the immediate constituents of “his watch” are the forms “his” and “watch.” By the constituent structure of a phrase or sentence is meant the hierarchical organization of the smallest forms of which it is composed (its ultimate constituents) into layers of successively more inclusive units. Viewed in this way, the sentence “Poor John lost his watch” is more than simply a sequence of five word forms associated with a particular intonation pattern. It is analyzable into the immediate constituents “poor John” and “lost his watch,” and each of these phrases is analyzable into its own immediate constituents and so on, until, at the last stage of the analysis, the ultimate constituents of the sentence are reached. The constituent structure of the whole sentence is represented by means of a tree diagram in Figure 1.
7 - Each form, whether it is simple or composite, belongs to a certain form class. Using arbitrarily selected letters to denote the form classes of English, “poor” may be a member of the form class A, “John” of the class B, “lost” of the class C, “his” of the class D, and “watch” of the class E. Because “poor John” is syntactically equivalent to (i.e., substitutable for) “John,” it is to be classified as a member of A. So too, it can be assumed, is “his watch.” In the case of “lost his watch” there is a problem. There are very many forms—including “lost,” “ate,” and “stole”—that can occur, as here, in constructions with a member of B and can also occur alone; for example, “lost” is substitutable for “stole the money,” as “stole” is substitutable for either or for “lost his watch.” This being so, one might decide to classify constructions like “lost his watch” as members of C. On the other hand, there are forms that—though they are substitutable for “lost,” “ate,” “stole,” and so on when these forms occur alone—cannot be used in combination with a following member of B (compare “died,” “existed”); and there are forms that, though they may be used in combination with a following member of B, cannot occur alone (compare “enjoyed”). The question is whether one respects the traditional distinction between transitive and intransitive verb forms. It may be decided, then, that “lost,” “stole,” “ate” and so forth belong to one class, C (the class to which “enjoyed” belongs), when they occur “transitively” (i.e., with a following member of B as their object) but to a different class, F (the class to which “died” belongs), when they occur “intransitively.” Finally, it can be said that the whole sentence “Poor John lost his watch” is a member of the form class G. Thus, the constituent structure not only of “Poor John lost his watch” but of a whole set of English sentences can be represented by means of the tree diagram given in Figure 2. New sentences of the same type can be constructed by substituting actual forms for the class labels.
7 - Any construction that belongs to the same form class as at least one of its immediate constituents is described as endocentric; the only endocentric construction in the model sentence above is “poor John.” All the other constructions, according to the analysis, are exocentric. This is clear from the fact that in Figure 2 the letters at the nodes above every phrase other than the phrase A + B (i.e., “poor John,” “old Harry,” and so on) are different from any of the letters at the ends of the lower branches connected directly to these nodes. For example, the phrase D + E (i.e., “his watch,” “the money,” and so forth) has immediately above it a node labelled B, rather than either D or E. Endocentric constructions fall into two types: subordinating and coordinating. If attention is confined, for simplicity, to constructions composed of no more than two immediate constituents, it can be said that subordinating constructions are those in which only one immediate constituent is of the same form class as the whole construction, whereas coordinating constructions are those in which both constituents are of the same form class as the whole construction. In a subordinating construction (e.g., “poor John”), the constituent that is syntactically equivalent to the whole construction is described as the head, and its partner is described as the modifier: thus, in “poor John,” the form “John” is the head, and “poor” is its modifier. An example of a coordinating construction is “men and women,” in which, it may be assumed, the immediate constituents are the word “men” and the word “women,” each of which is syntactically equivalent to “men and women.” (It is here implied that the conjunction “and” is not a constituent, properly so called, but an element that, like the relative order of the constituents, indicates the nature of the construction involved. Not all linguists have held this view.)
7 - One reason for giving theoretical recognition to the notion of constituent is that it helps to account for the ambiguity of certain constructions. A classic example is the phrase “old men and women,” which may be interpreted in two different ways according to whether one associates “old” with “men and women” or just with “men.” Under the first of the two interpretations, the immediate constituents are “old” and “men and women”; under the second, they are “old men” and “women.” The difference in meaning cannot be attributed to any one of the ultimate constituents but results from a difference in the way in which they are associated with one another. Ambiguity of this kind is referred to as syntactic ambiguity. Not all syntactic ambiguity is satisfactorily accounted for in terms of constituent structure.
7 - Bloomfield thought that semantics, or the study of meaning, was the weak point in the scientific investigation of language and would necessarily remain so until the other sciences whose task it was to describe the universe and humanity’s place in it had advanced beyond their present state. In his textbook Language (1933), he had himself adopted a behaviouristic theory of meaning, defining the meaning of a linguistic form as “the situation in which the speaker utters it and the response which it calls forth in the hearer.” Furthermore, he subscribed, in principle at least, to a physicalist thesis, according to which all science should be modelled upon the so-called exact sciences and all scientific knowledge should be reducible, ultimately, to statements made about the properties of the physical world. The reason for his pessimism concerning the prospects for the study of meaning was his feeling that it would be a long time before a complete scientific description of the situations in which utterances were produced and the responses they called forth in their hearers would be available. At the time that Bloomfield was writing, physicalism was more widely held than it is today, and it was perhaps reasonable for him to believe that linguistics should eschew mentalism and concentrate upon the directly observable. As a result, for some 30 years after the publication of Bloomfield’s textbook, the study of meaning was almost wholly neglected by his followers; most American linguists who received their training during this period had no knowledge of, still less any interest in, the work being done elsewhere in semantics.
7 - Two groups of scholars may be seen to have constituted an exception to this generalization: anthropologically minded linguists and linguists concerned with Bible translation. Much of the description of the indigenous languages of America has been carried out since the days of Boas and his most notable pupil Sapir by scholars who were equally proficient both in anthropology and in descriptive linguistics; such scholars have frequently added to their grammatical analyses of languages some discussion of the meaning of the grammatical categories and of the correlations between the structure of the vocabularies and the cultures in which the languages operated. It has already been pointed out that Boas and Sapir and, following them, Whorf were attracted by Humboldt’s view of the interdependence of language and culture and of language and thought. This view was quite widely held by American anthropological linguists (although many of them would not go as far as Whorf in asserting the dependence of thought and conceptualization upon language).
7 - Also of considerable importance in the description of the indigenous languages of America has been the work of linguists trained by the American Bible Society and the Summer Institute of Linguistics, a group of Protestant missionary linguists. Because their principal aim is to produce translations of the Bible, they have necessarily been concerned with meaning as well as with grammar and phonology. This has tempered the otherwise fairly orthodox Bloomfieldian approach characteristic of the group.
7 - The two most important developments in semantics in the mid-20th century were, first, the application of the structural approach to the study of meaning and, second, a better appreciation of the relationship between grammar and semantics. The second of these developments will be treated in the following section, on Transformational-generative grammar. The first, structural semantics, goes back to the period preceding World War II and is exemplified in a large number of publications, mainly by German scholars—Jost Trier, Leo Weisgerber, and their collaborators.
7 - The structural approach to semantics is best explained by contrasting it with the more traditional “atomistic” approach, according to which the meaning of each word in the language is described, in principle, independently of the meaning of all other words. The structuralist takes the view that the meaning of a word is a function of the relationships it contracts with other words in a particular lexical field, or subsystem, and that it cannot be adequately described except in terms of these relationships. For example, the colour terms in particular languages constitute a lexical field, and the meaning of each term depends upon the place it occupies in the field. Although the denotation of each of the words “green,” “blue,” and “yellow” in English is somewhat imprecise at the boundaries, the position that each of them occupies relative to the other terms in the system is fixed: “green” is between “blue” and “yellow,” so that the phrases “greenish yellow” or “yellowish green” and “bluish green” or “greenish blue” are used to refer to the boundary areas. Knowing the meaning of the word “green” implies knowing what cannot as well as what can be properly described as green (and knowing of the borderline cases that they are borderline cases). Languages differ considerably as to the number of basic colour terms that they recognize, and they draw boundaries within the psychophysical continuum of colour at different places. Blue, green, yellow, and so on do not exist as distinct colours in nature, waiting to be labelled differently, as it were, by different languages; they come into existence, for the speakers of particular languages, by virtue of the fact that those languages impose structure upon the continuum of colour and assign to three of the areas thus recognized the words “blue,” “green,” “yellow.”
7 - The language of any society is an integral part of the culture of that society, and the meanings recognized within the vocabulary of the language are learned by the child as part of the process of acquiring the culture of the society in which he is brought up. Many of the structural differences found in the vocabularies of different languages are to be accounted for in terms of cultural differences. This is especially clear in the vocabulary of kinship (to which a considerable amount of attention has been given by anthropologists and linguists), but it holds true of many other semantic fields also. A consequence of the structural differences that exist between the vocabularies of different languages is that, in many instances, it is in principle impossible to translate a sentence “literally” from one language to another.
7 - It is important, nevertheless, not to overemphasize the semantic incommensurability of languages. Presumably, there are many physiological and psychological constraints that, in part at least, determine one’s perception and categorization of the world. It may be assumed that, when one is learning the denotation of the more basic words in the vocabulary of one’s native language, attention is drawn first to what might be called the naturally salient features of the environment and that one is, to this degree at least, predisposed to identify and group objects in one way rather than another. It may also be that human beings are genetically endowed with rather more specific and linguistically relevant principles of categorization. It is possible that, although languages differ in the number of basic colour categories that they distinguish, there is a limited number of hierarchically ordered basic colour categories from which each language makes its selection and that what counts as a typical instance, or focus, of these universal colour categories is fixed and does not vary from one language to another. If this hypothesis is correct, then it is false to say, as many structural semanticists have said, that languages divide the continuum of colour in a quite arbitrary manner. But the general thesis of structuralism is unaffected, for it still remains true that each language has its own unique semantic structure even though the total structure is, in each case, built upon a substructure of universal distinctions.
7 - A generative grammar, in the sense in which Noam Chomsky used the term, is a rule system formalized with mathematical precision that generates, without need of any information that is not represented explicitly in the system, the grammatical sentences of the language that it describes, or characterizes, and assigns to each sentence a structural description, or grammatical analysis. All the concepts introduced in this definition of “generative” grammar will be explained and exemplified in the course of this section. Generative grammars fall into several types; this exposition is concerned mainly with the type known as transformational (or, more fully, transformational-generative). Transformational grammar was initiated by Zellig S. Harris in the course of work on what he called discourse analysis (the formal analysis of the structure of continuous text). It was further developed and given a somewhat different theoretical basis by Chomsky.
7 - Harris distinguished within the total set of grammatical sentences in a particular language (for example, English) two complementary subsets: kernel sentences (the set of kernel sentences being described as the kernel of the grammar) and nonkernel sentences. The difference between these two subsets lies in nonkernel sentences being derived from kernel sentences by means of transformational rules. For example, “The workers rejected the ultimatum” is a kernel sentence that may be transformed into the nonkernel sentences “The ultimatum was rejected by the workers” or “Did the workers reject the ultimatum?” Each of these may be described as a transform of the kernel sentence from which it is derived. The transformational relationship between corresponding active and passive sentences (e.g., “The workers rejected the ultimatum” and “The ultimatum was rejected by the workers”) is conventionally symbolized by the rule N1 V N2 → N2 be V + en by N1, in which N stands for any noun or noun phrase, V for any transitive verb, en for the past participle morpheme, and the arrow (→) instructs one to rewrite the construction to its left as the construction to the right. (There has been some simplification of the rule as it was formulated by Harris.) This rule may be taken as typical of the whole class of transformational rules in Harris’s system: it rearranges constituents (what was the first nominal, or noun, N1, in the kernel sentence is moved to the end of the transform, and what was the second nominal, N2, in the kernel sentence is moved to initial position in the transform), and it adds various elements in specified positions (be, en, and by). Other operations carried out by transformational rules include the deletion of constituents; e.g., the entire phrase “by the workers” is removed from the sentence “The ultimatum was rejected by the workers” by a rule symbolized as N2 be V+en by N1 → N2 be V+en. This transforms the construction on the left side of the arrow (which resulted from the passive transformation) by dropping the by-phrase, thus producing “The ultimatum was rejected.”
7 - Chomsky’s system of transformational grammar, though it was developed on the basis of his work with Harris, differed from Harris’s in a number of respects. It was Chomsky’s system that attracted the most attention and received the most extensive exemplification and further development. As outlined in Syntactic Structures (1957), it comprised three sections, or components: the phrase-structure component, the transformational component, and the morphophonemic component. Each of these components consisted of a set of rules operating upon a certain “input” to yield a certain “output.” The notion of phrase structure may be dealt with independently of its incorporation in the larger system. In the following system of rules, S stands for Sentence, NP for Noun Phrase, VP for Verb Phrase, Det for Determiner, Aux for Auxiliary (verb), N for Noun, and V for Verb stem.
7 - This is a simple phrase-structure grammar. It generates and thereby defines as grammatical such sentences as “The man will hit the ball,” and it assigns to each sentence that it generates a structural description. The kind of structural description assigned by a phrase-structure grammar is, in fact, a constituent structure analysis of the sentence.
7 - In these rules, the arrow can be interpreted as an instruction to rewrite (this is to be taken as a technical term) whatever symbol appears to the left of the arrow as the symbol or string of symbols that appears to the right of the arrow. For example, rule (2) rewrites the symbol VP as the string of symbols Verb + NP, and it thereby defines Verb + NP to be a construction of the type VP. Or, alternatively and equivalently, it says that constructions of the type VP may have as their immediate constituents constructions of the type Verb and NP (combined in that order). Rule (2) can be thought of as creating or being associated with the tree structure in Figure 3.
7 - Rules (1)–(8) do not operate in isolation but constitute an integrated system. The symbol S (standing mnemonically for “sentence”) is designated as the initial symbol. This information is not given in the rules (1)–(8), but it can be assumed either that it is given in a kind of protocol statement preceding the grammatical rules or that there is a universal convention according to which S is always the initial symbol. It is necessary to begin with a rule that has the initial symbol on the left. Thereafter any rule may be applied in any order until no further rule is applicable; in doing so, a derivation can be constructed of one of the sentences generated by the grammar. If the rules are applied in the following order: (1), (2), (3), (3), (4), (5), (5), (6), (6), (7), (8), then assuming that “the” is selected on both applications of (5), “man” on one application of (6), and “ball” on the other, “will” on the application of (7), and “hit” on the application of (8), the following derivation of the sentence “The man will hit the ball” will have been constructed:
7 - Many other derivations of this sentence are possible, depending on the order in which the rules are applied. The important point is that all these different derivations are equivalent in that they can be reduced to the same tree diagram; namely, the one shown in Figure 4. If this is compared with the system of rules, it will be seen that each application of each rule creates or is associated with a portion (or subtree) of the tree. The tree diagram, or phrase marker, may now be considered as a structural description of the sentence “The man hit the ball.” It is a description of the constituent structure, or phrase structure, of the sentence, and it is assigned by the rules that generate the sentence.
7 - It is important to interpret the term generate in a static, rather than a dynamic, sense. The statement that the grammar generates a particular sentence means that the sentence is one of the totality of sentences that the grammar defines to be grammatical or well formed. All the sentences are generated, as it were, simultaneously. The notion of generation must be interpreted as would be a mathematical formula containing variables. For example, in evaluating the formula y 2 + y for different values of y, one does not say that the formula itself generates these various resultant values (2, when y = 1; 5, when y = 2; etc.) one after another or at different times; one says that the formula generates them all simultaneously or, better still perhaps, timelessly. The situation is similar for a generative grammar. Although one sentence rather than another can be derived on some particular occasion by making one choice rather than another at particular places in the grammar, the grammar must be thought of as generating all sentences statically or timelessly.
7 - It has been noted that, whereas a phrase-structure grammar is one that consists entirely of phrase-structure rules, a transformational grammar (as formalized by Chomsky) includes both phrase-structure and transformational rules (as well as morphophonemic rules). The transformational rules depend upon the prior application of the phrase-structure rules and have the effect of converting, or transforming, one phrase marker into another. What is meant by this statement may be clarified first with reference to a purely abstract and very simple transformational grammar, in which the letters stand for constituents of a sentence (and S stands for “sentence”):
7 - The first five rules are phrase-structure rules (PS rules); rule (6) is a transformational rule (T rule). The output of rules (1)–(5) is the terminal string a + b + c + e + f + d + g + h, which has associated with it the structural description indicated by the phrase marker shown in Figure 5 (left). Rule (6) applies to this terminal string of the PS rules and the associated phrase marker. It has the effect of deleting C (and the constituents of C) and permuting A and D (together with their constituents). The result is the string of symbols d + g + h + a + b, with the associated phrase marker shown in Figure 5 (right).
7 - The phrase marker shown in Figure 5 (left) may be described as underlying, and the phrase marker shown in Figure 5 (right) as derived with respect to rule (6). One of the principal characteristics of a transformational rule is its transformation of an underlying phrase marker into a derived phrase marker in this way. Transformational rules, in contrast with phrase-structure rules, are also formally more heterogeneous and may have more than one symbol on the left-hand side of the arrow. The linguistic importance of these abstract considerations may be explained with reference to the relationship that holds in English between active and passive sentences.
7 - Chomsky’s rule for relating active and passive sentences (as given in Syntactic Structures) is very similar, at first sight, to Harris’s, discussed above. Chomsky’s rule is:
7 - This rule, called the passive transformation, presupposes and depends upon the prior application of a set of phrase-structure rules. For simplicity, the passive transformation may first be considered in relation to the set of terminal strings generated by the phrase-structure rules (1)–(8) given earlier. The string “the + man + will + hit + the + ball” (with its associated phrase marker, as shown in Figure 4) can be treated not as an actual sentence but as the structure underlying both the active sentence “The man will hit the ball” and the corresponding passive “The ball will be hit by the man.” The passive transformation is applicable under the condition that the underlying, or “input,” string is analyzable in terms of its phrase structure as NP - Aux - V - NP (the use of subscript numerals to distinguish the two NPs in the formulation of the rule is an informal device for indicating the operation of permutation). In the phrase marker in Figure 4, “the” + “man” are constituents of NP, “will” is a constituent of Aux, “hit” is a constituent of V, and “the” + “ball” are constituents of NP. The whole string is therefore analyzable in the appropriate sense, and the passive transformation converts it into the string “the + ball + will + be + en + hit + by + the + man.” A subsequent transformational rule will permute “en + hit” to yield “hit + en,” and one of the morphophonemic rules will then convert “hit + en” to “hit” (as “ride + en” will be converted to “ridden”; “open + en” to “opened,” and so on).
7 - Every transformational rule has the effect of converting an underlying phrase marker into a derived phrase marker. The manner in which the transformational rules assign derived constituent structure to their input strings is one of the major theoretical problems in the formalization of transformational grammar. Here it can be assumed not only that “be + en” is attached to Aux and “by” to NP (as indicated by the plus signs in the rule as it has been formulated above) but also that the rest of the derived structure is as shown in Figure 6. The phrase marker in Figure 6 formalizes the fact, among others, that “the ball” is the subject of the passive sentence “The ball will be hit by the man,” whereas “the man” is the subject of the corresponding active “The man will hit the ball” (compare Figure 4).
7 - Although the example above is a very simple one, and only a single transformational rule has been considered independently of other transformational rules in the same system, the passive transformation must operate, not only upon simple noun phrases like “the man” or “the ball,” but upon noun phrases that contain adjectives (“the old man”), modifying phrases (“the man in the corner”), relative clauses (“the man who checked in last night”), and so forth. The incorporation, or embedding, of these other structures with the noun phrase will be brought about by the prior application of other transformational rules. It should also be clear that the phrase-structure rules require extension to allow for the various forms of the verb (“is hitting,” “hit,” “was hitting,” “has hit,” “has been hitting,” etc.) and for the distinction of singular and plural.
7 - It is important to note that, unlike Harris’s, Chomsky’s system of transformational grammar does not convert one sentence into another: the transformational rules operate upon the structures underlying sentences and not upon actual sentences. A further point is that even the simplest sentences (i.e., kernel sentences) require the application of at least some transformational rules. Corresponding active and passive sentences, affirmative and negative sentences, declarative and interrogative sentences, and so on are formally related by deriving them from the same underlying terminal string of the phrase-structure component. The difference between kernel sentences and nonkernel sentences in Syntactic Structures (in a later system of Chomsky the category of kernel sentences is not given formal recognition at all) resides in the fact that kernel sentences are generated without the application of any optional transformations. Nonkernel sentences require the application of both optional and obligatory transformations, and they differ one from another in that a different selection of optional transformations is made.
7 - Chomsky’s system of transformational grammar was substantially modified in 1965. Perhaps the most important modification was the incorporation, within the system, of a semantic component, in addition to the syntactic component and phonological component. (The phonological component may be thought of as replacing the morphophonemic component of Syntactic Structures.) The rules of the syntactic component generate the sentences of the language and assign to each not one but two structural analyses: a deep structure analysis as represented by the underlying phrase marker, and a surface structure analysis, as represented by the final derived phrase marker. The underlying phrase marker is assigned by rules of the base (roughly equivalent to the PS [Phrase-Structure] rules of the earlier system); the derived phrase marker is assigned by the transformational rules. The interrelationship of the four sets of rules is shown diagrammatically in Figure 7. The meaning of the sentence is derived (mainly, if not wholly) from the deep structure by means of the rules of semantic interpretation; the phonetic realization of the sentence is derived from its surface structure by means of the rules of the phonological component. The grammar (“grammar” is now to be understood as covering semantics and phonology, as well as syntax) is thus an integrated system of rules for relating the pronunciation of a sentence to its meaning. The syntax, and more particularly the base, is at the “heart” of the system, as it were: it is the base component (as the arrows in the diagram indicate) that generates the infinite class of structures underlying the well-formed sentences of a language. These structures are then given a semantic and phonetic “interpretation” by the other components.
7 - The base consists of two parts: a set of categorial rules and a lexicon. Taken together, they fulfill a similar function to that fulfilled by the phrase-structure rules of the earlier system. But there are many differences of detail. Among the most important is that the lexicon (which may be thought of as a dictionary of the language cast in a particular form) lists, in principle, all the vocabulary words in the language and associates with each all the syntactic, semantic, and phonological information required for the correct operation of the rules. This information is represented in terms of what are called features. For example, the entry for “boy” might say that it has the syntactic features: [+ Noun], [+ Count], [+ Common], [+ Animate], and [+ Human]. The categorial rules generate a set of phrase markers that have in them, as it were, a number of “slots” to be filled with items from the lexicon. With each such “slot” there is associated a set of features that define the kind of item that can fill the “slot.” If a phrase marker is generated with a “slot” for the head of a noun phrase specified as requiring an animate noun (i.e., a noun having the feature [+ Animate]), the item “boy” would be recognized as being compatible with this specification and could be inserted in the “slot” by the rule of lexical substitution. Similarly, it could be inserted in “slots” specified as requiring a common noun, a human noun, or a countable noun, but it would be excluded from positions that require an abstract noun (e.g., “sincerity”) or an uncountable noun (e.g., “water”). By drawing upon the syntactic information coded in feature notation in the lexicon, the categorial rules might permit such sentences as “The boy died,” while excluding (and thereby defining as ungrammatical) such nonsentences as “The boy elapsed.”
7 - One of the most controversial topics in the development of transformational grammar was the relationship between syntax and semantics. Scholars working in the field agreed that there is a considerable degree of interdependence between the two, and the problem was how to formalize this interdependence. One school of linguists, called generative semanticists, accepted the general principles of transformational grammar but challenged Chomsky’s conception of deep structure as a separate and identifiable level of syntactic representation. In their opinion, the basic component of the grammar should consist of a set of rules for the generation of well-formed semantic representations. These would then be converted by a succession of transformational rules into strings of words with an assigned surface-structure syntactic analysis, there being no place in the passage from semantic representation to surface structure identifiable as Chomsky’s deep structure. Chomsky himself denied that there is any real difference between the two points of view and has maintained that the issue is purely one of notation. That this argument could be put forward by one party to the controversy and rejected by the other is perhaps a sufficient indication of the uncertainty of the evidence. Of greater importance than the overt issues, in so far as they are clear, was the fact that linguists were now studying much more intensively than they had in the past the complexities of the interdependence of syntax, on the one hand, and semantics and logic, on the other.
7 - The role of the phonological component of a generative grammar of the type outlined by Chomsky is to assign a phonetic “interpretation” to the strings of words generated by the syntactic component. These strings of words are represented in a phonological notation (taken from the lexicon) and have been provided with a surface-structure analysis by the transformational rules (see Figure 7). The phonological elements out of which the word forms are composed are segments consisting of what are referred to technically as distinctive features (following the usage of the Prague school, see below The Prague school). For example, the word form “man,” represented phonologically, is composed of three segments: the first consists of the features [+ consonantal], [+ bilabial], [+ nasal], etc.; the second of the features [+ vocalic], [+ front], [+ open], etc.; and the third of the features [+ consonantal], [+ alveolar], [+ nasal], etc. (These features should be taken as purely illustrative; there is some doubt about the definitive list of distinctive features.) Although these segments may be referred to as the “phonemes” /m/, /a/, and /n/, they should not be identified theoretically with units of the kind discussed in the section on Phonology under Structural linguistics. They are closer to what many American structural linguists called “morphophonemes” or the Prague school linguists labelled “archiphonemes,” being unspecified for any feature that is contextually redundant or predictable. For instance, the first segment of the phonological representation of “man” will not include the feature [+ voice]; because nasal consonants are always phonetically voiced in this position in English, the feature [+ voice] can be added to the phonetic specification by a rule of the phonological component.
7 - The system of tagmemic analysis, as presented by Kenneth L. Pike, was developed for the analysis not only of language but of all of human behaviour that manifests the property of patterning. In the following treatment, only language will be discussed.
7 - Every language is said to be trimodal—i.e., structured in three modes: phonology, grammar, and lexicon. These modes are interrelated but have a considerable degree of independence and must be described in their own terms. Phonology and lexicon should not be seen as mere appendages to grammar, the former simply specifying which phonemes can combine to form morphemes (or morphs), and the latter simply listing the morphemes and other meaningful units with a description of their meaning. There are levels of structure in each of the modes, and the units of one level are not necessarily coterminous with those of another. Phonemes, for example, may combine to form syllables and syllables to form phonological words (“phonological word” is defined as the domain of some phonological process such as accentuation, assimilation, or dissimilation), but the morpheme (or morph) will not necessarily consist of an integral number of syllables, still less of a single syllable. Nor will the word as a grammatical unit necessarily coincide with the phonological word. Similarly, the units of lexical analysis, sometimes referred to as lexemes (in one sense of this term), are not necessarily identifiable as single grammatical units, whether as morphemes, words, or phrases. No priority, then, is ascribed to any one of the three modes.
7 - The originality of tagmemic analysis and the application of the term tagmeme is most clearly manifest in the domain of grammar. By a tagmeme is meant an element of a construction, the element in question being regarded as a composite unit, described in such terms as “slot-filler” or “function-class.” For example, one of the tagmemes required for the analysis of English at the syntactic level might be noun-as-subject, in which “noun” refers to a class of substitutable, or paradigmatically related, morphemes or words capable of fulfilling a certain grammatical function, and “subject” refers to the function that may be fulfilled by one or more classes of elements. In the tagmeme noun-as-subject—which, using the customary tagmemic symbolism, may be represented as Subject:noun—the subject slot is filled by a noun. When a particular tagmeme is identified in the analysis of an actual utterance, it is said to be manifested by the particular member of the grammatical class that occurs in the appropriate slot in the utterance. For example, in the utterance “John is asleep,” the subject tagmeme is manifested by the noun “John.” Tagmemicists insist that tagmemes, despite their bipartite structure, are single units. In grammatical analysis, the distribution of tagmemes, not simply of classes, is stated throughout the sentences of the language. Subject:noun is a different tagmeme from Object:noun, as it is also a different tagmeme from Subject:pronoun.
7 - Within the grammar of a language there is a hierarchy of levels, units of one level being composed of sequences of units of the level below. In many languages, five such levels are recognized, defined in terms of the following units: morpheme, word, phrase, clause, and sentence. (The term level is being used in a different sense from that in which it was used earlier to refer to phonology and grammar.) The difference between morphology and syntax is simply a difference between two of these five levels, no greater than the difference, for example, between the phrase level and the clause level. Normally, tagmemes at one level are manifested by units belonging to the level below: clause tagmemes by phrases, phrase tagmemes by words, and so on. Intermediate levels may, however, be skipped. For example, the subject tagmeme in a clause may be manifested by a single word in English (e.g., “John,” “water”) and not necessarily by a phrase (“the young man”).
7 - It is also possible for there to be loop-backs in the grammatical hierarchy of a language. This means that a unit of higher level may be embedded within the structure of a unit of lower level; for example, a clause may fill a slot within a phrase (e.g., “who arrived late,” in “the man who arrived late”).

8 - war, in the popular sense, a conflict between political groups involving hostilities of considerable duration and magnitude. In the usage of social science, certain qualifications are added. Sociologists usually apply the term to such conflicts only if they are initiated and conducted in accordance with socially recognized forms. They treat war as an institution recognized in custom or in law. Military writers usually confine the term to hostilities in which the contending groups are sufficiently equal in power to render the outcome uncertain for a time. Armed conflicts of powerful states with isolated and powerless peoples are usually called pacifications, military expeditions, or explorations; with small states, they are called interventions or reprisals; and with internal groups, rebellions or insurrections. Such incidents, if the resistance is sufficiently strong or protracted, may achieve a magnitude that entitles them to the name “war.”
8 - In all ages war has been an important topic of analysis. In the latter part of the 20th century, in the aftermath of two World Wars and in the shadow of nuclear, biological, and chemical holocaust, more was written on the subject than ever before. Endeavours to understand the nature of war, to formulate some theory of its causes, conduct, and prevention, are of great importance, for theory shapes human expectations and determines human behaviour. The various schools of theorists are generally aware of the profound influence they can exercise upon life, and their writings usually include a strong normative element, for, when accepted by politicians, their ideas can assume the characteristics of self-fulfilling prophecies.
8 - The analysis of war may be divided into several categories. Philosophical, political, economic, technological, legal, sociological, and psychological approaches are frequently distinguished. These distinctions indicate the varying focuses of interest and the different analytical categories employed by the theoretician, but most of the actual theories are mixed because war is an extremely complex social phenomenon that cannot be explained by any single factor or through any single approach.
8 - Reflecting changes in the international system, theories of war have passed through several phases in the course of the past three centuries. After the ending of the wars of religion, about the middle of the 17th century, wars were fought for the interests of individual sovereigns and were limited both in their objectives and in their scope. The art of maneuver became decisive, and analysis of war was couched accordingly in terms of strategies. The situation changed fundamentally with the outbreak of the French Revolution, which increased the size of forces from small professional to large conscript armies and broadened the objectives of war to the ideals of the revolution, ideals that appealed to the masses who were subject to conscription. In the relative order of post-Napoleonic Europe, the mainstream of theory returned to the idea of war as a rational, limited instrument of national policy. This approach was best articulated by the Prussian military theorist Carl von Clausewitz in his famous classic On War (1832–37).
8 - World War I, which was “total” in character because it resulted in the mobilization of entire populations and economies for a prolonged period of time, did not fit into the Clausewitzian pattern of limited conflict, and it led to a renewal of other theories. These no longer regarded war as a rational instrument of state policy. The theorists held that war, in its modern, total form, if still conceived as a national state instrument, should be undertaken only if the most vital interests of the state, touching upon its very survival, are concerned. Otherwise, warfare serves broad ideologies and not the more narrowly defined interests of a sovereign or a nation. Like the religious wars of the 17th century, war becomes part of “grand designs,” such as the rising of the proletariat in communist eschatology or the Nazi doctrine of a master race.
8 - Some theoreticians have gone even further, denying war any rational character whatsoever. To them war is a calamity and a social disaster, whether it is afflicted by one nation upon another or conceived of as afflicting humanity as a whole. The idea is not new—in the aftermath of the Napoleonic Wars it was articulated, for example, by Tolstoy in the concluding chapter of War and Peace (1865–69). In the second half of the 20th century it gained new currency in peace research, a contemporary form of theorizing that combines analysis of the origins of warfare with a strong normative element aiming at its prevention. Peace research concentrates on two areas: the analysis of the international system and the empirical study of the phenomenon of war.
8 - World War II and the subsequent evolution of weapons of mass destruction made the task of understanding the nature of war even more urgent. On the one hand, war had become an intractable social phenomenon, the elimination of which seemed to be an essential precondition for the survival of mankind. On the other hand, the use of war as an instrument of policy was calculated in an unprecedented manner by the nuclear superpowers, the United States and the Soviet Union. War also remained a stark but rational instrumentality in certain more limited conflicts, such as those between Israel and the Arab nations. Thinking about war, consequently, became increasingly more differentiated because it had to answer questions related to very different types of conflict.
8 - Clausewitz cogently defines war as a rational instrument of foreign policy: “an act of violence intended to compel our opponent to fulfill our will.” Modern definitions of war, such as “armed conflict between political units,” generally disregard the narrow, legalistic definitions characteristic of the 19th century, which limited the concept to formally declared war between states. Such a definition includes civil wars but at the same time excludes such phenomena as insurrections, banditry, or piracy. Finally, war is generally understood to embrace only armed conflicts on a fairly large scale, usually excluding conflicts in which fewer than 50,000 combatants are involved.
8 - Contemporary theories of the causes of war divide roughly into two major schools. One attributes war to certain innate biological and psychological factors or drives, the other attributes it to certain social relations and institutions. Both schools include optimists and pessimists concerning the preventability of war.
8 - Theories centring upon man’s innate drives are developed by ethologists, who draw analogies from animal behaviour, and also by psychologists and psychoanalysts.
8 - Ethologists start with the persuasive argument that study of animal warfare may contribute toward an understanding of war as employed by man. The behaviour of monkeys and apes in captivity and the behaviour of young children, for example, show basic similarities. In both cases it is possible to observe that aggressive behaviour usually arises from several drives: rivalry for possession, the intrusion of a stranger, or frustration of an activity. The major conflict situations leading to aggression among animals, especially those concerning access of males to females and control of a territory for feeding and breeding, are usually associated with patterns of dominance.
8 - The analogies of animal to human behaviour drawn by many ethologists, however, are severely questioned by their more restrained colleagues as well as by many social scientists. The term “aggression,” for example, is imprecisely and inconsistently used, often referring merely to the largely symbolic behaviour of animals involving such signals as grimaces.
8 - Observed animal behaviour can be regarded as a possible important source of inspiration for hypotheses, but these must then be checked through the study of actual human behaviour. As this has not yet been adequately done, the hypotheses advanced have little foundation and are merely interesting ideas to be investigated. Further, human behaviour is not fixed to the extent that animal behaviour is, partly because man rapidly evolves different patterns of behaviour in response to environmental factors, such as geography, climate, and contact with other social groups. The variety of these behaviour patterns is such that they can be used on both sides of an argument concerning, for example, whether or not men have an innate tendency to be aggressive.
8 - Two particularly interesting subjects studied by ethologists are the effects of overcrowding on animals and animal behaviour regarding territory. The study of overcrowding is incomplete, and the findings that normal behaviour patterns tend to break down in such conditions and that aggressive behaviour often becomes prominent are subject to the qualification that animal and human reactions to overcrowding may be different. Ethologists have also advanced plausible hypotheses concerning biological means of population control through reduced fertility that occurs when animal populations increase beyond the capacity of their environment. Whether such biological control mechanisms operate in human society, however, requires further investigation.
8 - Findings concerning the “territorial imperative” in animals—that is, the demarcation and defense against intrusion of a fixed area for feeding and breeding—are even more subject to qualification when an analogy is drawn from them to human behaviour. The analogy between an animal territory and a territorial state is obviously extremely tenuous. In nature the territories of members of a species differ in extent but usually seem to be provided with adequate resources, and use of force in their defense is rarely necessary, as the customary menacing signals generally lead to the withdrawal of potential rivals. This scarcely compares with the sometimes catastrophic defense of the territory of a national state.
8 - One school of theorists has postulated that the major causes of war can be found in man’s psychological nature. Such psychological approaches range from very general, often merely intuitive assertions regarding human nature to complex analyses utilizing the concepts and techniques of modern psychology. The former category includes a wide range of ethical and philosophical teaching and insights, including the works of such figures as St. Augustine and the 17th-century Dutch philosopher Benedict de Spinoza.
8 - Modern writers utilizing psychological approaches emphasize the significance of psychological maladjustments or complexes and of false, stereotyped images held by decision makers of other countries and their leaders. Some psychologists posit an innate aggressiveness in man. Others concentrate upon public opinion and its influence, particularly in times of tension. Others stress the importance of decision makers and the need for their careful selection and training. Most believe that an improved social adjustment of individuals would decrease frustration, insecurity, and fear and would reduce the likelihood of war. All of them believe in the importance of research and education. Still, the limitations of such approaches derive from their very generality. Also, whether the psychological premises are optimistic or pessimistic about the nature of man, one cannot ignore the impact upon human behaviour of social and political institutions that give man the opportunities to exercise his good or evil propensities and to impose restraints upon him.
8 - Whereas psychological explanations of war contain much that seems to be valid, they are insufficient because man behaves differently in different social contexts. Hence, many thinkers have sought their explanations in these contexts, focusing either on the internal organization of states or on the international system within which these operate. The most voluminous and influential theories attributing war to the nature of the state fall into two broad streams, which can be loosely called liberal and socialist.
8 - The early or classical liberals of the 18th and 19th centuries distinguished three basic elements in their analysis—individuals, society, and the state—and regarded the state as the outcome of the interaction of the former two. They assumed that society is self-regulating and that the socioeconomic system is able to run smoothly with little interference from the government. Economy, decentralization, and freedom from governmental control were the classical liberal’s main concerns, as shown particularly clearly in the writings of John Stuart Mill. They accepted the necessity of maintaining defense but postulated the existence of a basic harmony of interests among states, which would minimize the incidence of wars. Economic cooperation based upon an international division of labour and upon free trade would be in the interests of everybody—commerce would be the great panacea, the rational substitute for war.
8 - In explanation of wars that did occur, however, liberals emphasized a variety of factors. First, they focused on autocratic governments, which were presumed to wage war against the wishes of peacefully inclined people. It thus became a major tenet of liberal political philosophy that war could be eliminated by introducing universal suffrage because the people would surely vote out of office any belligerently inclined government. From the early American pamphleteer Thomas Paine onward, a major school of liberals supported republicanism and stressed the peaceful impact of public opinion. Although they could not agree about actual policies, they stressed certain general ideas concerning relations between states, paralleling their laissez-faire ideas of the internal organization of the state with ideas of a minimum amount of international organization, use of force strictly limited to repelling aggression, the importance of public opinion and of democratically elected governments, and rational resolution of conflicts and disputes. Later in the course of the 19th century, however, and especially after World War I, liberals began to accept the conclusion that an unregulated international society did not automatically tend toward peace and advocated international organization as a corrective.
8 - Karl Marx attributed war not to the behaviour of states but to the class structure of society. To him wars occurred not as an often voluntary instrument of state policy but as the result of a clash of social forces. To Marx the state was merely a political superstructure; the primary, determining factor lies in the capitalist mode of production, which leads to the development of two antagonistic classes: the bourgeoisie and the proletariat. The bourgeoisie controls governmental machinery in its own interests. In its international relations, the capitalist state engages in wars because it is driven by the dynamism of its system—the constantly growing need for raw materials, markets, and supplies of cheap labour. The only way to avoid war is to remove its basic cause, by replacing capitalism with socialism, thus abolishing both class struggle and states. The Marxist doctrine, however, gave no clear guidance about the interim period before the millennium is reached; and the international solidarity of the proletariat proved a myth when war broke out in 1914, facing the European Social Democratic parties with the problem of adopting an attitude to the outbreak of the war. The Second International of working-class parties had repeatedly passed resolutions urging the working classes to bring pressure upon their respective governments to prevent war, but, once war had broken out, each individual party chose to regard it as defensive for its own state and to participate in the war effort. This was explained by Lenin as being due to a split in the organization of the proletariat that could be overcome only through the activity of a rigidly organized revolutionary vanguard.
8 - Socialists in the West turned increasingly, although in varying degrees, to revisionist interpretations of Marxism and returned to their attempts to revise socioeconomic structures through evolutionary constitutional processes, seeing this as the only possible means of preventing wars. In the Soviet Union the socialist theory of war changed as the new communist regime responded to changes in circumstances. Soviet theoreticians distinguished three major types of war: between capitalist states, between capitalist and socialist states, and colonial wars of liberation. The internecine wars among capitalist states were supposed to arise from capitalist competition and imperialist rivalries, such as those that led to the two World Wars. They were desirable, for they weakened the capitalist camp. A war between capitalist and socialist states was one that clearly expressed the basic principle of class struggle and was, therefore, one for which the socialist states must prepare. Finally, wars of colonial liberation could be expected between subjugated people and their colonial masters.
8 - The weakness of the theory was that the two major expected types of war, the intracapitalist and the capitalist-socialist, did not materialize as frequently as Soviet theoreticians had predicted. Further, the theory failed to adequately analyze the situation in the Soviet Union and in the socialist camp. Even in communist countries, nationalism seems to have proved more powerful than socialism: “national liberation” movements appeared and had to be forcibly subdued in the Soviet Union, despite its communist regime. Also, war between socialist states was not unthinkable, as the doctrine indicated: only the colossal preponderance of Soviet forces prevented a full-scale war in 1956 against Hungary and in 1968 against Czechoslovakia; war between the Soviet Union and the People’s Republic of China was a serious possibility for two decades after the Sino-Soviet split in 1962; and armed conflict erupted between China and Vietnam after the latter country became the most powerful in Southeast Asia. Finally, the theory did not provide for wars of liberation against socialist states, such as that conducted by the Afghan mujahideen against the Soviet Union from 1979 to 1989.
8 - Many theories claim or imply that wars result ultimately from the allegiance of men to nations and from the intimate connection between the nation and a state. This link between the nation and the state is firmly established by the doctrine of national self-determination, which has become in the eyes of many the major basis of the legitimacy of states and the major factor in their establishment and breakup. It was the principle on which the political boundaries of eastern Europe and the Balkans were arranged after World War I and became the principal slogan of the anticolonial movement of the 20th century, finding expression in Chapter I, article 1, of the Charter of the United Nations in the objective of “self-determination of peoples,” as well as in the more specific provisions of Chapters XI and XII. It is this intimate link between nationalism and statehood that renders them both so dangerous. The rulers of a state are ultimately governed in their behaviour by what is loosely summed up as the “national interest,” which occasionally clashes directly with the national interests of other states.
8 - The ideal of the nation-state is never fully achieved. In no historical case does one find all members of a particular nation gathered within one state’s boundaries. Conversely, many states contain sizable national minorities. This lack of full correlation has frequently given rise to dangerous tensions that can ultimately lead to war. A government inspired by nationalism may conduct a policy aiming at the assimilation of national minorities, as was the general tendency of central and eastern European governments in the interwar period; it may also attempt to reunite the members of the nation living outside its boundaries, as Adolf Hitler did. National groups that are not in control of a state may feel dissatisfied with its regime and claim self-determination in a separate state, as demonstrated in the attempt to carve Biafra out of Nigeria and the separation of Bangladesh from Pakistan.
8 - There is no rational basis for deciding on the extent to which the self-determination principle should be applied in allowing national minorities to break away. As a rule, the majority group violently opposes the breakaway movement. Violent conflicts can ensue and, through foreign involvement, turn into international wars. No suitable method has been found for divorcing nationalism from the state and for meeting national demands through adequate social and cultural provisions within a larger unit. Such an attempt in the Austro-Hungarian Empire before its dissolution in World War I failed. Even the Soviet Union was not permanently successful in containing its large proportion of national minorities.
8 - Nationalism not only induces wars but, through the severity of its influence, makes compromise and acceptance of defeat more difficult. It thus tends to prolong the duration and increase the severity of wars. Possibly, however, this is the characteristic only of new, immature nationalisms, for nationalism has ceased to be a major cause of conflict and war among the nations of western Europe.
8 - Nationalism is but one form of ideology: in all ages people seem to develop beliefs and try to proselytize others. Even within particular ideological groups, schisms result in conflicts as violent as those between totally opposed creeds, and heretics are often regarded as more dangerous and hostile than opponents. As long as individual states can identify themselves with explosive differences in beliefs, the probability of a war between states is increased, and its intensity is likely to be greater.
8 - Whereas some theories of war regard the state as an undifferentiated whole and generalize about its behaviour, other theorists are more sociologically oriented and focus on the roles played within the state by various special-interest groups.
8 - A distinction is made by these theorists between the great mass of people and those groupings directly involved or influential with government. The people, about whose attitudes adequate knowledge is lacking, are generally assumed to be taken up with their daily lives and to be in favour of peace. The influential groups, who are directly involved in external affairs and, hence, in wars, are the main subject of analysis. Warlike governments dragging peace-loving people into international conflict is a recurrent theme of both liberal and socialist analyses of war. Some writers have gone to the length of postulating a continuous conspiracy of the rulers against the ruled that can be traced to prehistoric times, when priests and warriors combined in the first state structures. Most writers, however, narrow the field and seek an answer to the question of why some governments are more prone to engage in war than others, and they generally find the answer in the influence of important interest groups that pursue particular and selfish ends.
8 - The chief and most obvious of such groups is the military. Military prowess was a major qualification for political leadership in primitive societies; the search for military glory as well as for the spoils of victory seems to have been one of the major motivations for war. Once the military function became differentiated and separated from civilian ones, a tension between the two became one of the most important issues of politics. The plausible view has generally been held that the military strive for war, in which they attain greater resources and can satisfy their status seeking and, sometimes, also an aspiration for direct and full political power. In peacetime the military are obviously less important, are denied resources, and are less likely to influence or attain political power directly. At the same time, a second, although usually subsidiary, consideration of the military as a causal agent in war holds that an officer corps is directly responsible for any fighting and is thus more aware of its potential dangers for its members and for the state as well. Although intent on keeping the state in a high state of preparedness, the military may be more cautious than civilians about engaging in war. It is often held, however, that increased military preparedness may result in increased tensions and thus indirectly lead to the outbreak of war.
8 - Closely allied are theories about groups that profit from wars economically—capitalists and the financiers, especially those involved in industries catering to war. All these play a central part as the villains of the piece in socialist and liberal theories of war, and even those not subscribing to such theories do not deny the importance of military-industrial complexes in countries in which large sectors of the economy specialize in war supplies. But, although industrialists in all the technologically advanced systems are undoubtedly influential in determining such factors as the level of armaments to be maintained, it is difficult to assume that their influence is or could be decisive when actual questions concerning war or peace are being decided by politicians.
8 - Finally, some scientists and technologists constitute a new, much smaller, but important group with special interests in war. To some extent one can generalize about them, although the group is heterogeneous, embracing as it does nuclear scientists, space researchers, biologists and geneticists, chemists, and engineers. If they are involved in defense work, they all share the interest of the military in securing more resources for their research: without their military applications, for example, neither nuclear nor space research would have gone ahead nearly as fast as it has. War, however, does not enhance the status and standing of scientists; on the contrary, they come under the close control of the military. They also usually have peaceful alternatives to military research, although these may not be very satisfactory or ample. Consequently, although modern war technology depends heavily upon scientists and although many of them are employed by governments in work directly or indirectly concerned with this technology, scientists as a group are far from being wedded to war. On the contrary, many of them are deeply concerned with the mass destruction made possible by science and participate in international pacifist movements.
8 - The international environment within which states and the people within them operate is regarded by many theorists as the major factor determining the occurrence and nature of wars. War remains possible as long as individual states seek to ensure self-preservation and promote their individual interests and—in the absence of a reliable international agency to control the actions of other states—rely on their own efforts. It is no accident that reforms of the international system figure prominently in many prescriptions for the prevention of war. Whereas the reform of human propensities or of the state is bound to be a long drawn-out affair if it is at all possible, relatively straightforward partial reforms of the international system may produce significant restraints upon resorting to war, and a thorough reform could make war impossible.
8 - Some theorists, being more optimistic about the nature of states, concentrate upon the removal of the fear and suspicion of other states, which is characteristic of the present as well as of all historical political systems; others, being less optimistic, think mainly of possible controls and restraints upon the behaviour of states. The underlying reasoning of both parties is generally similar. If individual states in competitive situations are governed by a short-term conception of their interests, acute conflicts between them will occur and will show a strong tendency to escalate. Thus, one state erects a tariff barrier to protect its industry against the competition of a trade partner, and the partner retaliates, the retaliatory interaction being repeated until the two countries find themselves in a trade war. Armaments races show a similar tendency to escalate, particularly so in an age of rapid technological change. The economic and scientific efforts necessary to avoid falling behind rivals in the invention and development of rapidly improving weapons of mass destruction have already reached unprecedented heights. And yet, neither trade wars nor arms races necessarily end in violent conflict. There seem to be operating some restraining and inhibiting factors that prevent an automatic escalation. Much of the theory of war concerns itself with the identification, improvement, and development of these restraining factors.
8 - The outcome of starkly competitive behaviour leading to wars is clearly against the interests of states, and it is rational for them to seek more desirable outcomes. If competitive behaviour is dangerous, theorists seek for alternative methods of cooperative behaviour that would not jeopardize the interests of the state through exposing it to the possibly less cooperative behaviour of others. Some theorists concentrate upon improving the rationality of the decision making of individual states through a better understanding of the international environment, through eliminating misperceptions and irrational fears, and through making clear the full possible costs of engaging in war and the full destructiveness of an all-out war, possible in our age.
8 - The relative paucity of wars and their limited nature throughout the century following the Napoleonic Wars (1815–1914) stirred great theoretical interest in the nature of the balance-of-power system of that period—that is, in the process by which the power of competing groups of states tended toward a condition of equilibrium. Contributing to the successful operation of the balance-of-power system of the 19th century were relatively slow technological change, great diversionary opportunities for industrial and colonial expansion, and the ideological and cultural homogeneity of Europe. Pursuit of a balance of power is a way of conducting foreign policy that is perhaps less prone to war than other types of policy because, instead of indiscriminately increasing their power, states increase it only moderately, so as not to provoke others; and instead of joining the strongest, they join the weaker side in order to ensure balance. States in a balance-of-power system must, however, be ready to abide by constraints upon their behaviour in order to ensure stability of the system.
8 - The application to international relations of a branch of mathematics—game theory—that analyzes the strategy of conflict situations has provided a new tool of analysis. In state interaction, as in any game situation, one side’s strategy generally depends upon that side’s expectations of the other side’s strategy. If all sides in a game are to maximize their chances of a satisfactory outcome, it is necessary that some rational rules of behaviour be conceptualized and agreed upon, and this idea of a set of rational rules can be applied to competing states in the international system. Game theorists distinguish antagonistic situations called zero-sum games, in which one state’s gain can be only at the expense of another state because the “payoff” is fixed. Even then a mutually acceptable distribution of gains can be rationally reached on the basis of the “minimax” principle—the party in a position of advantage satisfies itself with the minimum acceptable gain because it realizes that the other party, in a position of disadvantage, would yield on the basis of its possible minimum loss but would violently oppose a distribution even more to its detriment. In other situations, called non-zero-sum games, the payoff is not constant but can be increased by a cooperative approach; the gain of one participant is not at the cost of another. The contestants, however, have to agree about the distribution of the gain, which is the product of their cooperation.
8 - The theory of games is the foundation of theories of bargaining that analyze the behaviour of individual states in interaction. Diplomacy based upon such theories is less likely to lead to war. Policymakers pursuing such strategies will conduct conflicts of the zero-sum type so that war is avoided. More than that, with some skill, such situations can be transformed into the non-zero-sum type by introducing additional benefits accruing from cooperation in other interactions and also, more generally, by eliminating the likelihood of war and, consequently, by reducing the costs of preparing for one.
8 - Because wars within states have been eliminated through the establishment of suitable political structures, such as central governments that hold a monopoly of coercive power, many theories concentrate upon the establishment of parallel structures within the international context. Regional integration (cooperation in economic, social, and political affairs, as, for example, within the European Union) and the establishment of security communities (such as the North Atlantic Treaty Organization) have made much greater advances than attempts at the reform of the entire global international system.
8 - Because conflicts among neighbours tend to be frequent, regional integration is an important advance toward reducing the incidence of war. Even if it were to become generally successful, however, regional integration would simply shift the problem of war to a different level: there would be fewer possibilities of war because intraregional conflicts would be contained, but interregional conflicts could still give rise to wars of much greater scope and severity. The phenomenon of war must, therefore, be analyzed at the universal level.
8 - Some of the most influential thinking about war and the international system has come from specialists in international law. All of them postulate that there exists an international society of states that accepts the binding force of some norms of international behaviour. These norms are referred to as international law, although they differ fundamentally from municipal law because no sovereign exists who can enforce them. Most international lawyers realistically accept that international law is, consequently, among rather than above states. It is, according to legal doctrine, binding on states but unenforceable.
8 - International law concerns itself largely with two aspects of war: its legality and its regulation. As far as the legality of war is concerned, there arose in the 20th century a general consensus among states, expressed in several international treaties, including the Covenant of the League of Nations, the Kellogg-Briand Pact of 1928, and the Charter of the United Nations, that resort to armed force, except in certain circumstances such as self-defense, is illegal. Such a legalistic approach to the prevention of war, however, remains futile in the absence of a means of enforcement. The enforcement provisions of the United Nations Charter, which entail the application of military and economic sanctions, have never been applied successfully, owing to political disagreement among the major powers. This underlines the fact that legal norms, to be effective, must reflect an underlying political reality.
8 - The United Nations is charged with the maintenance of international peace and security. The several approaches to peace outlined in its Charter and developed in its practice are based upon and clearly reflect the cumulative development of the relevant theories of war.
8 - Drawing heavily upon the experience of the League of Nations, the Charter develops three interrelated approaches: first, pacific settlement of disputes, which would leave nations with nothing to fight about; second, collective security, which would confront aggressors with too much to fight against; and third, disarmament, which would deprive them of anything substantial with which to fight.
8 - Pacific settlement of disputes is based upon the assumption that war is primarily a technique for settling disputes, although it can, of course, also serve other purposes, such as allaying fears and seeking status. Further assumptions are that war frequently comes about because of the unawareness of decision makers of the possibility of settling disputes peacefully to the mutual advantage of both sides—an unawareness due to mere ignorance, pride, lack of imagination, or selfish and cynical leadership. It is thus possible that international organizations can contribute to the prevention of wars by devising and institutionalizing alternative, peaceful techniques for the settlement of disputes and by persuading the states to use them.
8 - The scope of this approach is limited, for states are notoriously reluctant to abide by impartial findings on matters they regard as being of vital importance. Hence, what the procedures really offer is a means of slowing down the progression of a dispute toward war, giving reason a chance to prevail.
8 - Collective security is an approach to peace involving an agreement by which states agree to take collective action against any state defined as an aggressor. Leaving aside the problems of settling disputes or enforcing law or satisfying justice, it concentrates upon forestalling violence by bringing to bear an overwhelmingly superior international force against any aggressor. Although collective security, in somewhat different forms, played a prominent part in the League of Nations Covenant and is embodied in the United Nations Charter, it has completely failed in both cases. Failing an international government capable of ultimately determining the issues, nations have not managed to agree on an unequivocal definition of aggression, have not in practice accepted the principle that aggression must be acted against independently of the identity of the perpetrator, and, therefore, have not established the international collective security force envisaged in the Charter.
8 - Disarmament and limitation of armaments are based upon the theory that states are inclined to strive for dominance in arms over any potential rivals and that this leads to arms races that tend to end in war. The major besetting sin of this theory is that it often tends to confuse cause with effect. Although arms races develop momentum of their own, they are themselves the result of political tensions leading to war. In short, it is the tensions that cause war, not the arms races. To hold otherwise is to mistake a symptom for a cause. Hence, reducing the levels of armaments does not necessarily reduce these tensions. Furthermore, it is the instability of strategic balances, rather than their level, that leads to war; agreements about disarmament or limitation of armaments may easily disturb the existing precarious balance and, therefore, be actually conducive to war.
8 - As these major approaches to peace envisaged in its Charter have not proved very fruitful, the United Nations has developed two new procedures aiming at the limitation of wars. First, “preventive diplomacy,” largely comprising the diplomatic initiatives of the secretary-general and the stationing of peacekeeping forces, has served to contain local conflicts and to prevent escalation, especially the involvement of the superpowers. Second, although the General Assembly’s recommendations have no legal binding force, they have become increasingly influential, for the assembly has become an important agency for what has been called the collective legitimization of state policies. Resort to war becomes more costly when a state is faced with the prospects of a collective condemnation. This new restraint upon war does not, however, act upon conflicts that the assembly may favourably regard as wars of colonial liberation. Nor could the assembly’s disapproval be relied upon to deter states from waging war in pursuit of an interest they deemed to be truly vital.
8 - Both the shortcomings and the limited practicability of all the approaches to the elimination of war through the reform of the international system have driven many thinkers to accept the idea that war can only be abolished by a full-scale world government. No midway solution between the relative anarchy of independent, individual states and a world government with the full paraphernalia of legislative powers and of an overwhelming military force would provide a sufficiently stable international framework for the nations to feel that wars would not break out and thus stop them from behaviour that is often conducive to wars. In an age faced with the danger of a war escalating into a general extermination of mankind, the central importance of preserving peace is obvious and is generally accepted. But here the thinkers divide. Some press on from this analysis to the logical conclusion that mankind must and, therefore, will establish a world government, and they advance ideas on how best to proceed in this direction. Others regard the world government as completely utopian, no matter how logical and desirable it may be. Yet, in terms of actual policies, the adherents of the two schools do not necessarily divide. Whether they do or do not believe that world government is attainable, they agree that the complex phenomenon of war represents a potential calamity of such a magnitude that all theorists must endeavour to understand it and to apply their understanding to the prevention and mitigation of war with all the means at their disposal.

9 - chemistry, the science that deals with the properties, composition, and structure of substances (defined as elements and compounds), the transformations they undergo, and the energy that is released or absorbed during these processes. Every substance, whether naturally occurring or artificially produced, consists of one or more of the hundred-odd species of atoms that have been identified as elements. Although these atoms, in turn, are composed of more elementary particles, they are the basic building blocks of chemical substances; there is no quantity of oxygen, mercury, or gold, for example, smaller than an atom of that substance. Chemistry, therefore, is concerned not with the subatomic domain but with the properties of atoms and the laws governing their combinations and how the knowledge of these properties can be used to achieve specific purposes.
9 - The great challenge in chemistry is the development of a coherent explanation of the complex behaviour of materials, why they appear as they do, what gives them their enduring properties, and how interactions among different substances can bring about the formation of new substances and the destruction of old ones. From the earliest attempts to understand the material world in rational terms, chemists have struggled to develop theories of matter that satisfactorily explain both permanence and change. The ordered assembly of indestructible atoms into small and large molecules, or extended networks of intermingled atoms, is generally accepted as the basis of permanence, while the reorganization of atoms or molecules into different arrangements lies behind theories of change. Thus chemistry involves the study of the atomic composition and structural architecture of substances, as well as the varied interactions among substances that can lead to sudden, often violent reactions.
9 - Chemistry also is concerned with the utilization of natural substances and the creation of artificial ones. Cooking, fermentation, glass making, and metallurgy are all chemical processes that date from the beginnings of civilization. Today, vinyl, Teflon, liquid crystals, semiconductors, and superconductors represent the fruits of chemical technology. The 20th century saw dramatic advances in the comprehension of the marvelous and complex chemistry of living organisms, and a molecular interpretation of health and disease holds great promise. Modern chemistry, aided by increasingly sophisticated instruments, studies materials as small as single atoms and as large and complex as DNA (deoxyribonucleic acid), which contains millions of atoms. New substances can even be designed to bear desired characteristics and then synthesized. The rate at which chemical knowledge continues to accumulate is remarkable. Over time more than 8,000,000 different chemical substances, both natural and artificial, have been characterized and produced. The number was less than 500,000 as recently as 1965.
9 - Intimately interconnected with the intellectual challenges of chemistry are those associated with industry. In the mid-19th century the German chemist Justus von Liebig commented that the wealth of a nation could be gauged by the amount of sulfuric acid it produced. This acid, essential to many manufacturing processes, remains today the leading chemical product of industrialized countries. As Liebig recognized, a country that produces large amounts of sulfuric acid is one with a strong chemical industry and a strong economy as a whole. The production, distribution, and utilization of a wide range of chemical products is common to all highly developed nations. In fact, one can say that the “iron age” of civilization is being replaced by a “polymer age,” for in some countries the total volume of polymers now produced exceeds that of iron.
9 - The days are long past when one person could hope to have a detailed knowledge of all areas of chemistry. Those pursuing their interests into specific areas of chemistry communicate with others who share the same interests. Over time a group of chemists with specialized research interests become the founding members of an area of specialization. The areas of specialization that emerged early in the history of chemistry, such as organic, inorganic, physical, analytical, and industrial chemistry, along with biochemistry, remain of greatest general interest. There has been, however, much growth in the areas of polymer, environmental, and medicinal chemistry during the 20th century. Moreover, new specialities continue to appear, as, for example, pesticide, forensic, and computer chemistry.
9 - Most of the materials that occur on Earth, such as wood, coal, minerals, or air, are mixtures of many different and distinct chemical substances. Each pure chemical substance (e.g., oxygen, iron, or water) has a characteristic set of properties that gives it its chemical identity. Iron, for example, is a common silver-white metal that melts at 1,535° C, is very malleable, and readily combines with oxygen to form the common substances hematite and magnetite. The detection of iron in a mixture of metals, or in a compound such as magnetite, is a branch of analytical chemistry called qualitative analysis. Measurement of the actual amount of a certain substance in a compound or mixture is termed quantitative analysis. Quantitative analytic measurement has determined, for instance, that iron makes up 72.3 percent, by mass, of magnetite, the mineral commonly seen as black sand along beaches and stream banks. Over the years, chemists have discovered chemical reactions that indicate the presence of such elemental substances by the production of easily visible and identifiable products. Iron can be detected by chemical means if it is present in a sample to an amount of 1 part per million or greater. Some very simple qualitative tests reveal the presence of specific chemical elements in even smaller amounts. The yellow colour imparted to a flame by sodium is visible if the sample being ignited has as little as one-billionth of a gram of sodium. Such analytic tests have allowed chemists to identify the types and amounts of impurities in various substances and to determine the properties of very pure materials. Substances used in common laboratory experiments generally have impurity levels of less than 0.1 percent. For special applications, one can purchase chemicals that have impurities totaling less than 0.001 percent. The identification of pure substances and the analysis of chemical mixtures enable all other chemical disciplines to flourish.
9 - The importance of analytical chemistry has never been greater than it is today. The demand in modern societies for a variety of safe foods, affordable consumer goods, abundant energy, and labour-saving technologies places a great burden on the environment. All chemical manufacturing produces waste products in addition to the desired substances, and waste disposal has not always been carried out carefully. Disruption of the environment has occurred since the dawn of civilization, and pollution problems have increased with the growth of global population. The techniques of analytical chemistry are relied on heavily to maintain a benign environment. The undesirable substances in water, air, soil, and food must be identified, their point of origin fixed, and safe, economical methods for their removal or neutralization developed. Once the amount of a pollutant deemed to be hazardous has been assessed, it becomes important to detect harmful substances at concentrations well below the danger level. Analytical chemists seek to develop increasingly accurate and sensitive techniques and instruments.
9 - Sophisticated analytic instruments, often coupled with computers, have improved the accuracy with which chemists can identify substances and have lowered detection limits. An analytic technique in general use is gas chromatography, which separates the different components of a gaseous mixture by passing the mixture through a long, narrow column of absorbent but porous material. The different gases interact differently with this absorbent material and pass through the column at different rates. As the separate gases flow out of the column, they can be passed into another analytic instrument called a mass spectrometer, which separates substances according to the mass of their constituent ions. A combined gas chromatograph–mass spectrometer can rapidly identify the individual components of a chemical mixture whose concentrations may be no greater than a few parts per billion. Similar or even greater sensitivities can be obtained under favourable conditions using techniques such as atomic absorption, polarography, and neutron activation. The rate of instrumental innovation is such that analytic instruments often become obsolete within 10 years of their introduction. Newer instruments are more accurate and faster and are employed widely in the areas of environmental and medicinal chemistry.
9 - Modern chemistry, which dates more or less from the acceptance of the law of conservation of mass in the late 18th century, focused initially on those substances that were not associated with living organisms. Study of such substances, which normally have little or no carbon, constitutes the discipline of inorganic chemistry. Early work sought to identify the simple substances—namely, the elements—that are the constituents of all more complex substances. Some elements, such as gold and carbon, have been known since antiquity, and many others were discovered and studied throughout the 19th and early 20th centuries. Today, more than 100 are known. The study of such simple inorganic compounds as sodium chloride (common salt) has led to some of the fundamental concepts of modern chemistry, the law of definite proportions providing one notable example. This law states that for most pure chemical substances the constituent elements are always present in fixed proportions by mass (e.g., every 100 grams of salt contains 39.3 grams of sodium and 60.7 grams of chlorine). The crystalline form of salt, known as halite, consists of intermingled sodium and chlorine atoms, one sodium atom for each one of chlorine. Such a compound, formed solely by the combination of two elements, is known as a binary compound. Binary compounds are very common in inorganic chemistry, and they exhibit little structural variety. For this reason, the number of inorganic compounds is limited in spite of the large number of elements that may react with each other. If three or more elements are combined in a substance, the structural possibilities become greater.
9 - After a period of quiescence in the early part of the 20th century, inorganic chemistry has again become an exciting area of research. Compounds of boron and hydrogen, known as boranes, have unique structural features that forced a change in thinking about the architecture of inorganic molecules. Some inorganic substances have structural features long believed to occur only in carbon compounds, and a few inorganic polymers have even been produced. Ceramics are materials composed of inorganic elements combined with oxygen. For centuries ceramic objects have been made by strongly heating a vessel formed from a paste of powdered minerals. Although ceramics are quite hard and stable at very high temperatures, they are usually brittle. Currently, new ceramics strong enough to be used as turbine blades in jet engines are being manufactured. There is hope that ceramics will one day replace steel in components of internal-combustion engines. In 1987 a ceramic containing yttrium, barium, copper, and oxygen, with the approximate formula YBa2Cu3O7, was found to be a superconductor at a temperature of about 100 K. A superconductor offers no resistance to the passage of an electrical current, and this new type of ceramic could very well find wide use in electrical and magnetic applications. A superconducting ceramic is so simple to make that it can be prepared in a high school laboratory. Its discovery illustrates the unpredictability of chemistry, for fundamental discoveries can still be made with simple equipment and inexpensive materials.
9 - Many of the most interesting developments in inorganic chemistry bridge the gap with other disciplines. Organometallic chemistry investigates compounds that contain inorganic elements combined with carbon-rich units. Many organometallic compounds play an important role in industrial chemistry as catalysts, which are substances that are able to accelerate the rate of a reaction even when present in only very small amounts. Some success has been achieved in the use of such catalysts for converting natural gas to related but more useful chemical substances. Chemists also have created large inorganic molecules that contain a core of metal atoms, such as platinum, surrounded by a shell of different chemical units. Some of these compounds, referred to as metal clusters, have characteristics of metals, while others react in ways similar to biologic systems. Trace amounts of metals in biologic systems are essential for processes such as respiration, nerve function, and cell metabolism. Processes of this kind form the object of study of bioinorganic chemistry. Although organic molecules were once thought to be the distinguishing chemical feature of living creatures, it is now known that inorganic chemistry plays a vital role as well.
9 - Organic compounds are based on the chemistry of carbon. Carbon is unique in the variety and extent of structures that can result from the three-dimensional connections of its atoms. The process of photosynthesis converts carbon dioxide and water to oxygen and compounds known as carbohydrates. Both cellulose, the substance that gives structural rigidity to plants, and starch, the energy storage product of plants, are polymeric carbohydrates. Simple carbohydrates produced by photosynthesis form the raw material for the myriad organic compounds found in the plant and animal kingdoms. When combined with variable amounts of hydrogen, oxygen, nitrogen, sulfur, phosphorus, and other elements, the structural possibilities of carbon compounds become limitless, and their number far exceeds the total of all nonorganic compounds. A major focus of organic chemistry is the isolation, purification, and structural study of these naturally occurring substances. Many natural products are simple molecules. Examples include formic acid (HCO2H) in ants, ethyl alcohol (C2H5OH) in fermenting fruit, and oxalic acid (C2H2O4) in rhubarb leaves. Other natural products, such as penicillin, vitamin B12, proteins, and nucleic acids, are exceedingly complex. The isolation of pure natural products from their host organism is made difficult by the low concentrations in which they may be present. Once they are isolated in pure form, however, modern instrumental techniques can reveal structural details for amounts weighing as little as one-millionth of a gram. The correlation of the physical and chemical properties of compounds with their structural features is the domain of physical organic chemistry. Once the properties endowed upon a substance by specific structural units termed functional groups are known, it becomes possible to design novel molecules that may exhibit desired properties. The preparation, under controlled laboratory conditions, of specific compounds is known as synthetic chemistry. Some products are easier to synthesize than to collect and purify from their natural sources. Tons of vitamin C, for example, are synthesized annually. Many synthetic substances have novel properties that make them especially useful. Plastics are a prime example, as are many drugs and agricultural chemicals. A continuing challenge for synthetic chemists is the structural complexity of most organic substances. To synthesize a desired substance, the atoms must be pieced together in the correct order and with the proper three-dimensional relationships. Just as a given pile of lumber and bricks can be assembled in many ways to build houses of several different designs, so too can a fixed number of atoms be connected together in various ways to give different molecules. Only one structural arrangement out of the many possibilities will be identical with a naturally occurring molecule. The antibiotic erythromycin, for example, contains 37 carbon, 67 hydrogen, and 13 oxygen atoms, along with one nitrogen atom. Even when joined together in the proper order, these 118 atoms can give rise to 262,144 different structures, only one of which has the characteristics of natural erythromycin. The great abundance of organic compounds, their fundamental role in the chemistry of life, and their structural diversity have made their study especially challenging and exciting. Organic chemistry is the largest area of specialization among the various fields of chemistry.
9 - As understanding of inanimate chemistry grew during the 19th century, attempts to interpret the physiological processes of living organisms in terms of molecular structure and reactivity gave rise to the discipline of biochemistry. Biochemists employ the techniques and theories of chemistry to probe the molecular basis of life. An organism is investigated on the premise that its physiological processes are the consequence of many thousands of chemical reactions occurring in a highly integrated manner. Biochemists have established, among other things, the principles that underlie energy transfer in cells, the chemical structure of cell membranes, the coding and transmission of hereditary information, muscular and nerve function, and biosynthetic pathways. In fact, related biomolecules have been found to fulfill similar roles in organisms as different as bacteria and human beings. The study of biomolecules, however, presents many difficulties. Such molecules are often very large and exhibit great structural complexity; moreover, the chemical reactions they undergo are usually exceedingly fast. The separation of the two strands of DNA, for instance, occurs in one-millionth of a second. Such rapid rates of reaction are possible only through the intermediary action of biomolecules called enzymes. Enzymes are proteins that owe their remarkable rate-accelerating abilities to their three-dimensional chemical structure. Not surprisingly, biochemical discoveries have had a great impact on the understanding and treatment of disease. Many ailments due to inborn errors of metabolism have been traced to specific genetic defects. Other diseases result from disruptions in normal biochemical pathways.
9 - Frequently, symptoms can be alleviated by drugs, and the discovery, mode of action, and degradation of therapeutic agents is another of the major areas of study in biochemistry. Bacterial infections can be treated with sulfonamides, penicillins, and tetracyclines, and research into viral infections has revealed the effectiveness of acyclovir against the herpes virus. There is much current interest in the details of carcinogenesis and cancer chemotherapy. It is known, for example, that cancer can result when cancer-causing molecules, or carcinogens as they are called, react with nucleic acids and proteins and interfere with their normal modes of action. Researchers have developed tests that can identify molecules likely to be carcinogenic. The hope, of course, is that progress in the prevention and treatment of cancer will accelerate once the biochemical basis of the disease is more fully understood.
9 - The molecular basis of biologic processes is an essential feature of the fast-growing disciplines of molecular biology and biotechnology. Chemistry has developed methods for rapidly and accurately determining the structure of proteins and DNA. In addition, efficient laboratory methods for the synthesis of genes are being devised. Ultimately, the correction of genetic diseases by replacement of defective genes with normal ones may become possible.
9 - The simple substance ethylene is a gas composed of molecules with the formula CH2CH2. Under certain conditions, many ethylene molecules will join together to form a long chain called polyethylene, with the formula (CH2CH2)n, where n is a variable but large number. Polyethylene is a tough, durable solid material quite different from ethylene. It is an example of a polymer, which is a large molecule made up of many smaller molecules (monomers), usually joined together in a linear fashion. Many naturally occurring substances, including cellulose, starch, cotton, wool, rubber, leather, proteins, and DNA, are polymers. Polyethylene, nylon, and acrylics are examples of synthetic polymers. The study of such materials lies within the domain of polymer chemistry, a specialty that has flourished in the 20th century. The investigation of natural polymers overlaps considerably with biochemistry, but the synthesis of new polymers, the investigation of polymerization processes, and the characterization of the structure and properties of polymeric materials all pose unique problems for polymer chemists.
9 - Polymer chemists have designed and synthesized polymers that vary in hardness, flexibility, softening temperature, solubility in water, and biodegradability. They have produced polymeric materials that are as strong as steel yet lighter and more resistant to corrosion. Oil, natural gas, and water pipelines are now routinely constructed of plastic pipe. In recent years, automakers have increased their use of plastic components to build lighter vehicles that consume less fuel. Other industries such as those involved in the manufacture of textiles, rubber, paper, and packaging materials are built upon polymer chemistry.
9 - Besides producing new kinds of polymeric materials, researchers are concerned with developing special catalysts that are required by the large-scale industrial synthesis of commercial polymers. Without such catalysts, the polymerization process would be very slow in certain cases.
9 - Many chemical disciplines, such as those already discussed, focus on certain classes of materials that share common structural and chemical features. Other specialties may be centred not on a class of substances but rather on their interactions and transformations. The oldest of these fields is physical chemistry, which seeks to measure, correlate, and explain the quantitative aspects of chemical processes. The Anglo-Irish chemist Robert Boyle, for example, discovered in the 17th century that at room temperature the volume of a fixed quantity of gas decreases proportionally as the pressure on it increases. Thus, for a gas at constant temperature, the product of its volume V and pressure P equals a constant number—i.e., PV = constant. Such a simple arithmetic relationship is valid for nearly all gases at room temperature and at pressures equal to or less than one atmosphere. Subsequent work has shown that the relationship loses its validity at higher pressures, but more complicated expressions that more accurately match experimental results can be derived. The discovery and investigation of such chemical regularities, often called laws of nature, lie within the realm of physical chemistry. For much of the 18th century the source of mathematical regularity in chemical systems was assumed to be the continuum of forces and fields that surround the atoms making up chemical elements and compounds. Developments in the 20th century, however, have shown that chemical behaviour is best interpreted by a quantum mechanical model of atomic and molecular structure. The branch of physical chemistry that is largely devoted to this subject is theoretical chemistry. Theoretical chemists make extensive use of computers to help them solve complicated mathematical equations. Other branches of physical chemistry include chemical thermodynamics, which deals with the relationship between heat and other forms of chemical energy, and chemical kinetics, which seeks to measure and understand the rates of chemical reactions. Electrochemistry investigates the interrelationship of electric current and chemical change. The passage of an electric current through a chemical solution causes changes in the constituent substances that are often reversible—i.e., under different conditions the altered substances themselves will yield an electric current. Common batteries contain chemical substances that, when placed in contact with each other by closing an electrical circuit, will deliver current at a constant voltage until the substances are consumed. At present there is much interest in devices that can use the energy in sunlight to drive chemical reactions whose products are capable of storing the energy. The discovery of such devices would make possible the widespread utilization of solar energy.
9 - There are many other disciplines within physical chemistry that are concerned more with the general properties of substances and the interactions among substances than with the substances themselves. Photochemistry is a specialty that investigates the interaction of light with matter. Chemical reactions initiated by the absorption of light can be very different from those that occur by other means. Vitamin D, for example, is formed in the human body when the steroid ergosterol absorbs solar radiation; ergosterol does not change to vitamin D in the dark.
9 - A rapidly developing subdiscipline of physical chemistry is surface chemistry. It examines the properties of chemical surfaces, relying heavily on instruments that can provide a chemical profile of such surfaces. Whenever a solid is exposed to a liquid or a gas, a reaction occurs initially on the surface of the solid, and its properties can change dramatically as a result. Aluminum is a case in point: it is resistant to corrosion precisely because the surface of the pure metal reacts with oxygen to form a layer of aluminum oxide, which serves to protect the interior of the metal from further oxidation. Numerous reaction catalysts perform their function by providing a reactive surface on which substances can react.
9 - The manufacture, sale, and distribution of chemical products is one of the cornerstones of a developed country. Chemists play an important role in the manufacture, inspection, and safe handling of chemical products, as well as in product development and general management. The manufacture of basic chemicals such as oxygen, chlorine, ammonia, and sulfuric acid provides the raw materials for industries producing textiles, agricultural products, metals, paints, and pulp and paper. Specialty chemicals are produced in smaller amounts for industries involved with such products as pharmaceuticals, foodstuffs, packaging, detergents, flavours, and fragrances. To a large extent, the chemical industry takes the products and reactions common to “bench-top” chemical processes and scales them up to industrial quantities.
9 - The monitoring and control of bulk chemical processes, especially with regard to heat transfer, pose problems usually tackled by chemists and chemical engineers. The disposal of by-products also is a major problem for bulk chemical producers. These and other challenges of industrial chemistry set it apart from the more purely intellectual disciplines of chemistry discussed above. Yet, within the chemical industry, there is a considerable amount of fundamental research undertaken within traditional specialties. Most large chemical companies have research-and-development capability. Pharmaceutical firms, for example, operate large research laboratories in which chemists test molecules for pharmacological activity. The new products and processes that are discovered in such laboratories are often patented and become a source of profit for the company funding the research. A great deal of the research conducted in the chemical industry can be termed applied research because its goals are closely tied to the products and processes of the company concerned. New technologies often require much chemical expertise. The fabrication of, say, electronic microcircuits involves close to 100 separate chemical steps from start to finish. Thus, the chemical industry evolves with the technological advances of the modern world and at the same time often contributes to the rate of progress.
9 - Chemistry is to a large extent a cumulative science. Over time the number and extent of observations and phenomena studied increase. Not all hypotheses and discoveries endure unchallenged, however. Some of them are discarded as new observations or more satisfying explanations appear. Nonetheless, chemistry has a broad spectrum of explanatory models for chemical phenomena that have endured and been extended over time. These now have the status of theories, interconnected sets of explanatory devices that correlate well with observed phenomena. As new discoveries are made, they are incorporated into existing theory whenever possible. However, as the discovery of high-temperature superconductors in 1986 illustrates, accepted theory is never sufficient to predict the course of future discovery. Serendipity, or chance discovery, will continue to play as much a role in the future as will theoretical sophistication.
9 - The chemical properties of a substance are a function of its structure, and the techniques of X-ray crystallography now enable chemists to determine the precise atomic arrangement of complex molecules. A molecule is an ordered assembly of atoms. Each atom in a molecule is connected to one or more neighbouring atoms by a chemical bond. The length of bonds and the angles between adjacent bonds are all important in describing molecular structure, and a comprehensive theory of chemical bonding is one of the major achievements of modern chemistry. Fundamental to bonding theory is the atomic–molecular concept.
9 - As far as general chemistry is concerned, atoms are composed of the three fundamental particles: the proton, the neutron, and the electron. Although the proton and the neutron are themselves composed of smaller units, their substructure has little impact on chemical transformation. As was explained in an earlier section, the proton carries a charge of +1, and the number of protons in an atomic nucleus distinguishes one type of chemical atom from another. The simplest atom of all, hydrogen, has a nucleus composed of a single proton. The neutron has very nearly the same mass as the proton, but it has no charge. Neutrons are contained with protons in the nucleus of all atoms other than hydrogen. The atom with one proton and one neutron in its nucleus is called deuterium. Because it has only one proton, deuterium exhibits the same chemical properties as hydrogen but has a different mass. Hydrogen and deuterium are examples of related atoms called isotopes. The third atomic particle, the electron, has a charge of -1, but its mass is 1,836 times smaller than that of a proton. The electron occupies a region of space outside the nucleus termed an orbital. Some orbitals are spherical with the nucleus at the centre. Because electrons have so little mass and move about at speeds close to half that of light, they exhibit the same wave–particle duality as photons of light. This means that some of the properties of an electron are best described by considering the electron to be a particle, while other properties are consistent with the behaviour of a standing wave. The energy of a standing wave, such as a vibrating string, is distributed over the region of space defined by the two fixed ends and the up-and-down extremes of vibration. Such a wave does not exist in a fixed region of space as does a particle. Early models of atomic structure envisioned the electron as a particle orbiting the nucleus, but electron orbitals are now interpreted as the regions of space occupied by standing waves called wave functions. These wave functions represent the regions of space around the nucleus in which the probability of finding an electron is high. They play an important role in bonding theory, as will be discussed later.
9 - Each proton in an atomic nucleus requires an electron for electrical neutrality. Thus, as the number of protons in a nucleus increases, so too does the number of electrons. The electrons, alone or in pairs, occupy orbitals increasingly distant from the nucleus. Electrons farther from the nucleus are attracted less strongly by the protons in the nucleus, and they can be removed more easily from the atom. The energy required to move an electron from one orbital to another, or from one orbital to free space, gives a measure of the energy level of the orbitals. These energies have been found to have distinct, fixed values; they are said to be quantized. The energy differences between orbitals give rise to the characteristic patterns of light absorption or emission that are unique to each chemical atom.
9 - A new chemical atom—that is, an element—results each time another proton is added to an atomic nucleus. Consecutive addition of protons generates the whole range of elements known to exist in the universe. Compounds are formed when two or more different elements combine through atomic bonding. Such bond formation is a consequence of electron pairing and constitutes the foundation of all structural chemistry.
9 - When two different atoms approach each other, the electrons in their outer orbitals can respond in two distinct ways. An electron in the outermost atomic orbital of atom A may move completely to an outer but stabler orbital of atom B. The charged atoms that result, A+ and B-, are called ions, and the electrostatic force of attraction between them gives rise to what is termed an ionic bond. Most elements can form ionic bonds, and the substances that result commonly exist as three-dimensional arrays of positive and negative ions. Ionic compounds are frequently crystalline solids that have high melting points (e.g., table salt).
9 - The second way in which the two outer electrons of atoms A and B can respond to the approach of A and B is to pair up to form a covalent bond. In the simple view known as the valence-bond model, in which electrons are treated strictly as particles, the two paired electrons are assumed to lie between the two nuclei and are shared equally by atoms A and B, resulting in a covalent bond. Atoms joined together by one or more covalent bonds constitute molecules. Hydrogen gas is composed of hydrogen molecules, which consist in turn of two hydrogen atoms linked by a covalent bond. The notation H2 for hydrogen gas is referred to as a molecular formula. Molecular formulas indicate the number and type of atoms that make up a molecule. The molecule H2 is responsible for the properties generally associated with hydrogen gas. Most substances on Earth have covalently bonded molecules as their fundamental chemical unit, and their molecular properties are completely different from those of the constituent elements. The physical and chemical properties of carbon dioxide, for example, are quite distinct from those of pure carbon and pure oxygen.
9 - The interpretation of a covalent bond as a localized electron pair is an oversimplification of the bonding situation. A more comprehensive description of bonding that considers the wave properties of electrons is the molecular-orbital theory. According to this theory, electrons in a molecule, rather than being localized between atoms, are distributed over all the atoms in the molecule in a spatial distribution described by a molecular orbital. Such orbitals result when the atomic orbitals of bonded atoms combine with each other. The total number of molecular orbitals present in a molecule is equal to the sum of all atomic orbitals in the constituent atoms prior to bonding. Thus, for the simple combination of atoms A and B to form the molecule AB, two atomic orbitals combine to generate two molecular orbitals. One of these, the so-called bonding molecular orbital, represents a region of space enveloping both the A and B atoms, while the other, the anti-bonding molecular orbital, has two lobes, neither of which occupies the space between the two atoms. The bonding molecular orbital is at a lower energy level than are the two atomic orbitals, while the anti-bonding orbital is at a higher energy level. The two paired electrons that constitute the covalent bond between A and B occupy the bonding molecular orbital. For this reason, there is a high probability of finding the electrons between A and B, but they can be found elsewhere in the orbital as well. Because only two electrons are involved in bond formation and both can be accommodated in the lower energy orbital, the anti-bonding orbital remains unpopulated. This theory of bonding predicts that bonding between A and B will occur because the energy of the paired electrons after bonding is less than that of the two electrons in their atomic orbitals prior to bonding. The formation of a covalent bond is thus energetically favoured. The system goes from a state of higher energy to one of lower energy.
9 - Another feature of this bonding picture is that it is able to predict the energy required to move an electron from the bonding molecular orbital to the anti-bonding one. The energy required for such an electronic excitation can be provided by visible light, for example, and the wavelength of the light absorbed determines the colour displayed by the absorbing molecule (e.g., violets are blue because the pigments in the flower absorb the red rays of natural light and reflect more of the blue). As the number of atoms in a molecule increases, so too does the number of molecular orbitals. Calculation of molecular orbitals for large molecules is mathematically difficult, but computers have made it possible to determine the wave equations for several large molecules. Molecular properties predicted by such calculations correlate well with experimental results.
9 - Many elements can form two or more covalent bonds, but only a few are able to form extended chains of covalent bonds. The outstanding example is carbon, which can form as many as four covalent bonds and can bond to itself indefinitely. Carbon has six electrons in total, two of which are paired in an atomic orbital closest to the nucleus. The remaining four are farther from the nucleus and are available for covalent bonding. When there is sufficient hydrogen present, carbon will react to form methane, CH4. When all four electron pairs occupy the four molecular orbitals of lowest energy, the molecule assumes the shape of a tetrahedron, with carbon at the centre and the four hydrogen atoms at the apexes. The C–H bond length is 110 picometres (1 picometre = 10-12 metre), and the angle between adjacent C–H bonds is close to 110°. Such tetrahedral symmetry is common to many carbon compounds and results in interesting structural possibilities. If two carbon atoms are joined together, with three hydrogen atoms bonded to each carbon atom, the molecule ethane is obtained. When four carbon atoms are joined together, two different structures are possible: a linear structure designated n-butane and a branched structure called iso-butane. These two structures have the same molecular formula, C4H10, but a different order of attachment of their constituent atoms. The two molecules are termed structural isomers. Each of them has unique chemical and physical properties, and they are different compounds. The number of possible isomers increases rapidly as the number of carbon atoms increases. There are five isomers for C6H14, 75 for C10H22, and 6.2 × 1013 for C40H82. When carbon forms bonds to atoms other than hydrogen, such as oxygen, nitrogen, and sulfur, the structural possibilities become even greater. It is this great potential for structural diversity that makes carbon compounds essential to living organisms.
9 - Even when the bonding sequence of carbon compounds is fixed, further structural variation is still possible. When two carbon atoms are joined together by two bonding pairs of electrons, a double bond is formed. A double bond forces the two carbon atoms and attached groups into a rigid, planar structure. As a result, a molecule such as CHCl=CHCl can exist in two nonidentical forms called geometric isomers. Structural rigidity also occurs in ring structures, and attached groups can be on the same side of a ring or on different sides. Yet another opportunity for isomerism arises when a carbon atom is bonded to four different groups. These can be attached in two different ways, one of which is the mirror image of the other. This type of isomerism is called optical isomerism, because the two isomers affect plane-polarized light differently. Two optical isomers are possible for every carbon atom that is bonded to four different groups. For a molecule bearing 10 such carbon atoms, the total number of possible isomers will be 210 = 1,024. Large biomolecules often have 10 or more carbon atoms for which such optical isomers are possible. Only one of all the possible isomers will be identical to the natural molecule. For this reason, the laboratory synthesis of large organic molecules is exceedingly difficult. Only in the last few decades of the 20th century have chemists succeeded in developing reagents and processes that yield specific optical isomers. They expect that new synthetic methods will make possible the synthesis of ever more complex natural products.
9 - The structure of ionic substances and covalently bonded molecules largely determines their function. As noted above, the properties of a substance depend on the number and type of atoms it contains and on the bonding patterns present. Its bulk properties also depend, however, on the interactions among individual atoms, ions, or molecules. The force of attraction between the fundamental units of a substance dictate whether, at a given temperature and pressure, that substance will exist in the solid, liquid, or gas phase. At room temperature and pressure, for example, the strong forces of attraction between the positive ions of sodium (Na+) and the negative ions of chlorine (Cl−) draw them into a compact solid structure. The weaker forces of attraction among neighbouring water molecules allow the looser packing characteristic of a liquid. Finally, the very weak attractive forces acting among adjacent oxygen molecules are exceeded by the dispersive forces of heat; oxygen, consequently, is a gas. Interparticle forces thus affect the chemical and physical behaviour of substances, but they also determine to a large extent how a particle will respond to the approach of a different particle. If the two particles react with each other to form new particles, a chemical reaction has occurred. Notwithstanding the unlimited structural diversity allowed by molecular bonding, the world would be devoid of life if substances were incapable of change. The study of chemical transformation, which complements the study of molecular structure, is built on the concepts of energy and entropy.
9 - The concept of energy is a fundamental and familiar one in all the sciences. In simple terms, the energy of a body represents its ability to do work, and work itself is a force acting over a distance.
9 - Chemical systems can have both kinetic energy (energy of motion) and potential energy (stored energy). The kinetic energy possessed by any collection of molecules in a solid, liquid, or gas is known as its thermal energy. Since liquids expand when they have more thermal energy, a liquid column of mercury, for example, will rise higher in an evacuated tube as it becomes warmer. In this way a thermometer can be used to measure the thermal energy, or temperature, of a system. The temperature at which all molecular motion comes to a halt is known as absolute zero.
9 - Energy also may be stored in atoms or molecules as potential energy. When protons and neutrons combine to form the nucleus of a certain element, the reduction in potential energy is matched by the production of a huge quantity of kinetic energy. Consider, for instance, the formation of the deuterium nucleus from one proton and one neutron. The fundamental mass unit of the chemist is the mole, which represents the mass, in grams, of 6.02 × 1023 individual particles, whether they be atoms or molecules. One mole of protons has a mass of 1.007825 grams and one mole of neutrons has a mass of 1.008665 grams. By simple addition the mass of one mole of deuterium atoms (ignoring the negligible mass of one mole of electrons) should be 2.016490 grams. The measured mass is 0.00239 gram less than this. The missing mass is known as the binding energy of the nucleus and represents the mass equivalent of the energy released by nucleus formation. By using Einstein’s formula for the conversion of mass to energy (E = mc2), one can calculate the energy equivalent of 0.00239 gram as 2.15 × 108 kilojoules. This is approximately 240,000 times greater than the energy released by the combustion of one mole of methane. Such studies of the energetics of atom formation and interconversion are part of a specialty known as nuclear chemistry.
9 - The energy released by the combustion of methane is about 900 kilojoules per mole. Although much less than the energy released by nuclear reactions, the energy given off by a chemical process such as combustion is great enough to be perceived as heat and light. Energy is released in so-called exothermic reactions because the chemical bonds in the product molecules, carbon dioxide and water, are stronger and stabler than those in the reactant molecules, methane and oxygen. The chemical potential energy of the system has decreased, and most of the released energy appears as heat, while some appears as radiant energy, or light. The heat produced by such a combustion reaction will raise the temperature of the surrounding air and, at constant pressure, increase its volume. This expansion of air results in work being done. In the cylinder of an internal-combustion engine, for example, the combustion of gasoline results in hot gases that expand against a moving piston. The motion of the piston turns a crankshaft, which then propels the vehicle. In this case, chemical potential energy has been converted to thermal energy, some of which produces useful work. This process illustrates a statement of the conservation of energy known as the first law of thermodynamics. This law states that, for an exothermic reaction, the energy released by the chemical system is equal to the heat gained by the surroundings plus the work performed. By measuring the heat and work quantities that accompany chemical reactions, it is possible to ascertain the energy differences between the reactants and the products of various reactions. In this manner, the potential energy stored in a variety of molecules can be determined, and the energy changes that accompany chemical reactions can be calculated.
9 - Some chemical processes occur even though there is no net energy change. Consider a vessel containing a gas, connected to an evacuated vessel via a channel wherein a barrier obstructs passage of the gas. If the barrier is removed, the gas will expand into the evacuated vessel. This expansion is consistent with the observation that a gas always expands to fill the volume available. When the temperature of both vessels is the same, the energy of the gas before and after the expansion is the same. The reverse reaction does not occur, however. The spontaneous reaction is the one that yields a state of greater disorder. In the expanded volume, the individual gas molecules have greater freedom of movement and thus are more disordered. The measure of the disorder of a system is a quantity termed entropy. At a temperature of absolute zero, all movement of atoms and molecules ceases, and the disorder—and entropy—of such perfectly compacted substances is zero. (Zero entropy at zero temperature is in accord with the third law of thermodynamics.) All substances above absolute zero will have a positive entropy value that increases with temperature. When a hot body cools down, the thermal energy it loses passes to the surrounding air, which is at a lower temperature. As the entropy of the cooling body decreases, the entropy of the surrounding air increases. In fact, the increase in entropy of the air is greater than the decrease in entropy of the cooling body. This is consistent with the second law, which states that the total entropy of a system and its surroundings always increases in a spontaneous reaction. Thus the first and second laws of thermodynamics indicate that, for all processes of chemical change throughout the universe, energy is conserved but entropy increases.
9 - Application of the laws of thermodynamics to chemical systems allows chemists to predict the behaviour of chemical reactions. When energy and entropy considerations favour the formation of product molecules, reagent molecules will act to form products until an equilibrium is established between products and reagents. The ratio of products to reagents is specified by a quantity known as an equilibrium constant, which is a function of the energy and entropy differences between the two. What thermodynamics cannot predict, however, is the rate at which chemical reactions occur. For fast reactions an equilibrium mixture of products and reagents can be established in one millisecond or less; for slow reactions the time required could be hundreds of years.
9 - When the specific rates of chemical reactions are measured experimentally, they are found to be dependent on the concentrations of reacting species, temperature, and a quantity called activation energy. Chemists explain this phenomenon by recourse to the collision theory of reaction rates. This theory builds on the premise that a reaction between two or more chemicals requires, at the molecular level, a collision between two rapidly moving molecules. If the two molecules collide in the right way and with enough kinetic energy, one of the molecules may acquire enough energy to initiate the bond-breaking process. As this occurs, new bonds may begin to form, and ultimately reagent molecules are converted into product molecules. The point of highest energy during bond breaking and bond formation is called the transition state of the molecular process. The difference between the energy of the transition state and that of the reacting molecules is the activation energy that must be exceeded for a reaction to occur. Reaction rates increase with temperature because the colliding molecules have greater energies, and more of them will have energies that exceed the activation energy of reaction. The modern study of the molecular basis of chemical change has been greatly aided by lasers and computers. It is now possible to study short-lived collision products and to better determine the molecular mechanisms that fix the rate of chemical reactions. This knowledge is useful in designing new catalysts that can accelerate the rate of reaction by lowering the activation energy. Catalysts are important for many biochemical and industrial processes because they speed up reactions that ordinarily occur too slowly to be useful. Moreover, they often do so with increased control over the structural features of the product molecules. A rhodium phosphine catalyst, for example, has enabled chemists to obtain 96 percent of the correct optical isomer in a key step in the synthesis of L-dopa, a drug used for treating Parkinson’s disease.
9 - For the first two-thirds of the 20th century, chemistry was seen by many as the science of the future. The potential of chemical products for enriching society appeared to be unlimited. Increasingly, however, and especially in the public mind, the negative aspects of chemistry have come to the fore. Disposal of chemical by-products at waste-disposal sites of limited capacity has resulted in environmental and health problems of enormous concern. The legitimate use of drugs for the medically supervised treatment of diseases has been tainted by the growing misuse of mood-altering drugs. The very word chemicals has come to be used all too frequently in a pejorative sense. There is, as a result, a danger that the pursuit and application of chemical knowledge may be seen as bearing risks that outweigh the benefits.
9 - It is easy to underestimate the central role of chemistry in modern society, but chemical products are essential if the world’s population is to be clothed, housed, and fed. The world’s reserves of fossil fuels (e.g., oil, natural gas, and coal) will eventually be exhausted, some as soon as the 21st century, and new chemical processes and materials will provide a crucial alternative energy source. The conversion of solar energy to more concentrated, useful forms, for example, will rely heavily on discoveries in chemistry. Long-term, environmentally acceptable solutions to pollution problems are not attainable without chemical knowledge. There is much truth in the aphorism that “chemical problems require chemical solutions.” Chemical inquiry will lead to a better understanding of the behaviour of both natural and synthetic materials and to the discovery of new substances that will help future generations better supply their needs and deal with their problems.
9 - Progress in chemistry can no longer be measured only in terms of economics and utility. The discovery and manufacture of new chemical goods must continue to be economically feasible but must be environmentally acceptable as well. The impact of new substances on the environment can now be assessed before large-scale production begins, and environmental compatibility has become a valued property of new materials. For example, compounds consisting of carbon fully bonded to chlorine and fluorine, called chlorofluorocarbons (or Freons), were believed to be ideal for their intended use when they were first discovered. They are nontoxic, nonflammable gases and volatile liquids that are very stable. These properties led to their widespread use as solvents, refrigerants, and propellants in aerosol containers. Time has shown, however, that these compounds decompose in the upper regions of the atmosphere and that the decomposition products act to destroy stratospheric ozone. Limits have now been placed on the use of chlorofluorocarbons, but it is impossible to recover the amounts already dispersed into the atmosphere.
9 - The chlorofluorocarbon problem illustrates how difficult it is to anticipate the overall impact that new materials can have on the environment. Chemists are working to develop methods of assessment, and prevailing chemical theory provides the working tools. Once a substance has been identified as hazardous to the existing ecological balance, it is the responsibility of chemists to locate that substance and neutralize it, limiting the damage it can do or removing it from the environment entirely. The last years of the 20th century will see many new, exciting discoveries in the processes and products of chemistry. Inevitably, the harmful effects of some substances will outweigh their benefits, and their use will have to be limited. Yet, the positive impact of chemistry on society as a whole seems beyond doubt.
9 - Chemistry has justly been called the central science. Chemists study the various substances in the world, with a particular focus on the processes by which one substance is transformed into another. Today, chemistry is defined as the study of the composition and properties of elements and compounds, the structure of their molecules, and the chemical reactions that they undergo. Rather than starting with such modern concepts, though, a fuller appreciation of the subject requires an examination of the historical processes that led to these concepts.
9 - Indeed, the philosophers of antiquity could have had no notion that all matter consists of the combinations of a few dozen elements as they are understood today. The earliest critical thinking on the nature of substances, as far as the historical record indicates, was by certain Greek philosophers beginning about 600 bce. Thales of Miletus, Anaximander, Empedocles, and others propounded theories that the world consisted of varieties of earth, water, air, fire, or indeterminate “seeds” or “unbounded” matter. Leucippus and Democritus propounded a materialistic theory of invisibly tiny irreducible atoms from which the world was made. In the 4th century bce, Plato (influenced by Pythagoreanism) taught that the world of the senses was but the shadow of a mathematical world of “forms” beyond human perception.
9 - In contrast, Plato’s student Aristotle took the world of the senses seriously. Adopting Empedocles’s view that the terrestrial region consisted of earth, water, air, and fire, Aristotle taught that each of these materials was a combination of qualities such as hot, cold, moist, and dry. For Aristotle, these “elements” were not building blocks of matter as they are thought of now; rather, they resulted from the qualities imposed on otherwise featureless prime matter. Consequently, there were many different kinds of earth, for instance, and nothing precluded one element from being transformed into another by appropriate adjustment of its qualities. Thus, Aristotle rejected the speculations of the ancient atomists and their irreducible fundamental particles. His views were highly regarded in late antiquity and remained influential throughout the Middle Ages.
9 - For thousands of years before Aristotle, metalsmiths, assayers, ceramists, and dyers had worked to perfect their crafts using empirically derived knowledge of chemical processes. By Hellenistic and Roman times, their skills were well advanced, and sophisticated ceramics, glasses, dyes, drugs, steels, bronze, brass, alloys of gold and silver, foodstuffs, and many other chemical products were traded. Hellenistic Alexandria in Egypt was a centre for these arts, and it was apparently there that a group of ideas emerged that later became known as alchemy.
9 - Three different sets of ideas and skills fed into the origin of alchemy. First was the empirical sophistication of jewelers, gold- and silversmiths, and other artisans who had learned how to fashion precious and semiprecious materials. Among their skills were smelting, assaying, alloying, gilding, amalgamating, distilling, sublimating, painting, and lacquering. The second component was the early Greek theory of matter, especially Aristotelian philosophy, which suggested the possibility of unlimited transformability of one kind of matter into another. The third of alchemy’s roots consisted of a complex combination of ideas derived from Asian philosophies and religions, Hellenistic mystery religions, and what became known as the Hermetic writings (a body of pseudonymous Greek writings on magic, astrology, and alchemy ascribed to the Egyptian god Thoth or his Greek counterpart Hermes Trismegistos). It is important to note, however, that Hellenistic Egypt is only one of several candidates for the homeland of alchemy; at about the same time, similar ideas were developing in Persia, China, and elsewhere.
9 - In general, alchemists sought to manipulate the properties of matter in order to prepare more valuable substances. Their most familiar quest was to find the philosopher’s stone, a magical substance that would transmute ordinary metals such as copper, tin, iron, or lead into silver or gold. Important materials in this craft included sulfur, mercury, and electrum (a gold-silver alloy). However, many other alchemists spurned alchemical transmutation (aurifaction), devoting their efforts instead to a pharmaceutical preparation known as the “elixir of life” that would cure any disease, including the ultimate disease, death. The philosopher’s stone and the elixir of life could be considered parallel quests, for each would “cure” metallic or human bodies, respectively, yielding immortal perfection. There was a parallel religious dimension to all this as well. Finally, some alchemists spurned material manipulations entirely, devoting themselves to meditation with the goal of achieving spiritual purity and ultimate redemption.
9 - After the rise of Islam, Arabic-speaking scholars of the 9th century translated Greek scientific and philosophical works into their own language. Thereafter, philosophers in the Islamic world pursued chemical and alchemical ideas with enthusiasm and success. The sizable number of modern chemical words derived from Arabic—alcohol, alkali, alchemy, zircon, elixir, natron, and others—suggests the importance of this period for the history of chemistry. One of the leading ideas of medieval Arabic alchemy was the theory that all metals were formed of sulfur and mercury in various proportions and that altering those proportions could transform the metal under study—even to produce silver or gold from lead or iron. Not every alchemist, however, believed in the possibility of such transmutations.
9 - Later, scholars in Christian western Europe learned of ancient Greek and early medieval Arabic philosophy by translating these books into Latin. Thus, the alchemical tradition, along with the rest of the Greco-Arabic philosophical and scientific corpus, passed to the West in the course of the 12th century. Well-known Scholastic philosophers of the 13th century, such as Roger Bacon in England and Albertus Magnus in Germany and France, wrote on alchemy. Alongside this learned literature, the empirical chemical arts continued to flourish and comprised a largely separate realm of expertise among artisans, engineers, and mechanics.
9 - An important Western alchemist of the late 13th century was the pseudonymous Latin writer who called himself Geber in homage to the 8th-century Arab alchemist Jābir ibn Ḥayyān. Geber was the first to record methods for the preparation and use of sulfuric acid, nitric acid, and hydrochloric acid; the earliest clear evidence for widespread familiarity with distilled alcohol also does not much predate his day. These substances could only have been produced by novel stills that were more robust and efficient than their predecessors, and the appearance of these remarkable new materials produced dramatic changes in the repertoire of chemists.
9 - The Renaissance saw even stronger interest in the science. The German-Swiss physician Paracelsus practiced alchemy, Kabbala, astrology, and magic, and in the first half of the 16th century he championed the role of mineral rather than herbal remedies. His emphasis on chemicals in pharmacy and medicine was influential on later figures, and lively controversies over the Paracelsian approach raged around the turn of the 17th century. Gradually the Hermetic influence declined in Europe, however, as certain celebrated feats of putative aurifaction were revealed as frauds.
9 - It would be a mistake to think that open-minded empirical investigation that is well integrated with theory (which is how one might define science) was absent from the history of alchemy. Alchemy had many quite scientific practitioners through the centuries, notably including Britain’s Robert Boyle and Isaac Newton—heroes of the scientific revolution of the 17th century—who applied systematic and quantitative method to their (mostly secret) alchemical studies. Indeed, as late as the end of the 17th century there was little to distinguish alchemy from chemistry, either substantively or semantically, since both words were applied to the same set of ideas. It was only in the early 18th century that chemists conferred different definitions on the two words, banishing alchemy to the ashbin of discredited occult pseudosciences.
9 - This shift was partly simple self-promotion by chemists in the new environment of the Enlightenment, whose vanguard glorified rationalism, experiment, and progress while demonizing the mystical. However, it was also becoming ever clearer that certain central ideas of alchemy (especially metallic transmutation) had never been demonstrated. One of the leaders in this regard was the German physician and chemist Georg Ernst Stahl, who vigorously attacked alchemy (after dabbling in it himself) and proposed an expansive new chemical theory. Stahl noted parallels between the burning of combustible materials and the calcination of metals—the conversion of a metal into its calx, or oxide. He suggested that both processes consisted of the loss of a material fluid, contained within all combustibles, called phlogiston.
9 - Phlogiston became the centrepiece of a broad-ranging theory that dominated 18th-century chemical thought. Phlogiston, in short, was thought to be a material substance that defined combustibility. When metallic iron becomes red rust, it loses its phlogiston, just as a burning log does. The ashes of the log and the red rust “ashes” (calx) of iron can no longer burn because they no longer contain the principle of combustibility, or phlogiston. But iron calx can be converted back to the metal if it is strongly heated in the presence of a phlogiston-rich substance such as charcoal. The charcoal donates its phlogiston (becoming ashes itself), while the calx turns into molten metallic iron. Thus, smelting (reduction) of metallic ores could also be understood in phlogistic terms. Later phlogistonists added respiration to the number of phenomena that the theory could elucidate. An animal breathes air, emitting phlogiston in an analogy to a slow fire, fueled by the phlogiston-rich food it consumes. Earth’s atmosphere avoids excess accumulation of phlogiston because plants incorporate it into combustible plant tissues that can then be used as animal food. Combustion, calcination, or respiration eventually cease in an enclosed space because air has a limited capacity to absorb the phlogiston emitted from the burning, calcining, or respiring entity.
9 - The phlogiston theory became popular both because of its great success in explaining phenomena and guiding further investigation and because of a certain Enlightenment predilection for materialistic physical theories (the putative fluid of heat became known as caloric, and there were other suggested fluids of electricity, light, and so on). This materialist-mechanist trend can also be seen in the diffuse but powerful influence of Newton and René Descartes on chemists of the 18th century. Enlightenment chemists established distinctive scientific communities and a well-defined discipline (closely allied, to be sure, with medical and artisanal studies) in the major countries of Europe. The chemist’s workplace or laboratory (the word itself had been coined in the Renaissance to apply to the chemical arts) was now closely associated with the field, and a standardized repertoire of operations was taught there.
9 - Still unsettled were some fundamental issues relating to chemical composition. To a phlogistonist, a metallic calx was elemental, and the associated metal was a compound of calx plus phlogiston. This puzzled some, though, since the metal gained rather than lost weight when it supposedly lost phlogiston to become a calx. The issues were sharpened in the 1770s, when the virtuoso English chemist (and Unitarian minister) Joseph Priestley produced a new gas by heating certain minerals. A candle burned in this gas with extraordinary vigour, and in an enclosed space a mouse breathing it survived far longer than one could in ordinary air. Priestley’s explanation was that the new gas had been radically dephlogisticated and, hence, had much greater capacity than air for absorbing phlogiston.
9 - Actually, gases (then usually known as airs) were a relatively novel object of chemical attention. In Scotland in 1756, Joseph Black studied the gas given off in respiration and combustion, characterizing it chemically and following its participation in certain chemical reactions. (Black, a physician, taught chemistry as a branch of medicine, as did most academic chemists of this era.) He called the new gas “fixed air,” since it was also found “fixed” in certain minerals such as limestone. His discovery that this gas was a normal component of common air (at a fraction of a percent, to be sure) was the first clear indication that atmospheric air was a mixture rather than a homogeneous element. In the following quarter century, many new gases were discovered and studied, by such workers as Priestley, the English physicist and chemist Henry Cavendish, and the Swedish pharmacist Carl Scheele.
9 - The new research on “airs” attracted the attention of the young French aristocrat Antoine-Laurent Lavoisier. Lavoisier commanded both the wealth and the scientific brilliance to enable him to construct elaborate apparatuses to carry out his numerous ingenious experiments. In the course of just a few years in the 1770s, Lavoisier developed a radical new system of chemistry, based on Black’s methods and Priestley’s dephlogisticated air.
9 - Lavoisier first determined that certain metals and nonmetals absorb a gaseous substance from the air in undergoing calcination or combustion and, in the process, increase in weight. Initially, he thought that this gas must be Black’s fixed air, for he knew of no other chemical species present in ordinary air; moreover, fixed air was known to be produced in smelting, so it seemed reasonable to think that it was present in the calx that was smelted. At this point (October 1774), Priestley communicated to Lavoisier his discovery of dephlogisticated air. Further experiments led Lavoisier to continuously modify his ideas, until it finally became clear to him that it was this new gas, and not fixed air, that was the active entity in combustion, calcination, and respiration. Moreover, he determined (or so he thought, at least) that this gas was contained in all acids. He renamed it oxygen, Greek for “acid producer.”
9 - Lavoisier’s oxygen was in some respects the inverse of phlogiston. Rather than releasing anything, the combustible or metal absorbed (more precisely, chemically combined with) oxygen in the process that Lavoisier now called oxidation. He showed that atmospheric air was a mixture of two principal components, oxygen and a physiologically inert gas (known to Priestley) that he called azote or nitrogen. He also showed that water is a chemical compound of two substances, oxygen and what Cavendish had called “inflammable air.” The latter gas was now renamed hydrogen (“water producer”). Black’s fixed air proved to be a gaseous form of oxidized carbon, or carbon dioxide. The various parts of Lavoisier’s new system were beginning to fit together beautifully.
9 - The keys to Lavoisier’s success were twofold. First, he carefully accounted for all the substances, including gases, entering into and emerging from the chemical reactions he studied by tracking their weights with the greatest possible precision. He knew to do this partly from Black’s example, but he proceeded with a mastery that the science had never before seen. Second, he established a simple operational definition of a chemical element—namely, a substance that could not be reduced in weight as the result of any chemical reaction that it undergoes. Oxygen, carbon, iron, and sulfur were now regarded as elements, along with close to 30 other substances. Lavoisier wrote a textbook to promote the new oxygenist chemistry, Traité élémentaire de chimie (1789), which appeared in the same year the French Revolution began. He and his associates also developed a new nomenclature—essentially the one used today for inorganic compounds—along with a new journal. As an aristocrat of the ancien régime and an investor in a tax-collection agency, Lavoisier was executed in the Reign of Terror, but by that time (1794) the chemical revolution that he had started had largely succeeded in replacing phlogistonist chemistry.
9 - Lavoisier’s set of chemical elements, and the new way of understanding chemical composition, proved to be invaluable for analytic and inorganic chemistry, but in a real sense the chemical revolution had only just begun. Around the turn of the century, the English Quaker schoolteacher John Dalton began to wonder about the invisibly small ultimate particles of which each of these elemental substances might be composed. He thought that if the atoms of each of the elements were distinct, they must be characterized by a distinct weight that is unique to each element. Although these atoms were far too small to weigh individually, he realized that he could deduce their weights relative to each other—the ratio of the weight of an atom of oxygen to one of hydrogen, for instance—by examining reacting weights of macroscopic quantities of these elements. In fact, the laws of stoichiometry (combining weights of elements) were just then being developed, and Dalton used these regularities to justify his inferences. His first discussion of these issues dates to 1803, and he presented his atomic theory in the multivolume New System of Chemical Philosophy (1808–27).
9 - Dalton’s atomic theory was a landmark event in the history of chemistry, but it had a crucial flaw. His procedure required that one know the formulas of the simple compounds resulting from the combination of the elements. For example, analytical data of that day indicated that water resulted from the combination of seven parts by weight of oxygen with one part of hydrogen. If the resulting water molecule was HO (one atom of each element combining to form a molecule of water), then the weight ratio of the atoms of these elements must be the same, seven to one. However, if the formula were H2O, then the weight of an oxygen atom would have to be 14 times the weight of a hydrogen atom. There was simply no way to determine molecular formulas at that time, so Dalton made assumptions based on the simplicity of nature. He chose HO as his water formula and, therefore, seven as the relative atomic weight of oxygen.
9 - In the following years, several leading chemists adopted essential elements of Dalton’s theory, but many objected to the hypothetical elements just described; some also doubted the very possibility of investigating the world of the invisibly small. In 1808 the French chemist Joseph-Louis Gay-Lussac discovered that when gases combine chemically, they do so in small integral multiples by volume. Three years later the Italian physicist Amedeo Avogadro argued that this fact suggested that equal volumes of gases contain equal numbers of constituent particles (Avogadro’s law), physical conditions being the same. This idea provided a physical method of determining certain molecular formulas. For instance, Gay-Lussac had pointed out that exactly two volumes of hydrogen combine with precisely one of oxygen to form water. If Avogadro was right, the formula for water had to be H2O. But this line of reasoning also led to the uncomfortable notion that elementary gases had polyatomic molecules (O2, H2, and so on), and therefore many chemists rejected Avogadro’s hypotheses.
9 - By far the greatest of the early atomists was the Swede Jöns Jacob Berzelius, who accepted parts of Avogadro’s ideas and developed an elaborate version of chemical atomism by 1826. It was Berzelius who in 1813 had proposed the alphabetic system for denoting elements, atoms, and molecular formulas, and the use of formulas as an aid for studying chemical composition and reactions began to blossom about 1830. However, different chemists were still making different assumptions regarding the formulas of simple compounds such as water, and so, for decades, various inconsistent systems of atomic weights and formulas were in use in the various European countries.
9 - Berzelius also developed a theory of chemical combination based on the electrochemical studies that the invention of the battery (1800) had spawned. He became convinced that all molecules were held together by the Coulomb force, the electrostatic attraction between oppositely charged objects. (Berzelius assumed that a molecule’s constituent atoms or groups of atoms were not neutral, and he called these charged components radicals.) This theory of electrochemical dualism worked well with inorganic compounds, but organic substances seemed anomalous. Particularly in the 1830s, when chemists learned how to replace the hydrogen of organic compounds with chlorine atoms, Berzelius’s theory appeared to be threatened—after all, hydrogen and chlorine had opposite electrochemical characteristics, yet the substitution seemed to make little difference in the properties of the compounds. In the 1840s and ’50s, extensive debates over rival systems of chemical atomism and over electrochemical dualism enlivened the journal literature.
9 - Both problems were finally resolved through the further development of organic chemistry. The leading organic chemists of the day were the German Justus von Liebig and the Frenchman Jean-Baptiste-André Dumas. In 1830 Liebig invented a device that made organic analysis rapid, convenient, and accurate, and his laboratory institute at the tiny University of Giessen in Hesse became the most famous chemical school in the world. Liebig taught an enormous number of chemists, and his students assisted in his research program. He was the leading figure in the rise of the research university and in the idea of a research group. As a professor at Giessen, and later at the University of Munich, he laid much emphasis on practical applications of chemistry, especially for physiology, agriculture, and consumer products. Dumas exerted a similar influence in France, training students and pursuing research at a private laboratory in Paris.
9 - Both Liebig and Dumas initially accepted the Berzelian scheme and sought to understand organic molecules as composed of identifiable radicals held together electrochemically. The younger French chemists Auguste Laurent and Charles Gerhardt pursued chlorine substitution reactions and cast doubt on this simple model; sometime after 1840 Liebig and Dumas both retreated into positivism. In 1852 Liebig’s English former postdoctoral assistant Edward Frankland noticed a regularity in the combining capacity of the atoms of certain metals and semimetals. At about the same time, two former students of both Liebig and Dumas, Alexander Williamson in London and Charles-Adolphe Wurtz in Paris, were independently approaching the same idea from a different direction. Using a system of atomic weights and formulas developed by Gerhardt and Laurent—a modified version of Berzelius’s system that incorporated Avogadro’s ideas more consistently—they proposed that oxygen atoms could combine with two other simple atoms, such as hydrogen, or with two organic radicals and that nitrogen atoms could combine with three. This was the beginning of the concept of atomic valence.
9 - In 1858 the young German theorist August Kekule then expanded this concept to carbon, not only proposing that carbon atoms were tetravalent but adding the idea that they could bond to each other to form chains, comprising a molecular “skeleton” to which other atoms could cling. Kekule’s theory of chemical structure clarified the compositions of hundreds of organic compounds and served as a guide to the synthesis of thousands more. (The self-chaining of carbon atoms was independently developed by the Scottish chemist Archibald Scott Couper.) This theory experienced dramatic expansion when Kekule successfully applied it to aromatic compounds (after 1865) and after Jacobus Henricus van ’t Hoff of the Netherlands and Joseph LeBel of France independently began to investigate molecular structures in three dimensions—later called stereochemistry.
9 - Kekule’s innovations were closely connected with a reform movement that gathered steam in the 1850s, seeking to replace the multiplicity of atomic weight systems with Gerhardt’s and Laurent’s proposal. Indeed, Kekule could not have succeeded with structure theory if he had not started with the reformed atomic weights. Kekule, Wurtz, and German chemist Carl Weltzien were organizers of the first international chemical conference, held at Karlsruhe in southwestern Germany in September 1860, which was intended to gain unity and understanding across the European chemical community. The Italian chemist Stanislao Cannizzaro played perhaps the most critical role at the conference. The reformers’ success was incomplete, but the Karlsruhe Congress can stand as an appropriate symbol of the era when chemistry attained a recognizably modern appearance.
9 - The widespread adoption of a single reformed set of atomic weights for the 60-odd known elements appears to have prompted renewed speculation on the relationships of the elements to each other, and various proposals for systems of classification were developed in the 1860s. By far the most successful of these systems was that of the Russian chemist Dmitry Mendeleev. In 1869 he announced that when the elements were arranged horizontally according to increasing atomic weight, and a new horizontal row was begun below the first whenever similar properties in the elements reappear, then the resulting semi-rectangular table revealed consistent periodicities. The vertical columns of similar elements were called groups or families, and the entire array was called the periodic table of the elements. Mendeleev demonstrated that this manner of looking at the elements was more than mere chance when he was able to use his periodic law to predict the existence of three new elements, later named gallium, scandium, and germanium, which were discovered in the 1870s and ’80s.
9 - To be sure, there were still many anomalies. For example, 15 chemically similar rare earth elements had been discovered by the end of the century. These elements were resistant to any periodic system; eventually they were grouped together in a separate category, the lanthanides (later called the lanthanoids; see transition element). Then in the 1890s British scientists William Ramsay and Lord Rayleigh discovered the inert, or rare, gases argon, helium, neon, krypton, and xenon. These were all clearly members of a single chemical family, but there were no vacant spaces in the table for them. Soon after the turn of the 20th century, chemists decided simply to create an extra group for them.
9 - Structuralist ideas from organic chemistry, as well as the development of the periodic table, gave new impetus to the study of inorganic compounds in the late 19th century. The leading chemical field in the second half of the century, however, was clearly organic chemistry, and the leading country was Germany. It was the Germans who exploited the structure theory most aggressively, and their success was measured by the explosive growth of university institutes as well as by practical applications developed in commercial enterprises. Organic chemists such as August Wilhelm von Hofmann and Emil Fischer at the University of Berlin and Adolf von Baeyer at the University of Munich developed large research groups that turned out novel compounds, research publications, and doctoral dissertations by the score. By the late 19th century, German chemistry, both academic and industrial, dominated Europe and the world.
9 - This is not to say that other approaches to chemistry were neglected, nor that other countries failed to participate in the excitement. Physical studies of chemical compounds and reactions began early in the century, and the field of physical chemistry had achieved maturity by the 1880s. Michael Faraday in England, Hermann Kopp and Robert Bunsen in Germany, and Henri-Victor Regnault in France carried out investigations on the physical characteristics of substances in the period 1830–60. Studies of heat, work, and force led to the rise of thermodynamics around 1850; originally oriented almost entirely to the science of physics, figures such as the American Josiah Willard Gibbs, the Frenchmen Marcellin Berthelot and Pierre Duhem, and the Germans Hermann von Helmholtz and Wilhelm Ostwald then applied energy and entropy concepts to chemistry in the 1870s and ’80s. Electrochemistry, invented by the independent efforts of Berzelius and Humphry Davy in England at the beginning of the century, was pursued fruitfully by Faraday and others. Bunsen and Gustav Kirchhoff of Germany developed chemical spectroscopy in the late 1850s. Studies on the kinetics of chemical reactions began in the 1860s.
9 - All this work culminated in the “official” establishment of the field of physical chemistry, traditionally considered to be when the Zeitschrift für Physikalische Chemie (“Journal of Physical Chemistry”) began publication in 1887. The editors were Ostwald and van ’t Hoff, with Svante Arrhenius of Sweden, a future Nobelist, an especially important member of its editorial board. Controversies over the reality of ionic dissociation and other issues connected with electrochemistry, the theory of solutions, and thermodynamics enlivened early issues of the journal.
9 - Physical chemists were in increasing demand as universities turned to them for instruction in basic courses on general and theoretical chemistry. This was nowhere more true than in the United States, with its vigorously expanding educational structure, including both private and state (land-grant) universities and emerging German-influenced doctoral programs. Soon after the turn of the century, two chemists at the Massachusetts Institute of Technology (MIT) who had studied with Ostwald, Arthur Noyes and Gilbert Lewis, formed the nucleus of a rising American chemical community. Noyes continued his career at Throop Polytechnic in Pasadena (later renamed the California Institute of Technology, commonly known as Caltech), and Lewis went on to the University of California at Berkeley.
9 - Physical chemistry was profoundly altered by what some have called the second scientific revolution—namely, the discoveries of the electron, X-rays, radioactivity, and new radioactive elements, the understanding of radioactive emissions and nuclear decay processes, and early versions of the theories of quantum mechanics and relativity. All of this happened in just 10 years, from 1895 to 1905, and the scientific bombshells continued in the following years. In 1911 the British physicist Ernest Rutherford proposed a nuclear model of the atom, but his orbiting electrons seemed to violate classical electromagnetic theory, and the model was not immediately embraced. However, two years later the Danish physicist Niels Bohr resolved some of these anomalies by applying spectroscopic data and the quantum theory of the German physicists Max Planck and Albert Einstein to Rutherford’s model (see figure). Bohr went on to head an international theoretical research group in Copenhagen that led in developing quantum mechanics during the 1920s. In the meantime, Rutherford revealed the existence of the proton and Einstein advanced his theory of general relativity.
9 - So much for the physicists; but the chemists were not sitting on their hands through all of this. Since its discovery a half century earlier, one of the greatest puzzles in chemistry had been the central phenomenon of valence. It was as inexplicable as it was incontrovertibly true that oxygen atoms had exactly two valence “hooks” with which to form bonds and carbon normally had four (that is to say, oxygen is divalent, carbon tetravalent). Moreover, these bonds were not radially symmetrical like electrostatic charges or gravitation but seemed to be directed at distinct spatial angles around the atom. And the existence of highly stable elementary molecules such as H2 was downright embarrassing—for what could be the basis for the strong attraction of two identical atoms for each other? Some scientists, such as the great Swiss chemist Alfred Werner, used combinations of structural-organic and ionic theories to develop a scheme that brilliantly explained the structures of complex inorganic substances known as coordination compounds.
9 - Others would take their cue from the discovery of the electron. As early as 1902, taking into account the work of the English physicist J.J. Thomson, Werner, and Ramsay and Rayleigh on the rare gases, Lewis privately drew casual sketches—depicting cubic atoms with outer electrons—that constituted the first step toward an electronic theory of chemical bonding. However, it was not until after Rutherford and Bohr had provided the early development of the nuclear theory of the atom that Lewis’s ideas gelled. (Simultaneously and independently, the German physicist Walther Kossel published a similar theory.) Lewis suggested that a chemical bond consisted of a pair of electrons that was shared between the combining atoms. By equal sharing of electrons (forming what the American physical chemist Irving Langmuir was soon to call a covalent bond), each atom could complete its outer electron shell and thus achieve stability. The normally complete outer shell, Lewis thought, contained eight electrons—the configuration of the notably stable (that is, inert) rare gases. This was the octet rule, and it helped to explain why Mendeleev’s periodicities often came in multiples of eight.
9 - The Lewis-Kossel-Langmuir electronic theory of valence (1916–23) was very incomplete, but was also extraordinarily fruitful for further developments, and essential elements of it survived for decades. In 1922 Bohr proposed electron configurations in the so-called K, L, M, and N shells. The theory was soon thereafter modified by breaking developments in quantum mechanics achieved by Bohr, German physicist Werner Heisenberg, Austrian physicist Erwin Schrödinger, and others. In 1927 two German researchers working with Schrödinger in Zürich, Fritz London and Walter Heitler, produced the first-ever quantum mechanical treatment of a chemical system, the hydrogen molecule.
9 - The American physical chemist Linus Pauling (along with another American, John Slater) independently developed this approach into what he called the valence bond method of understanding chemical combination. The orbitals in the various electron shells (classified by the letters s, p, d, and f) could be mathematically “hybridized,” resulting in the directed bonds actually observed in chemical compounds. Pauling also made extensive use of the quantum mechanical resonance effect, especially for understanding aromatic compounds. All of this was summarized in his classic work The Nature of the Chemical Bond (1939). An alternative quantum mechanical method of understanding chemical bonding, called the molecular orbital method, was developed by the American chemist Robert Mulliken and the German physicist Friedrich Hund. Although mathematically more complex, this approach has largely replaced Pauling’s. In any case, ever since Lewis and Bohr, it has been understood that all chemical reactions and all chemical bonding involves the outer electron shells—the valence electrons—of participating atoms.
9 - Organic chemists also incorporated electronic ideas into their theories. In the 1920s the Englishmen Robert Robinson and Christopher Ingold—bitter rivals then and later—led in the development of electronic theories of organic reaction mechanisms by focusing on rearranging electron pairs over the course of chemical reactions. Not only did this allow chemists to understand the intimate details of reactions in a way that had not previously been possible, but it also allowed them to successfully predict the reactivities of organic compounds in different chemical environments. Other studies of quantum mechanics applied to organic substances, combined with the kinetics of reactions, the nature of acids and bases, and instrumental methods of understanding compounds, led to a well-developed specialty field of physical organic chemistry.
9 - Organic chemistry, of course, looks not only in the direction of physics and physical chemistry but also, and even more essentially, in the direction of biology. Biochemistry began with studies of substances derived from plants and animals. By about 1800 many such substances were known, and chemistry had begun to assist physiology in understanding biological function. The nature of the principal chemical categories of foods—proteins, lipids, and carbohydrates—began to be studied in the first half of the century. By the end of the century, the role of enzymes as organic catalysts was clarified, and amino acids were perceived as constituents of proteins. The brilliant German chemist Emil Fischer determined the nature and structure of many carbohydrates and proteins. The announcement of the discovery (1912) of vitamins, independently by the Polish-born American biochemist Casimir Funk and the British biochemist Frederick Hopkins, precipitated a revolution in both biochemistry and human nutrition. Gradually, the details of intermediary metabolism—the way the body uses nutrient substances for energy, growth, and tissue repair—were unraveled. Perhaps the most representative example of this kind of work was the German-born British biochemist Hans Krebs’s establishment of the tricarboxylic acid cycle, or Krebs cycle, in the 1930s.
9 - But the most dramatic discovery in the history of 20th-century biochemistry was surely the structure of DNA (deoxyribonucleic acid), revealed by American geneticist James Watson and British biophysicist Francis Crick in 1953—the famous double helix. The new understanding of the molecule that incorporates the genetic code provided an essential link between chemistry and biology, a bridge over which much traffic continues to flow. The individual “letters” that make the code—four nucleotides named adenine, guanine, cytosine, and thymine—were discovered a century ago, but only at the close of the 20th century could the sequence of these letters in the genes that make up DNA be determined en masse. In June 2000, representatives from the publicly funded U.S. Human Genome Project and from Celera Genomics, a private company in Rockville, Md., simultaneously announced the independent and nearly complete sequencing of the more than three billion nucleotides in the human genome. However, both groups emphasized that this monumental accomplishment was, in a broader perspective, only the end of a race to the starting line.
9 - DNA is, of course, a macromolecule, and an understanding of this centrally important category of chemical compounds was a precondition for the events just described. Starch, cellulose, proteins, and rubber are other examples of natural macromolecules, or very large polymers. The word polymer (meaning “multiple parts”) was coined by Berzelius about 1830, but in the 19th century it was only applied to special cases such as ethylene (C2H4) versus butylene (C4H8). Only in the 1920s did the German chemist Hermann Staudinger definitely assert that complex carbohydrates and rubber had huge molecules. He coined the word macromolecule, viewing polymers as consisting of similar units joined head to tail by the hundreds and connected by ordinary chemical bonds.
9 - Empirical work on polymers had long predated Staudinger’s contributions, though. Nitrocellulose was used in the production of smokeless gunpowder, and mixtures of nitrocellulose with other organic compounds led to the first commercial polymers: collodion, xylonite, and celluloid. The last of these was the earliest plastic. The first totally synthetic plastic was patented by Leo Baekeland in 1909 and named Bakelite. Many new plastics were introduced in the 1920s, ’30s, and ’40s, including polymerized versions of acrylic acid (a variety of carboxylic acid), vinyl chloride, styrene, ethylene, and many others. Wallace Carothers’s nylon excited extraordinary attention during the World War II years. Great effort was also devoted to develop artificial substitutes for rubber—a natural resource in especially short supply during wartime. Already by World War I, German chemists had substitute materials, though many were less than satisfactory. The first highly successful rubber substitutes were produced in the early 1930s and were of great importance in World War II.
9 - During the interwar period, the leading role for chemistry shifted away from Germany. This was largely the result of the 1914–18 war, which alerted the Allied countries to the extent to which they had become dependent on the German chemical industries. Dyes, drugs, fertilizers, explosives, photochemicals, food chemicals (such as chemicals for food additives, food colouring, and food preservation), heavy chemicals, and strategic materiel of many kinds had been supplied internationally before the war largely by German chemical companies, and, when supplies of these vital materials were cut off in 1914, the Allies had to scramble to replace them. One particularly striking example is the introduction of chlorine gas and other poisons, starting in 1915, as chemical warfare agents. In any case, after the war ended, chemistry was enthusiastically promoted in Britain, France, and the United States, and the interwar years saw the United States rise to the status of a world power in science, including chemistry.
9 - All this makes clear why World War I is sometimes referred to as “the chemists’ war,” in the same way that World War II can be called “the physicists’ war” because of radar and nuclear weapons. But chemistry was an essential partner to physics in the development of nuclear science and technology. Indeed, the synthesis of transuranium elements (atomic numbers greater than 92) was a direct consequence of the research leading to (and during) the Manhattan Project in World War II. This is all part of the legacy of the dean of nuclear chemists, American Glenn Seaborg, discoverer or codiscoverer of 10 of the transuranium elements. In 1997, element 106 was named seaborgium in his honour.
9 - As far as the daily practice of chemical research is concerned, probably the most dramatic change during the 20th century was the revolution in methods of analysis. In 1930 chemists still used “wet-chemical,” or test-tube, methods that had changed little in the previous hundred years: reagent tests, titrations, determination of boiling and melting points, elemental combustion analysis, synthetic and analytic structural arguments, and so on. Starting with commercial labs that provided an out-source for routine analyses and with pH meters that displaced chemical indicators, chemists increasingly began to rely on physical instrumentation and specialists rather than personally administered wet-chemical methods. Physical instrumentation provides the sharp “eyes” that can see to the atomic-molecular level.
9 - In the 1910s J.J. Thomson and his assistant Francis Aston had developed the mass spectrograph to measure atomic and molecular weights with high accuracy. It was gradually improved, so that by the 1940s the mass spectrograph had been transformed into the mass spectrometer—no longer a machine for atomic weight research but rather an analytical instrument for the routine identification of complex unknown compounds (see mass spectrometry). Similarly, colorimetry had a long history, dating back well into the previous century. In the 1940s colorimetric principles were applied to sophisticated instrumentation to create a range of usable spectrophotometers, including visible, infrared, ultraviolet, and Raman spectroscopy. The later addition of laser and computer technology to analytical spectrometers provided further sophistication and also offered important tools for studies of the kinetics and mechanisms of reactions.
9 - Chromatography, used for generations to separate mixtures and identify the presence of a target substance, was ever more impressively automated, and gas chromatography (GC) in particular experienced vigorous development. Nuclear magnetic resonance (NMR), which uses radio waves interacting with a magnetic field to reveal the chemical environments of hydrogen atoms in a compound, was also developed after World War II. Early NMR machines were available in the 1950s; by the 1960s they were workhorses of organic chemical analysis. Also by this time, GC-NMR combinations were introduced, providing chemists unexcelled ability to separate and analyze minute amounts of sample. In the 1980s NMR became well known to the general public, when the technique was applied to medicine—though the name of the application was altered to magnetic resonance imaging (MRI) to avoid the loaded word nuclear.
9 - Many other instrumental methods have seen vigorous development, such as electron paramagnetic resonance and X-ray diffraction. In sum, between 1930 and 1970 the analytical revolution in chemistry utterly transformed the practice of the science and enormously accelerated its progress. Nor did the pace of innovation in analytical chemistry diminish during the final third of the century.
9 - No specialty was more affected by these changes than organic chemistry. The case of the American chemist Robert B. Woodward may be taken as illustrative. Woodward was the finest master of classical organic chemistry, but he was also a leader in aggressively exploiting new instrumentation, especially infrared, ultraviolet, and NMR spectrometry. His stock in trade was “total synthesis,” the creation of a (usually natural) organic substance in the laboratory, beginning with the simplest possible starting materials. Among the compounds that he and his collaborators synthesized were alkaloids such as quinine and strychnine, antibiotics such as tetracycline, and the extremely complex molecule chlorophyll. Woodward’s highest accomplishment in this field actually came six years after his receipt of the Nobel Prize for Chemistry in 1965: the synthesis of vitamin B12, a notable landmark in complexity. Progress continued apace after Woodward’s death. By 1994 a group at Harvard University had succeeded in synthesizing an extraordinarily challenging natural product, called palytoxin, that had more than 60 stereocentres.
9 - These total syntheses have had both practical and scientific spin-offs. Before the “instrumental revolution,” syntheses were often or even usually done to prove molecular structures. Today they are a central element of the search for new drugs. They can also illuminate theory. Together with a young Polish-born American chemical theoretician named Roald Hoffmann, Woodward followed up hints from the B12 synthesis that resulted in the formulation of orbital symmetry rules. These rules seemed to apply to all thermal or photochemical organic reactions that occur in a single step. The simplicity and accuracy of the predictions generated by the new rules, including highly specific stereochemical details of the product of the reaction, provided an invaluable tool for synthetic organic chemists.
9 - Stereochemistry, born toward the end of the 19th century, received steadily increasing attention throughout the 20th century. The three-dimensional details of molecular structure proved to be not only critical to chemical (and biochemical) function but also extraordinarily difficult to analyze and synthesize. Several Nobel Prizes in the second half of the century—those awarded to Derek Barton of Britain, John Cornforth of Australia, Vladimir Prelog of the Soviet Union, and others—were given partially or entirely to honour stereochemical advances. Also important in this regard was the American Elias J. Corey, awarded the Nobel Prize for Chemistry in 1990, who developed what he called retrosynthetic analysis, assisted increasingly by special interactive computer software. This approach transformed synthetic organic chemistry. Another important innovation was combinatorial chemistry, in which scores of compounds are simultaneously prepared—all permutations on a basic type—and then screened for physiological activity.
9 - Two more innovations of the late 20th century deserve at least brief mention, especially as they are special focuses of the chemical industry in the 21st century. The phenomenon of superconductivity (the ability to conduct electricity with no resistance) was discovered in 1911 at temperatures very close to absolute zero (0 K, −273.15 °C, or −459.67 °F). In 1986 two Swiss chemists discovered that lanthanum copper oxide doped with barium became superconducting at the “high” temperature of 35 K (−238 °C, or −397 °F). Since then, new superconducting materials have been discovered that operate well above the temperature of liquid nitrogen—77 K (−196 °C, or −321 °F). In addition to its purely scientific interest, much research focuses on practical applications of superconductivity.
9 - In 1985 Richard Smalley and Robert Curl at Rice University in Houston, Tex., collaborating with Harold Kroto of the University of Sussex in Brighton, Eng., discovered a fundamental new form of carbon, possessing molecules consisting solely of 60 carbon atoms. They named it buckminsterfullerene (later nicknamed “buckyball”), after Buckminster Fuller, the inventor of the geodesic dome. Research on fullerenes has accelerated since 1990, when a method was announced for producing buckyballs in large quantities and practical applications appeared likely. In 1991 Science magazine named buckminsterfullerene their “molecule of the year.”
9 - Two centuries ago, Lavoisier’s chemical revolution could still be questioned by the English émigré Joseph Priestley. A century ago, the physical reality of the atom was still doubted by some. Today, chemists can maneuver atoms one by one with a scanning tunneling microscope, and other techniques of what has become known as nanotechnology are in rapid development. The history of chemistry is an extraordinary story.

10 - rock and roll, style of popular music that originated in the United States in the mid-1950s and that evolved by the mid-1960s into the more encompassing international style known as rock music, though the latter also continued to be known as rock and roll.
10 - Rock and roll has been described as a merger of country music and rhythm and blues, but, if it were that simple, it would have existed long before it burst into the national consciousness. The seeds of the music had been in place for decades, but they flowered in the mid-1950s when nourished by a volatile mix of Black culture and white spending power. Black vocal groups such as the Dominoes and the Spaniels began combining gospel-style harmonies and call-and-response singing with earthy subject matter and more aggressive rhythm-and-blues rhythms. Heralding this new sound were disc jockeys such as Alan Freed of Cleveland, Ohio, Dewey Phillips of Memphis, Tennessee, and William (“Hoss”) Allen of WLAC in Nashville, Tennessee—who created rock-and-roll radio by playing hard-driving rhythm-and-blues and raunchy blues records that introduced white suburban teenagers to a culture that sounded more exotic, thrilling, and illicit than anything they had ever known. In 1954 that sound coalesced around an image: that of a handsome white singer, Elvis Presley, who sounded like a Black man.
10 - Presley’s nondenominational taste in music incorporated everything from hillbilly rave-ups and blues wails to pop-crooner ballads. Yet his early recordings with producer Sam Phillips, guitarist Scotty Moore, and bassist Bill Black for in Memphis were less about any one style than about a feeling. For decades African Americans had used the term rock and roll as a euphemism for sex, and Presley’s music oozed sexuality. Presley was hardly the only artist who embodied this attitude, but he was clearly a catalyst in the merger of Black and white culture into something far bigger and more complex than both.
10 - In Presley’s wake, the music of Black singers such as Fats Domino, Little Richard, Chuck Berry, and Bo Diddley, who might have been considered rhythm-and-blues artists only years before, fit alongside the rockabilly-flavoured tunes of white performers such as Buddy Holly, Eddie Cochran, and Jerry Lee Lewis, in part because they were all now addressing the same audience: teenagers. For young white America, this new music was a soundtrack for rebellion, however mild. When Bill Haley and His Comets kicked off the 1955 motion picture Blackboard Jungle with “Rock Around the Clock,” teens in movie houses throughout the United States stomped on their seats. Movie stars such as Marlon Brando in The Wild One (1953) and James Dean in Rebel Without a Cause (1955) oozed sullen, youthful defiance that was echoed by the music. This emerging rock-and-roll culture brought a wave of condemnations from religious leaders, government officials, and parents’ groups, who branded it the “devil’s music.”
10 - The music industry’s response was to sanitize the product: it had clean-cut, nonthreatening artists such as Pat Boone record tame versions of Little Richard songs, and it manufactured a legion of pretty-boy crooners such as Frankie Avalon and Fabian who thrived on and who would essentially serve as the Perry Comos and Bing Crosbys for a new generation of listeners. By the end of the 1950s, Presley had been inducted into the army, Holly had died in a plane crash, and Little Richard had converted to gospel. Rock and roll’s golden era had ended, and the music entered a transitional phase characterized by a more sophisticated approach: the orchestrated wall of sound erected by Phil Spector, the “hit factory” singles churned out by Motown records, and the harmony-rich surf fantasies of the Beach Boys. By the mid-1960s this sophistication allowed the music greater freedom than ever before, and it fragmented into numerous styles that became known simply as rock.
10 - Young girl wearing a demin jacket playing the trumpet (child, musical instruments, Asian ethnicity)
10 - Although instrumental accompaniment is almost universal in the blues, the blues is essentially a vocal form. Blues songs are lyrical rather than narrative; blues singers are expressing feelings rather than telling stories. The emotion expressed is generally one of sadness or melancholy, often due to problems of love but also oppression and hard times. To express this musically, blues performers use vocal techniques such as melisma (sustaining a single syllable across several pitches), rhythmic techniques such as syncopation, and instrumental techniques such as “choking” or bending guitar strings on the neck or applying a metal slide or bottleneck to the guitar strings to create a whining voicelike sound.
10 - As a musical style, the blues is characterized by expressive “microtonal” pitch inflections (blue notes), a three-line textual stanza of the form AAB, and a 12-measure form. Typically the first two and a half measures of each line are devoted to singing, the last measure and a half consisting of an instrumental “break” that repeats, answers, or complements the vocal line. In terms of functional (i.e., traditional European) harmony, the simplest blues harmonic progression is described as follows (I, IV, and V refer respectively to the first or tonic, fourth or subdominant, and fifth or dominant notes of the scale):
10 - African influences are apparent in the blues tonality, the call-and-response pattern of the repeated refrain structure of the blues stanza, the falsetto break in the vocal style, and the imitation of vocal idioms by instruments, especially the guitar and harmonica.
10 - The origins of the blues are poorly documented. Blues developed in the southern United States after the American Civil War (1861–65). It was influenced by work songs and field hollers, minstrel show music, ragtime, church music, and the folk and popular music of the white population. Blues derived from and was largely played by Southern Black men, most of whom came from the milieu of agricultural workers. The earliest references to blues date back to the 1890s and early 1900s. In 1912 Black bandleader W.C. Handy’s composition “Memphis Blues” was published. It became very popular, and thereafter many other Tin Pan Alley songs entitled blues began to appear.
10 - The rural blues developed in three principal regions, Georgia and the Carolinas, Texas, and Mississippi. The blues of Georgia and the Carolinas is noted for its clarity of enunciation and regularity of rhythm. Influenced by ragtime and white folk music, it is more melodic than the Texas and Mississippi styles. Blind Willie McTell and Blind Boy Fuller were representative of this style. The Texas blues is characterized by high, clear singing accompanied by supple guitar lines that consist typically of single-string picked arpeggios rather than strummed chords. Blind Lemon Jefferson was by far the most influential Texas bluesman. Mississippi Delta blues is the most intense of the three styles and has been the most influential. Vocally, it is the most speechlike, and the guitar accompaniment is rhythmic and percussive; a slide or bottleneck is often used. The Mississippi style is represented by Charley Patton, Eddie (“Son”) House, and Robert Johnson, among others.
10 - The first blues recordings were made in the 1920s by Black women, beginning with Mamie Smith. Her version of American composer and pianist Perry Bradford’s “Crazy Blues” in 1920 was so successful that the General Phonograph Company’s OKeh label launched a series called “Original Race Records.” It was advertised exclusively to African Americans in Black-owned newspapers. Other white-owned record companies were quick to target the Black market with their own “race record” lines. Blues singers Bessie Smith, Ethel Waters, and Clara Smith recorded for Columbia, while Ma Rainey, Ida Cox, and Alberta Hunter recorded for Paramount, which billed itself as the “Premier Race Label.” Over the next several years, Black musical director Clarence Williams signed and recorded for OKeh many leading blues, jazz, and gospel artists, including Louis Armstrong, King Oliver, and Lonnie Johnson. The rise of the “race records” industry spread the blues to audiences previously unfamiliar with the form.
10 - The Great Depression and the World Wars caused the geographic dispersal of the blues as millions of Blacks left the South for the cities of the North. The blues became adapted to the more sophisticated urban environment. Lyrics took up urban themes, and the blues ensemble developed as the solo bluesman was joined by a pianist or harmonica player and then by a rhythm section consisting of bass and drums. The electric guitar and the amplified harmonica created a driving sound of great rhythmic and emotional intensity.
10 - Among the cities in which the blues initially took root were Atlanta, Memphis, and St. Louis. John Lee Hooker settled in Detroit, and on the West Coast T-Bone Walker developed a style later adopted by B.B. King. It was Chicago, however, that played the greatest role in the development of urban blues. In the 1920s and ’30s Memphis Minnie, Tampa Red, Big Bill Broonzy, and Sonny Boy Williamson were popular Chicago performers. After World War II they were supplanted by a new generation of bluesmen that included Muddy Waters, Howlin’ Wolf, Elmore James, Little Walter Jacobs, Buddy Guy, and Koko Taylor. Later musicians that were advertised as blues performers include Z.Z. Hill, Denise LaSalle, and Latimore.
10 - The blues have influenced many other musical styles. Blues and jazz are closely related; such seminal jazzmen as Jelly Roll Morton and Louis Armstrong employed blues elements in their music. Soul music and rhythm and blues also show obvious blues tonalities and forms. The blues have had their greatest influence on rock music. Early rock singers such as Elvis Presley often used blues material. British rock musicians in the 1960s, especially the Rolling Stones, Eric Clapton, and John Mayall, were strongly influenced by the blues, as were such American rock musicians as Mike Bloomfield, Paul Butterfield, and the Allman Brothers Band.
10 - The blues also influenced American literature, especially during the Harlem Renaissance (c. 1918–37). Black writers such as Langston Hughes, Sterling Brown, and Jean Toomer valued the blues as an indigenous art form of oppressed people, a secular equivalent of the spirituals, and an antidote to bourgeois Black assimilationism. In Hughes’s second book, Fine Clothes to the Jew (1927), he turned to the blues for a poetic form derived from and answering to the desires, needs, and aesthetic sensibilities of the Black working class.